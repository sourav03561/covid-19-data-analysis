[2024-06-14T15:23:00.204+0530] {processor.py:161} INFO - Started process (PID=62367) to work on /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T15:23:00.205+0530] {processor.py:830} INFO - Processing file /home/wsl/airflow/dags/Collect Data/test3.py for tasks to queue
[2024-06-14T15:23:00.205+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:23:00.205+0530] {dagbag.py:540} INFO - Filling up the DagBag from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T15:23:16.860+0530] {logging_mixin.py:188} INFO - <pyspark.sql.session.SparkSession object at 0x7f386407d630>
[2024-06-14T15:23:30.405+0530] {processor.py:842} WARNING - No viable dags retrieved from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T15:23:30.414+0530] {processor.py:183} INFO - Processing /home/wsl/airflow/dags/Collect Data/test3.py took 30.217 seconds
[2024-06-14T15:24:33.057+0530] {processor.py:161} INFO - Started process (PID=63398) to work on /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T15:24:33.068+0530] {processor.py:830} INFO - Processing file /home/wsl/airflow/dags/Collect Data/test3.py for tasks to queue
[2024-06-14T15:24:33.069+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:24:33.068+0530] {dagbag.py:540} INFO - Filling up the DagBag from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T15:24:50.572+0530] {logging_mixin.py:188} INFO - <pyspark.sql.session.SparkSession object at 0x7f386407d630>
[2024-06-14T15:25:06.009+0530] {processor.py:842} WARNING - No viable dags retrieved from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T15:25:06.017+0530] {processor.py:183} INFO - Processing /home/wsl/airflow/dags/Collect Data/test3.py took 32.967 seconds
[2024-06-14T15:27:52.951+0530] {processor.py:161} INFO - Started process (PID=65224) to work on /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T15:27:52.997+0530] {processor.py:830} INFO - Processing file /home/wsl/airflow/dags/Collect Data/test3.py for tasks to queue
[2024-06-14T15:27:52.998+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:27:52.998+0530] {dagbag.py:540} INFO - Filling up the DagBag from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T15:28:36.155+0530] {logging_mixin.py:188} INFO - <pyspark.sql.session.SparkSession object at 0x7f386407d6c0>
[2024-06-14T15:29:08.124+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:29:08.124+0530] {_transport.py:372} INFO - PUT http://localhost:9200/_bulk [status:N/A duration:0.001s]
[2024-06-14T15:29:08.125+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:29:08.125+0530] {_node_pool.py:249} WARNING - Node <Urllib3HttpNode(http://localhost:9200)> has failed for 1 times in a row, putting on 1 second timeout
[2024-06-14T15:29:08.125+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:29:08.125+0530] {_transport.py:415} WARNING - Retrying request after failure (attempt 0 of 3)
Traceback (most recent call last):
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_transport.py", line 342, in perform_request
    resp = node.perform_request(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_node/_http_urllib3.py", line 202, in perform_request
    raise err from None
elastic_transport.ConnectionError: Connection error caused by: NewConnectionError(<urllib3.connection.HTTPConnection object at 0x7f3857b7a410>: Failed to establish a new connection: [Errno 111] Connection refused)
[2024-06-14T15:29:08.126+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:29:08.126+0530] {_transport.py:372} INFO - PUT http://localhost:9200/_bulk [status:N/A duration:0.000s]
[2024-06-14T15:29:08.127+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:29:08.126+0530] {_node_pool.py:249} WARNING - Node <Urllib3HttpNode(http://localhost:9200)> has failed for 2 times in a row, putting on 2 second timeout
[2024-06-14T15:29:08.127+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:29:08.127+0530] {_transport.py:415} WARNING - Retrying request after failure (attempt 1 of 3)
Traceback (most recent call last):
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_transport.py", line 342, in perform_request
    resp = node.perform_request(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_node/_http_urllib3.py", line 202, in perform_request
    raise err from None
elastic_transport.ConnectionError: Connection error caused by: NewConnectionError(<urllib3.connection.HTTPConnection object at 0x7f385efb92a0>: Failed to establish a new connection: [Errno 111] Connection refused)
[2024-06-14T15:29:08.128+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:29:08.128+0530] {_transport.py:372} INFO - PUT http://localhost:9200/_bulk [status:N/A duration:0.000s]
[2024-06-14T15:29:08.128+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:29:08.128+0530] {_node_pool.py:249} WARNING - Node <Urllib3HttpNode(http://localhost:9200)> has failed for 3 times in a row, putting on 4 second timeout
[2024-06-14T15:29:08.128+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:29:08.128+0530] {_transport.py:415} WARNING - Retrying request after failure (attempt 2 of 3)
Traceback (most recent call last):
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_transport.py", line 342, in perform_request
    resp = node.perform_request(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_node/_http_urllib3.py", line 202, in perform_request
    raise err from None
elastic_transport.ConnectionError: Connection error caused by: NewConnectionError(<urllib3.connection.HTTPConnection object at 0x7f386456dcc0>: Failed to establish a new connection: [Errno 111] Connection refused)
[2024-06-14T15:29:08.130+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:29:08.129+0530] {_transport.py:372} INFO - PUT http://localhost:9200/_bulk [status:N/A duration:0.001s]
[2024-06-14T15:29:08.130+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:29:08.130+0530] {_node_pool.py:249} WARNING - Node <Urllib3HttpNode(http://localhost:9200)> has failed for 4 times in a row, putting on 8 second timeout
[2024-06-14T15:29:08.675+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:29:08.130+0530] {dagbag.py:350} ERROR - Failed to import: /home/wsl/airflow/dags/Collect Data/test3.py
Traceback (most recent call last):
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/wsl/airflow/dags/Collect Data/test3.py", line 95, in <module>
    helpers.bulk(es, actions)
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/helpers/actions.py", line 521, in bulk
    for ok, item in streaming_bulk(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/helpers/actions.py", line 436, in streaming_bulk
    for data, (ok, info) in zip(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/helpers/actions.py", line 339, in _process_bulk_chunk
    resp = client.bulk(*args, operations=bulk_actions, **kwargs)  # type: ignore[arg-type]
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/_sync/client/utils.py", line 446, in wrapped
    return api(*args, **kwargs)
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/_sync/client/__init__.py", line 714, in bulk
    return self.perform_request(  # type: ignore[return-value]
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/_sync/client/_base.py", line 271, in perform_request
    response = self._perform_request(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/_sync/client/_base.py", line 316, in _perform_request
    meta, resp_body = self.transport.perform_request(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_transport.py", line 342, in perform_request
    resp = node.perform_request(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_node/_http_urllib3.py", line 202, in perform_request
    raise err from None
elastic_transport.ConnectionError: Connection error caused by: ConnectionError(Connection error caused by: NewConnectionError(<urllib3.connection.HTTPConnection object at 0x7f3857b7a410>: Failed to establish a new connection: [Errno 111] Connection refused))
[2024-06-14T15:29:08.677+0530] {processor.py:842} WARNING - No viable dags retrieved from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T15:29:14.845+0530] {processor.py:183} INFO - Processing /home/wsl/airflow/dags/Collect Data/test3.py took 81.912 seconds
[2024-06-14T15:31:42.849+0530] {processor.py:161} INFO - Started process (PID=66915) to work on /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T15:31:42.851+0530] {processor.py:830} INFO - Processing file /home/wsl/airflow/dags/Collect Data/test3.py for tasks to queue
[2024-06-14T15:31:42.853+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:31:42.852+0530] {dagbag.py:540} INFO - Filling up the DagBag from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T15:32:15.236+0530] {logging_mixin.py:188} INFO - <pyspark.sql.session.SparkSession object at 0x7f3863f1c3a0>
[2024-06-14T15:32:31.984+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:32:31.984+0530] {_transport.py:372} INFO - PUT http://localhost:9200/_bulk [status:N/A duration:0.001s]
[2024-06-14T15:32:31.985+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:32:31.984+0530] {_node_pool.py:249} WARNING - Node <Urllib3HttpNode(http://localhost:9200)> has failed for 1 times in a row, putting on 1 second timeout
[2024-06-14T15:32:31.985+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:32:31.985+0530] {_transport.py:415} WARNING - Retrying request after failure (attempt 0 of 3)
Traceback (most recent call last):
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_transport.py", line 342, in perform_request
    resp = node.perform_request(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_node/_http_urllib3.py", line 202, in perform_request
    raise err from None
elastic_transport.ConnectionError: Connection error caused by: NewConnectionError(<urllib3.connection.HTTPConnection object at 0x7f38599ae2c0>: Failed to establish a new connection: [Errno 111] Connection refused)
[2024-06-14T15:32:31.986+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:32:31.986+0530] {_transport.py:372} INFO - PUT http://localhost:9200/_bulk [status:N/A duration:0.000s]
[2024-06-14T15:32:31.987+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:32:31.986+0530] {_node_pool.py:249} WARNING - Node <Urllib3HttpNode(http://localhost:9200)> has failed for 2 times in a row, putting on 2 second timeout
[2024-06-14T15:32:31.987+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:32:31.987+0530] {_transport.py:415} WARNING - Retrying request after failure (attempt 1 of 3)
Traceback (most recent call last):
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_transport.py", line 342, in perform_request
    resp = node.perform_request(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_node/_http_urllib3.py", line 202, in perform_request
    raise err from None
elastic_transport.ConnectionError: Connection error caused by: NewConnectionError(<urllib3.connection.HTTPConnection object at 0x7f385ba4c9a0>: Failed to establish a new connection: [Errno 111] Connection refused)
[2024-06-14T15:32:31.988+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:32:31.987+0530] {_transport.py:372} INFO - PUT http://localhost:9200/_bulk [status:N/A duration:0.000s]
[2024-06-14T15:32:31.988+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:32:31.988+0530] {_node_pool.py:249} WARNING - Node <Urllib3HttpNode(http://localhost:9200)> has failed for 3 times in a row, putting on 4 second timeout
[2024-06-14T15:32:31.988+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:32:31.988+0530] {_transport.py:415} WARNING - Retrying request after failure (attempt 2 of 3)
Traceback (most recent call last):
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_transport.py", line 342, in perform_request
    resp = node.perform_request(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_node/_http_urllib3.py", line 202, in perform_request
    raise err from None
elastic_transport.ConnectionError: Connection error caused by: NewConnectionError(<urllib3.connection.HTTPConnection object at 0x7f3863f1e6e0>: Failed to establish a new connection: [Errno 111] Connection refused)
[2024-06-14T15:32:31.989+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:32:31.989+0530] {_transport.py:372} INFO - PUT http://localhost:9200/_bulk [status:N/A duration:0.001s]
[2024-06-14T15:32:31.990+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:32:31.989+0530] {_node_pool.py:249} WARNING - Node <Urllib3HttpNode(http://localhost:9200)> has failed for 4 times in a row, putting on 8 second timeout
[2024-06-14T15:32:31.991+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:32:31.990+0530] {dagbag.py:350} ERROR - Failed to import: /home/wsl/airflow/dags/Collect Data/test3.py
Traceback (most recent call last):
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/wsl/airflow/dags/Collect Data/test3.py", line 95, in <module>
    helpers.bulk(es, actions)
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/helpers/actions.py", line 521, in bulk
    for ok, item in streaming_bulk(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/helpers/actions.py", line 436, in streaming_bulk
    for data, (ok, info) in zip(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/helpers/actions.py", line 339, in _process_bulk_chunk
    resp = client.bulk(*args, operations=bulk_actions, **kwargs)  # type: ignore[arg-type]
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/_sync/client/utils.py", line 446, in wrapped
    return api(*args, **kwargs)
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/_sync/client/__init__.py", line 714, in bulk
    return self.perform_request(  # type: ignore[return-value]
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/_sync/client/_base.py", line 271, in perform_request
    response = self._perform_request(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/_sync/client/_base.py", line 316, in _perform_request
    meta, resp_body = self.transport.perform_request(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_transport.py", line 342, in perform_request
    resp = node.perform_request(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_node/_http_urllib3.py", line 202, in perform_request
    raise err from None
elastic_transport.ConnectionError: Connection error caused by: ConnectionError(Connection error caused by: NewConnectionError(<urllib3.connection.HTTPConnection object at 0x7f38599ae2c0>: Failed to establish a new connection: [Errno 111] Connection refused))
[2024-06-14T15:32:31.992+0530] {processor.py:842} WARNING - No viable dags retrieved from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T15:32:32.011+0530] {processor.py:183} INFO - Processing /home/wsl/airflow/dags/Collect Data/test3.py took 49.174 seconds
[2024-06-14T15:33:59.718+0530] {processor.py:161} INFO - Started process (PID=68220) to work on /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T15:34:00.058+0530] {processor.py:830} INFO - Processing file /home/wsl/airflow/dags/Collect Data/test3.py for tasks to queue
[2024-06-14T15:34:00.064+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:34:00.062+0530] {dagbag.py:540} INFO - Filling up the DagBag from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T15:34:23.086+0530] {logging_mixin.py:188} INFO - <pyspark.sql.session.SparkSession object at 0x7f386407e230>
[2024-06-14T15:34:41.493+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:34:41.493+0530] {_transport.py:372} INFO - PUT http://localhost:9200/_bulk [status:N/A duration:0.001s]
[2024-06-14T15:34:42.767+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:34:42.766+0530] {_node_pool.py:249} WARNING - Node <Urllib3HttpNode(http://localhost:9200)> has failed for 1 times in a row, putting on 1 second timeout
[2024-06-14T15:34:42.771+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:34:42.769+0530] {_transport.py:415} WARNING - Retrying request after failure (attempt 0 of 3)
Traceback (most recent call last):
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_transport.py", line 342, in perform_request
    resp = node.perform_request(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_node/_http_urllib3.py", line 202, in perform_request
    raise err from None
elastic_transport.ConnectionError: Connection error caused by: NewConnectionError(<urllib3.connection.HTTPConnection object at 0x7f3859b87f10>: Failed to establish a new connection: [Errno 111] Connection refused)
[2024-06-14T15:34:42.774+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:34:42.773+0530] {_transport.py:372} INFO - PUT http://localhost:9200/_bulk [status:N/A duration:0.002s]
[2024-06-14T15:34:42.775+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:34:42.775+0530] {_node_pool.py:249} WARNING - Node <Urllib3HttpNode(http://localhost:9200)> has failed for 2 times in a row, putting on 2 second timeout
[2024-06-14T15:34:42.777+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:34:42.776+0530] {_transport.py:415} WARNING - Retrying request after failure (attempt 1 of 3)
Traceback (most recent call last):
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_transport.py", line 342, in perform_request
    resp = node.perform_request(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_node/_http_urllib3.py", line 202, in perform_request
    raise err from None
elastic_transport.ConnectionError: Connection error caused by: NewConnectionError(<urllib3.connection.HTTPConnection object at 0x7f385bc96380>: Failed to establish a new connection: [Errno 111] Connection refused)
[2024-06-14T15:34:42.780+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:34:42.779+0530] {_transport.py:372} INFO - PUT http://localhost:9200/_bulk [status:N/A duration:0.002s]
[2024-06-14T15:34:42.781+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:34:42.780+0530] {_node_pool.py:249} WARNING - Node <Urllib3HttpNode(http://localhost:9200)> has failed for 3 times in a row, putting on 4 second timeout
[2024-06-14T15:34:42.783+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:34:42.781+0530] {_transport.py:415} WARNING - Retrying request after failure (attempt 2 of 3)
Traceback (most recent call last):
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_transport.py", line 342, in perform_request
    resp = node.perform_request(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_node/_http_urllib3.py", line 202, in perform_request
    raise err from None
elastic_transport.ConnectionError: Connection error caused by: NewConnectionError(<urllib3.connection.HTTPConnection object at 0x7f3861f9c670>: Failed to establish a new connection: [Errno 111] Connection refused)
[2024-06-14T15:34:42.786+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:34:42.785+0530] {_transport.py:372} INFO - PUT http://localhost:9200/_bulk [status:N/A duration:0.001s]
[2024-06-14T15:34:42.787+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:34:42.786+0530] {_node_pool.py:249} WARNING - Node <Urllib3HttpNode(http://localhost:9200)> has failed for 4 times in a row, putting on 8 second timeout
[2024-06-14T15:34:42.795+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:34:42.788+0530] {dagbag.py:350} ERROR - Failed to import: /home/wsl/airflow/dags/Collect Data/test3.py
Traceback (most recent call last):
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/wsl/airflow/dags/Collect Data/test3.py", line 95, in <module>
    helpers.bulk(es, actions)
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/helpers/actions.py", line 521, in bulk
    for ok, item in streaming_bulk(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/helpers/actions.py", line 436, in streaming_bulk
    for data, (ok, info) in zip(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/helpers/actions.py", line 339, in _process_bulk_chunk
    resp = client.bulk(*args, operations=bulk_actions, **kwargs)  # type: ignore[arg-type]
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/_sync/client/utils.py", line 446, in wrapped
    return api(*args, **kwargs)
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/_sync/client/__init__.py", line 714, in bulk
    return self.perform_request(  # type: ignore[return-value]
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/_sync/client/_base.py", line 271, in perform_request
    response = self._perform_request(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/_sync/client/_base.py", line 316, in _perform_request
    meta, resp_body = self.transport.perform_request(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_transport.py", line 342, in perform_request
    resp = node.perform_request(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_node/_http_urllib3.py", line 202, in perform_request
    raise err from None
elastic_transport.ConnectionError: Connection error caused by: ConnectionError(Connection error caused by: NewConnectionError(<urllib3.connection.HTTPConnection object at 0x7f3859b87f10>: Failed to establish a new connection: [Errno 111] Connection refused))
[2024-06-14T15:34:42.796+0530] {processor.py:842} WARNING - No viable dags retrieved from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T15:34:48.463+0530] {processor.py:183} INFO - Processing /home/wsl/airflow/dags/Collect Data/test3.py took 48.754 seconds
[2024-06-14T15:37:25.574+0530] {processor.py:161} INFO - Started process (PID=69793) to work on /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T15:37:25.579+0530] {processor.py:830} INFO - Processing file /home/wsl/airflow/dags/Collect Data/test3.py for tasks to queue
[2024-06-14T15:37:25.582+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:37:25.581+0530] {dagbag.py:540} INFO - Filling up the DagBag from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T15:37:38.891+0530] {logging_mixin.py:188} INFO - <pyspark.sql.session.SparkSession object at 0x7f3863f1c7c0>
[2024-06-14T15:37:55.027+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:37:55.026+0530] {_transport.py:372} INFO - PUT http://localhost:9200/_bulk [status:N/A duration:0.001s]
[2024-06-14T15:37:55.028+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:37:55.027+0530] {_node_pool.py:249} WARNING - Node <Urllib3HttpNode(http://localhost:9200)> has failed for 1 times in a row, putting on 1 second timeout
[2024-06-14T15:37:55.029+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:37:55.028+0530] {_transport.py:415} WARNING - Retrying request after failure (attempt 0 of 3)
Traceback (most recent call last):
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_transport.py", line 342, in perform_request
    resp = node.perform_request(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_node/_http_urllib3.py", line 202, in perform_request
    raise err from None
elastic_transport.ConnectionError: Connection error caused by: NewConnectionError(<urllib3.connection.HTTPConnection object at 0x7f38593bc1f0>: Failed to establish a new connection: [Errno 111] Connection refused)
[2024-06-14T15:37:55.030+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:37:55.030+0530] {_transport.py:372} INFO - PUT http://localhost:9200/_bulk [status:N/A duration:0.001s]
[2024-06-14T15:37:55.031+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:37:55.031+0530] {_node_pool.py:249} WARNING - Node <Urllib3HttpNode(http://localhost:9200)> has failed for 2 times in a row, putting on 2 second timeout
[2024-06-14T15:37:55.032+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:37:55.031+0530] {_transport.py:415} WARNING - Retrying request after failure (attempt 1 of 3)
Traceback (most recent call last):
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_transport.py", line 342, in perform_request
    resp = node.perform_request(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_node/_http_urllib3.py", line 202, in perform_request
    raise err from None
elastic_transport.ConnectionError: Connection error caused by: NewConnectionError(<urllib3.connection.HTTPConnection object at 0x7f38593bc640>: Failed to establish a new connection: [Errno 111] Connection refused)
[2024-06-14T15:37:55.033+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:37:55.033+0530] {_transport.py:372} INFO - PUT http://localhost:9200/_bulk [status:N/A duration:0.001s]
[2024-06-14T15:37:55.034+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:37:55.034+0530] {_node_pool.py:249} WARNING - Node <Urllib3HttpNode(http://localhost:9200)> has failed for 3 times in a row, putting on 4 second timeout
[2024-06-14T15:37:55.035+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:37:55.034+0530] {_transport.py:415} WARNING - Retrying request after failure (attempt 2 of 3)
Traceback (most recent call last):
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_transport.py", line 342, in perform_request
    resp = node.perform_request(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_node/_http_urllib3.py", line 202, in perform_request
    raise err from None
elastic_transport.ConnectionError: Connection error caused by: NewConnectionError(<urllib3.connection.HTTPConnection object at 0x7f38593bc8e0>: Failed to establish a new connection: [Errno 111] Connection refused)
[2024-06-14T15:37:55.036+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:37:55.036+0530] {_transport.py:372} INFO - PUT http://localhost:9200/_bulk [status:N/A duration:0.001s]
[2024-06-14T15:37:55.037+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:37:55.037+0530] {_node_pool.py:249} WARNING - Node <Urllib3HttpNode(http://localhost:9200)> has failed for 4 times in a row, putting on 8 second timeout
[2024-06-14T15:37:55.040+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:37:55.037+0530] {dagbag.py:350} ERROR - Failed to import: /home/wsl/airflow/dags/Collect Data/test3.py
Traceback (most recent call last):
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/wsl/airflow/dags/Collect Data/test3.py", line 95, in <module>
    helpers.bulk(es, actions)
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/helpers/actions.py", line 521, in bulk
    for ok, item in streaming_bulk(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/helpers/actions.py", line 436, in streaming_bulk
    for data, (ok, info) in zip(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/helpers/actions.py", line 339, in _process_bulk_chunk
    resp = client.bulk(*args, operations=bulk_actions, **kwargs)  # type: ignore[arg-type]
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/_sync/client/utils.py", line 446, in wrapped
    return api(*args, **kwargs)
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/_sync/client/__init__.py", line 714, in bulk
    return self.perform_request(  # type: ignore[return-value]
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/_sync/client/_base.py", line 271, in perform_request
    response = self._perform_request(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/_sync/client/_base.py", line 316, in _perform_request
    meta, resp_body = self.transport.perform_request(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_transport.py", line 342, in perform_request
    resp = node.perform_request(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_node/_http_urllib3.py", line 202, in perform_request
    raise err from None
elastic_transport.ConnectionError: Connection error caused by: ConnectionError(Connection error caused by: NewConnectionError(<urllib3.connection.HTTPConnection object at 0x7f38593bc1f0>: Failed to establish a new connection: [Errno 111] Connection refused))
[2024-06-14T15:37:55.041+0530] {processor.py:842} WARNING - No viable dags retrieved from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T15:37:55.067+0530] {processor.py:183} INFO - Processing /home/wsl/airflow/dags/Collect Data/test3.py took 29.514 seconds
[2024-06-14T15:39:22.325+0530] {processor.py:161} INFO - Started process (PID=70879) to work on /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T15:39:22.328+0530] {processor.py:830} INFO - Processing file /home/wsl/airflow/dags/Collect Data/test3.py for tasks to queue
[2024-06-14T15:39:22.330+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:39:22.329+0530] {dagbag.py:540} INFO - Filling up the DagBag from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T15:39:35.491+0530] {logging_mixin.py:188} INFO - <pyspark.sql.session.SparkSession object at 0x7f3863f1c820>
[2024-06-14T15:39:59.543+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:39:59.543+0530] {_transport.py:372} INFO - PUT http://localhost:9200/_bulk [status:N/A duration:0.001s]
[2024-06-14T15:39:59.544+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:39:59.543+0530] {_node_pool.py:249} WARNING - Node <Urllib3HttpNode(http://localhost:9200)> has failed for 1 times in a row, putting on 1 second timeout
[2024-06-14T15:39:59.544+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:39:59.544+0530] {_transport.py:415} WARNING - Retrying request after failure (attempt 0 of 3)
Traceback (most recent call last):
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_transport.py", line 342, in perform_request
    resp = node.perform_request(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_node/_http_urllib3.py", line 202, in perform_request
    raise err from None
elastic_transport.ConnectionError: Connection error caused by: NewConnectionError(<urllib3.connection.HTTPConnection object at 0x7f38599a63e0>: Failed to establish a new connection: [Errno 111] Connection refused)
[2024-06-14T15:39:59.545+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:39:59.545+0530] {_transport.py:372} INFO - PUT http://localhost:9200/_bulk [status:N/A duration:0.001s]
[2024-06-14T15:39:59.545+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:39:59.545+0530] {_node_pool.py:249} WARNING - Node <Urllib3HttpNode(http://localhost:9200)> has failed for 2 times in a row, putting on 2 second timeout
[2024-06-14T15:39:59.546+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:39:59.545+0530] {_transport.py:415} WARNING - Retrying request after failure (attempt 1 of 3)
Traceback (most recent call last):
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_transport.py", line 342, in perform_request
    resp = node.perform_request(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_node/_http_urllib3.py", line 202, in perform_request
    raise err from None
elastic_transport.ConnectionError: Connection error caused by: NewConnectionError(<urllib3.connection.HTTPConnection object at 0x7f385ba48610>: Failed to establish a new connection: [Errno 111] Connection refused)
[2024-06-14T15:39:59.546+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:39:59.546+0530] {_transport.py:372} INFO - PUT http://localhost:9200/_bulk [status:N/A duration:0.000s]
[2024-06-14T15:39:59.547+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:39:59.547+0530] {_node_pool.py:249} WARNING - Node <Urllib3HttpNode(http://localhost:9200)> has failed for 3 times in a row, putting on 4 second timeout
[2024-06-14T15:39:59.547+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:39:59.547+0530] {_transport.py:415} WARNING - Retrying request after failure (attempt 2 of 3)
Traceback (most recent call last):
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_transport.py", line 342, in perform_request
    resp = node.perform_request(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_node/_http_urllib3.py", line 202, in perform_request
    raise err from None
elastic_transport.ConnectionError: Connection error caused by: NewConnectionError(<urllib3.connection.HTTPConnection object at 0x7f38644c4910>: Failed to establish a new connection: [Errno 111] Connection refused)
[2024-06-14T15:39:59.548+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:39:59.548+0530] {_transport.py:372} INFO - PUT http://localhost:9200/_bulk [status:N/A duration:0.000s]
[2024-06-14T15:39:59.548+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:39:59.548+0530] {_node_pool.py:249} WARNING - Node <Urllib3HttpNode(http://localhost:9200)> has failed for 4 times in a row, putting on 8 second timeout
[2024-06-14T15:39:59.550+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:39:59.548+0530] {dagbag.py:350} ERROR - Failed to import: /home/wsl/airflow/dags/Collect Data/test3.py
Traceback (most recent call last):
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/wsl/airflow/dags/Collect Data/test3.py", line 95, in <module>
    helpers.bulk(es, actions)
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/helpers/actions.py", line 521, in bulk
    for ok, item in streaming_bulk(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/helpers/actions.py", line 436, in streaming_bulk
    for data, (ok, info) in zip(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/helpers/actions.py", line 339, in _process_bulk_chunk
    resp = client.bulk(*args, operations=bulk_actions, **kwargs)  # type: ignore[arg-type]
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/_sync/client/utils.py", line 446, in wrapped
    return api(*args, **kwargs)
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/_sync/client/__init__.py", line 714, in bulk
    return self.perform_request(  # type: ignore[return-value]
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/_sync/client/_base.py", line 271, in perform_request
    response = self._perform_request(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/_sync/client/_base.py", line 316, in _perform_request
    meta, resp_body = self.transport.perform_request(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_transport.py", line 342, in perform_request
    resp = node.perform_request(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_node/_http_urllib3.py", line 202, in perform_request
    raise err from None
elastic_transport.ConnectionError: Connection error caused by: ConnectionError(Connection error caused by: NewConnectionError(<urllib3.connection.HTTPConnection object at 0x7f38599a63e0>: Failed to establish a new connection: [Errno 111] Connection refused))
[2024-06-14T15:39:59.550+0530] {processor.py:842} WARNING - No viable dags retrieved from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T15:40:04.683+0530] {processor.py:183} INFO - Processing /home/wsl/airflow/dags/Collect Data/test3.py took 42.376 seconds
[2024-06-14T15:41:08.112+0530] {processor.py:161} INFO - Started process (PID=71880) to work on /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T15:41:08.116+0530] {processor.py:830} INFO - Processing file /home/wsl/airflow/dags/Collect Data/test3.py for tasks to queue
[2024-06-14T15:41:08.119+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:41:08.117+0530] {dagbag.py:540} INFO - Filling up the DagBag from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T15:41:27.136+0530] {logging_mixin.py:188} INFO - <pyspark.sql.session.SparkSession object at 0x7f3863f18850>
[2024-06-14T15:41:42.164+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:41:42.163+0530] {_transport.py:372} INFO - PUT http://localhost:9200/_bulk [status:N/A duration:0.001s]
[2024-06-14T15:41:42.164+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:41:42.164+0530] {_node_pool.py:249} WARNING - Node <Urllib3HttpNode(http://localhost:9200)> has failed for 1 times in a row, putting on 1 second timeout
[2024-06-14T15:41:42.165+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:41:42.165+0530] {_transport.py:415} WARNING - Retrying request after failure (attempt 0 of 3)
Traceback (most recent call last):
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_transport.py", line 342, in perform_request
    resp = node.perform_request(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_node/_http_urllib3.py", line 202, in perform_request
    raise err from None
elastic_transport.ConnectionError: Connection error caused by: NewConnectionError(<urllib3.connection.HTTPConnection object at 0x7f38599ae410>: Failed to establish a new connection: [Errno 111] Connection refused)
[2024-06-14T15:41:42.167+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:41:42.166+0530] {_transport.py:372} INFO - PUT http://localhost:9200/_bulk [status:N/A duration:0.001s]
[2024-06-14T15:41:42.167+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:41:42.167+0530] {_node_pool.py:249} WARNING - Node <Urllib3HttpNode(http://localhost:9200)> has failed for 2 times in a row, putting on 2 second timeout
[2024-06-14T15:41:42.167+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:41:42.167+0530] {_transport.py:415} WARNING - Retrying request after failure (attempt 1 of 3)
Traceback (most recent call last):
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_transport.py", line 342, in perform_request
    resp = node.perform_request(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_node/_http_urllib3.py", line 202, in perform_request
    raise err from None
elastic_transport.ConnectionError: Connection error caused by: NewConnectionError(<urllib3.connection.HTTPConnection object at 0x7f385ba48640>: Failed to establish a new connection: [Errno 111] Connection refused)
[2024-06-14T15:41:42.168+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:41:42.168+0530] {_transport.py:372} INFO - PUT http://localhost:9200/_bulk [status:N/A duration:0.000s]
[2024-06-14T15:41:42.169+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:41:42.168+0530] {_node_pool.py:249} WARNING - Node <Urllib3HttpNode(http://localhost:9200)> has failed for 3 times in a row, putting on 4 second timeout
[2024-06-14T15:41:42.169+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:41:42.169+0530] {_transport.py:415} WARNING - Retrying request after failure (attempt 2 of 3)
Traceback (most recent call last):
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_transport.py", line 342, in perform_request
    resp = node.perform_request(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_node/_http_urllib3.py", line 202, in perform_request
    raise err from None
elastic_transport.ConnectionError: Connection error caused by: NewConnectionError(<urllib3.connection.HTTPConnection object at 0x7f38709d5f00>: Failed to establish a new connection: [Errno 111] Connection refused)
[2024-06-14T15:41:42.170+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:41:42.169+0530] {_transport.py:372} INFO - PUT http://localhost:9200/_bulk [status:N/A duration:0.000s]
[2024-06-14T15:41:42.170+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:41:42.170+0530] {_node_pool.py:249} WARNING - Node <Urllib3HttpNode(http://localhost:9200)> has failed for 4 times in a row, putting on 8 second timeout
[2024-06-14T15:41:42.172+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:41:42.170+0530] {dagbag.py:350} ERROR - Failed to import: /home/wsl/airflow/dags/Collect Data/test3.py
Traceback (most recent call last):
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/wsl/airflow/dags/Collect Data/test3.py", line 95, in <module>
    helpers.bulk(es, actions)
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/helpers/actions.py", line 521, in bulk
    for ok, item in streaming_bulk(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/helpers/actions.py", line 436, in streaming_bulk
    for data, (ok, info) in zip(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/helpers/actions.py", line 339, in _process_bulk_chunk
    resp = client.bulk(*args, operations=bulk_actions, **kwargs)  # type: ignore[arg-type]
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/_sync/client/utils.py", line 446, in wrapped
    return api(*args, **kwargs)
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/_sync/client/__init__.py", line 714, in bulk
    return self.perform_request(  # type: ignore[return-value]
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/_sync/client/_base.py", line 271, in perform_request
    response = self._perform_request(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/_sync/client/_base.py", line 316, in _perform_request
    meta, resp_body = self.transport.perform_request(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_transport.py", line 342, in perform_request
    resp = node.perform_request(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_node/_http_urllib3.py", line 202, in perform_request
    raise err from None
elastic_transport.ConnectionError: Connection error caused by: ConnectionError(Connection error caused by: NewConnectionError(<urllib3.connection.HTTPConnection object at 0x7f38599ae410>: Failed to establish a new connection: [Errno 111] Connection refused))
[2024-06-14T15:41:42.172+0530] {processor.py:842} WARNING - No viable dags retrieved from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T15:41:42.191+0530] {processor.py:183} INFO - Processing /home/wsl/airflow/dags/Collect Data/test3.py took 34.096 seconds
[2024-06-14T15:42:50.682+0530] {processor.py:161} INFO - Started process (PID=72863) to work on /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T15:42:50.684+0530] {processor.py:830} INFO - Processing file /home/wsl/airflow/dags/Collect Data/test3.py for tasks to queue
[2024-06-14T15:42:50.685+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:42:50.684+0530] {dagbag.py:540} INFO - Filling up the DagBag from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T15:43:14.279+0530] {logging_mixin.py:188} INFO - <pyspark.sql.session.SparkSession object at 0x7f3863f188b0>
[2024-06-14T15:43:30.633+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:43:30.633+0530] {_transport.py:372} INFO - PUT http://localhost:9200/_bulk [status:N/A duration:0.001s]
[2024-06-14T15:43:30.635+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:43:30.633+0530] {_node_pool.py:249} WARNING - Node <Urllib3HttpNode(http://localhost:9200)> has failed for 1 times in a row, putting on 1 second timeout
[2024-06-14T15:43:30.637+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:43:30.636+0530] {_transport.py:415} WARNING - Retrying request after failure (attempt 0 of 3)
Traceback (most recent call last):
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_transport.py", line 342, in perform_request
    resp = node.perform_request(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_node/_http_urllib3.py", line 202, in perform_request
    raise err from None
elastic_transport.ConnectionError: Connection error caused by: NewConnectionError(<urllib3.connection.HTTPConnection object at 0x7f385991e470>: Failed to establish a new connection: [Errno 111] Connection refused)
[2024-06-14T15:43:30.638+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:43:30.638+0530] {_transport.py:372} INFO - PUT http://localhost:9200/_bulk [status:N/A duration:0.001s]
[2024-06-14T15:43:30.639+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:43:30.639+0530] {_node_pool.py:249} WARNING - Node <Urllib3HttpNode(http://localhost:9200)> has failed for 2 times in a row, putting on 2 second timeout
[2024-06-14T15:43:30.639+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:43:30.639+0530] {_transport.py:415} WARNING - Retrying request after failure (attempt 1 of 3)
Traceback (most recent call last):
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_transport.py", line 342, in perform_request
    resp = node.perform_request(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_node/_http_urllib3.py", line 202, in perform_request
    raise err from None
elastic_transport.ConnectionError: Connection error caused by: NewConnectionError(<urllib3.connection.HTTPConnection object at 0x7f385ba486a0>: Failed to establish a new connection: [Errno 111] Connection refused)
[2024-06-14T15:43:30.640+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:43:30.640+0530] {_transport.py:372} INFO - PUT http://localhost:9200/_bulk [status:N/A duration:0.000s]
[2024-06-14T15:43:30.640+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:43:30.640+0530] {_node_pool.py:249} WARNING - Node <Urllib3HttpNode(http://localhost:9200)> has failed for 3 times in a row, putting on 4 second timeout
[2024-06-14T15:43:30.641+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:43:30.641+0530] {_transport.py:415} WARNING - Retrying request after failure (attempt 2 of 3)
Traceback (most recent call last):
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_transport.py", line 342, in perform_request
    resp = node.perform_request(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_node/_http_urllib3.py", line 202, in perform_request
    raise err from None
elastic_transport.ConnectionError: Connection error caused by: NewConnectionError(<urllib3.connection.HTTPConnection object at 0x7f38644c49a0>: Failed to establish a new connection: [Errno 111] Connection refused)
[2024-06-14T15:43:30.642+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:43:30.641+0530] {_transport.py:372} INFO - PUT http://localhost:9200/_bulk [status:N/A duration:0.000s]
[2024-06-14T15:43:30.642+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:43:30.642+0530] {_node_pool.py:249} WARNING - Node <Urllib3HttpNode(http://localhost:9200)> has failed for 4 times in a row, putting on 8 second timeout
[2024-06-14T15:43:30.643+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:43:30.642+0530] {dagbag.py:350} ERROR - Failed to import: /home/wsl/airflow/dags/Collect Data/test3.py
Traceback (most recent call last):
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/wsl/airflow/dags/Collect Data/test3.py", line 95, in <module>
    helpers.bulk(es, actions)
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/helpers/actions.py", line 521, in bulk
    for ok, item in streaming_bulk(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/helpers/actions.py", line 436, in streaming_bulk
    for data, (ok, info) in zip(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/helpers/actions.py", line 339, in _process_bulk_chunk
    resp = client.bulk(*args, operations=bulk_actions, **kwargs)  # type: ignore[arg-type]
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/_sync/client/utils.py", line 446, in wrapped
    return api(*args, **kwargs)
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/_sync/client/__init__.py", line 714, in bulk
    return self.perform_request(  # type: ignore[return-value]
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/_sync/client/_base.py", line 271, in perform_request
    response = self._perform_request(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/_sync/client/_base.py", line 316, in _perform_request
    meta, resp_body = self.transport.perform_request(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_transport.py", line 342, in perform_request
    resp = node.perform_request(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_node/_http_urllib3.py", line 202, in perform_request
    raise err from None
elastic_transport.ConnectionError: Connection error caused by: ConnectionError(Connection error caused by: NewConnectionError(<urllib3.connection.HTTPConnection object at 0x7f385991e470>: Failed to establish a new connection: [Errno 111] Connection refused))
[2024-06-14T15:43:30.644+0530] {processor.py:842} WARNING - No viable dags retrieved from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T15:43:31.663+0530] {processor.py:183} INFO - Processing /home/wsl/airflow/dags/Collect Data/test3.py took 40.992 seconds
[2024-06-14T15:44:34.257+0530] {processor.py:161} INFO - Started process (PID=73842) to work on /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T15:44:34.261+0530] {processor.py:830} INFO - Processing file /home/wsl/airflow/dags/Collect Data/test3.py for tasks to queue
[2024-06-14T15:44:34.263+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:44:34.262+0530] {dagbag.py:540} INFO - Filling up the DagBag from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T15:44:57.849+0530] {logging_mixin.py:188} INFO - <pyspark.sql.session.SparkSession object at 0x7f3863f1c8e0>
[2024-06-14T15:45:31.807+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:45:31.807+0530] {_transport.py:372} INFO - PUT http://localhost:9200/_bulk [status:N/A duration:0.004s]
[2024-06-14T15:45:31.809+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:45:31.808+0530] {_node_pool.py:249} WARNING - Node <Urllib3HttpNode(http://localhost:9200)> has failed for 1 times in a row, putting on 1 second timeout
[2024-06-14T15:45:31.811+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:45:31.809+0530] {_transport.py:415} WARNING - Retrying request after failure (attempt 0 of 3)
Traceback (most recent call last):
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_transport.py", line 342, in perform_request
    resp = node.perform_request(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_node/_http_urllib3.py", line 202, in perform_request
    raise err from None
elastic_transport.ConnectionError: Connection error caused by: NewConnectionError(<urllib3.connection.HTTPConnection object at 0x7f38599ae4a0>: Failed to establish a new connection: [Errno 111] Connection refused)
[2024-06-14T15:45:31.813+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:45:31.812+0530] {_transport.py:372} INFO - PUT http://localhost:9200/_bulk [status:N/A duration:0.001s]
[2024-06-14T15:45:31.813+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:45:31.813+0530] {_node_pool.py:249} WARNING - Node <Urllib3HttpNode(http://localhost:9200)> has failed for 2 times in a row, putting on 2 second timeout
[2024-06-14T15:45:31.814+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:45:31.814+0530] {_transport.py:415} WARNING - Retrying request after failure (attempt 1 of 3)
Traceback (most recent call last):
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_transport.py", line 342, in perform_request
    resp = node.perform_request(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_node/_http_urllib3.py", line 202, in perform_request
    raise err from None
elastic_transport.ConnectionError: Connection error caused by: NewConnectionError(<urllib3.connection.HTTPConnection object at 0x7f385ba48670>: Failed to establish a new connection: [Errno 111] Connection refused)
[2024-06-14T15:45:31.816+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:45:31.816+0530] {_transport.py:372} INFO - PUT http://localhost:9200/_bulk [status:N/A duration:0.001s]
[2024-06-14T15:45:31.817+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:45:31.816+0530] {_node_pool.py:249} WARNING - Node <Urllib3HttpNode(http://localhost:9200)> has failed for 3 times in a row, putting on 4 second timeout
[2024-06-14T15:45:31.817+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:45:31.817+0530] {_transport.py:415} WARNING - Retrying request after failure (attempt 2 of 3)
Traceback (most recent call last):
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_transport.py", line 342, in perform_request
    resp = node.perform_request(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_node/_http_urllib3.py", line 202, in perform_request
    raise err from None
elastic_transport.ConnectionError: Connection error caused by: NewConnectionError(<urllib3.connection.HTTPConnection object at 0x7f38709d5270>: Failed to establish a new connection: [Errno 111] Connection refused)
[2024-06-14T15:45:31.820+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:45:31.819+0530] {_transport.py:372} INFO - PUT http://localhost:9200/_bulk [status:N/A duration:0.001s]
[2024-06-14T15:45:31.820+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:45:31.820+0530] {_node_pool.py:249} WARNING - Node <Urllib3HttpNode(http://localhost:9200)> has failed for 4 times in a row, putting on 8 second timeout
[2024-06-14T15:45:31.825+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:45:31.821+0530] {dagbag.py:350} ERROR - Failed to import: /home/wsl/airflow/dags/Collect Data/test3.py
Traceback (most recent call last):
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/wsl/airflow/dags/Collect Data/test3.py", line 95, in <module>
    helpers.bulk(es, actions)
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/helpers/actions.py", line 521, in bulk
    for ok, item in streaming_bulk(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/helpers/actions.py", line 436, in streaming_bulk
    for data, (ok, info) in zip(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/helpers/actions.py", line 339, in _process_bulk_chunk
    resp = client.bulk(*args, operations=bulk_actions, **kwargs)  # type: ignore[arg-type]
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/_sync/client/utils.py", line 446, in wrapped
    return api(*args, **kwargs)
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/_sync/client/__init__.py", line 714, in bulk
    return self.perform_request(  # type: ignore[return-value]
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/_sync/client/_base.py", line 271, in perform_request
    response = self._perform_request(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/_sync/client/_base.py", line 316, in _perform_request
    meta, resp_body = self.transport.perform_request(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_transport.py", line 342, in perform_request
    resp = node.perform_request(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_node/_http_urllib3.py", line 202, in perform_request
    raise err from None
elastic_transport.ConnectionError: Connection error caused by: ConnectionError(Connection error caused by: NewConnectionError(<urllib3.connection.HTTPConnection object at 0x7f38599ae4a0>: Failed to establish a new connection: [Errno 111] Connection refused))
[2024-06-14T15:45:31.826+0530] {processor.py:842} WARNING - No viable dags retrieved from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T15:45:31.851+0530] {processor.py:183} INFO - Processing /home/wsl/airflow/dags/Collect Data/test3.py took 57.612 seconds
[2024-06-14T15:46:44.024+0530] {processor.py:161} INFO - Started process (PID=75048) to work on /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T15:46:44.029+0530] {processor.py:830} INFO - Processing file /home/wsl/airflow/dags/Collect Data/test3.py for tasks to queue
[2024-06-14T15:46:44.032+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:46:44.031+0530] {dagbag.py:540} INFO - Filling up the DagBag from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T15:46:57.824+0530] {logging_mixin.py:188} INFO - <pyspark.sql.session.SparkSession object at 0x7f3863f1ca00>
[2024-06-14T15:47:16.775+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:47:16.775+0530] {_transport.py:372} INFO - PUT http://localhost:9200/_bulk [status:N/A duration:0.001s]
[2024-06-14T15:47:16.776+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:47:16.775+0530] {_node_pool.py:249} WARNING - Node <Urllib3HttpNode(http://localhost:9200)> has failed for 1 times in a row, putting on 1 second timeout
[2024-06-14T15:47:17.539+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:47:17.535+0530] {_transport.py:415} WARNING - Retrying request after failure (attempt 0 of 3)
Traceback (most recent call last):
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_transport.py", line 342, in perform_request
    resp = node.perform_request(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_node/_http_urllib3.py", line 202, in perform_request
    raise err from None
elastic_transport.ConnectionError: Connection error caused by: NewConnectionError(<urllib3.connection.HTTPConnection object at 0x7f38597108b0>: Failed to establish a new connection: [Errno 111] Connection refused)
[2024-06-14T15:47:17.547+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:47:17.546+0530] {_transport.py:372} INFO - PUT http://localhost:9200/_bulk [status:N/A duration:0.004s]
[2024-06-14T15:47:17.561+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:47:17.548+0530] {_node_pool.py:249} WARNING - Node <Urllib3HttpNode(http://localhost:9200)> has failed for 2 times in a row, putting on 2 second timeout
[2024-06-14T15:47:17.563+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:47:17.561+0530] {_transport.py:415} WARNING - Retrying request after failure (attempt 1 of 3)
Traceback (most recent call last):
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_transport.py", line 342, in perform_request
    resp = node.perform_request(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_node/_http_urllib3.py", line 202, in perform_request
    raise err from None
elastic_transport.ConnectionError: Connection error caused by: NewConnectionError(<urllib3.connection.HTTPConnection object at 0x7f3859710d00>: Failed to establish a new connection: [Errno 111] Connection refused)
[2024-06-14T15:47:17.565+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:47:17.564+0530] {_transport.py:372} INFO - PUT http://localhost:9200/_bulk [status:N/A duration:0.001s]
[2024-06-14T15:47:17.566+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:47:17.566+0530] {_node_pool.py:249} WARNING - Node <Urllib3HttpNode(http://localhost:9200)> has failed for 3 times in a row, putting on 4 second timeout
[2024-06-14T15:47:17.567+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:47:17.567+0530] {_transport.py:415} WARNING - Retrying request after failure (attempt 2 of 3)
Traceback (most recent call last):
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_transport.py", line 342, in perform_request
    resp = node.perform_request(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_node/_http_urllib3.py", line 202, in perform_request
    raise err from None
elastic_transport.ConnectionError: Connection error caused by: NewConnectionError(<urllib3.connection.HTTPConnection object at 0x7f3859710fa0>: Failed to establish a new connection: [Errno 111] Connection refused)
[2024-06-14T15:47:17.570+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:47:17.569+0530] {_transport.py:372} INFO - PUT http://localhost:9200/_bulk [status:N/A duration:0.001s]
[2024-06-14T15:47:17.571+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:47:17.570+0530] {_node_pool.py:249} WARNING - Node <Urllib3HttpNode(http://localhost:9200)> has failed for 4 times in a row, putting on 8 second timeout
[2024-06-14T15:47:17.576+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:47:17.571+0530] {dagbag.py:350} ERROR - Failed to import: /home/wsl/airflow/dags/Collect Data/test3.py
Traceback (most recent call last):
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/wsl/airflow/dags/Collect Data/test3.py", line 95, in <module>
    helpers.bulk(es, actions)
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/helpers/actions.py", line 521, in bulk
    for ok, item in streaming_bulk(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/helpers/actions.py", line 436, in streaming_bulk
    for data, (ok, info) in zip(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/helpers/actions.py", line 339, in _process_bulk_chunk
    resp = client.bulk(*args, operations=bulk_actions, **kwargs)  # type: ignore[arg-type]
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/_sync/client/utils.py", line 446, in wrapped
    return api(*args, **kwargs)
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/_sync/client/__init__.py", line 714, in bulk
    return self.perform_request(  # type: ignore[return-value]
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/_sync/client/_base.py", line 271, in perform_request
    response = self._perform_request(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/_sync/client/_base.py", line 316, in _perform_request
    meta, resp_body = self.transport.perform_request(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_transport.py", line 342, in perform_request
    resp = node.perform_request(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_node/_http_urllib3.py", line 202, in perform_request
    raise err from None
elastic_transport.ConnectionError: Connection error caused by: ConnectionError(Connection error caused by: NewConnectionError(<urllib3.connection.HTTPConnection object at 0x7f38597108b0>: Failed to establish a new connection: [Errno 111] Connection refused))
[2024-06-14T15:47:17.577+0530] {processor.py:842} WARNING - No viable dags retrieved from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T15:47:17.833+0530] {processor.py:183} INFO - Processing /home/wsl/airflow/dags/Collect Data/test3.py took 33.832 seconds
[2024-06-14T15:48:26.964+0530] {processor.py:161} INFO - Started process (PID=76192) to work on /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T15:48:26.989+0530] {processor.py:830} INFO - Processing file /home/wsl/airflow/dags/Collect Data/test3.py for tasks to queue
[2024-06-14T15:48:26.991+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:48:26.990+0530] {dagbag.py:540} INFO - Filling up the DagBag from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T15:48:43.441+0530] {logging_mixin.py:188} INFO - <pyspark.sql.session.SparkSession object at 0x7f3863f188e0>
[2024-06-14T15:49:02.271+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:49:02.270+0530] {_transport.py:372} INFO - PUT http://localhost:9200/_bulk [status:N/A duration:0.002s]
[2024-06-14T15:49:02.272+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:49:02.271+0530] {_node_pool.py:249} WARNING - Node <Urllib3HttpNode(http://localhost:9200)> has failed for 1 times in a row, putting on 1 second timeout
[2024-06-14T15:49:03.663+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:49:02.272+0530] {_transport.py:415} WARNING - Retrying request after failure (attempt 0 of 3)
Traceback (most recent call last):
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_transport.py", line 342, in perform_request
    resp = node.perform_request(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_node/_http_urllib3.py", line 202, in perform_request
    raise err from None
elastic_transport.ConnectionError: Connection error caused by: NewConnectionError(<urllib3.connection.HTTPConnection object at 0x7f385970c8b0>: Failed to establish a new connection: [Errno 111] Connection refused)
[2024-06-14T15:49:03.666+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:49:03.664+0530] {_node_pool.py:310} INFO - Resurrected node <Urllib3HttpNode(http://localhost:9200)> (force=False)
[2024-06-14T15:49:03.672+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:49:03.672+0530] {_transport.py:372} INFO - PUT http://localhost:9200/_bulk [status:N/A duration:0.004s]
[2024-06-14T15:49:03.674+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:49:03.673+0530] {_node_pool.py:249} WARNING - Node <Urllib3HttpNode(http://localhost:9200)> has failed for 2 times in a row, putting on 2 second timeout
[2024-06-14T15:49:03.675+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:49:03.674+0530] {_transport.py:415} WARNING - Retrying request after failure (attempt 1 of 3)
Traceback (most recent call last):
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_transport.py", line 342, in perform_request
    resp = node.perform_request(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_node/_http_urllib3.py", line 202, in perform_request
    raise err from None
elastic_transport.ConnectionError: Connection error caused by: NewConnectionError(<urllib3.connection.HTTPConnection object at 0x7f385970cbb0>: Failed to establish a new connection: [Errno 111] Connection refused)
[2024-06-14T15:49:03.679+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:49:03.678+0530] {_transport.py:372} INFO - PUT http://localhost:9200/_bulk [status:N/A duration:0.002s]
[2024-06-14T15:49:03.681+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:49:03.680+0530] {_node_pool.py:249} WARNING - Node <Urllib3HttpNode(http://localhost:9200)> has failed for 3 times in a row, putting on 4 second timeout
[2024-06-14T15:49:03.683+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:49:03.682+0530] {_transport.py:415} WARNING - Retrying request after failure (attempt 2 of 3)
Traceback (most recent call last):
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_transport.py", line 342, in perform_request
    resp = node.perform_request(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_node/_http_urllib3.py", line 202, in perform_request
    raise err from None
elastic_transport.ConnectionError: Connection error caused by: NewConnectionError(<urllib3.connection.HTTPConnection object at 0x7f385970cfa0>: Failed to establish a new connection: [Errno 111] Connection refused)
[2024-06-14T15:49:03.687+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:49:03.686+0530] {_transport.py:372} INFO - PUT http://localhost:9200/_bulk [status:N/A duration:0.002s]
[2024-06-14T15:49:03.689+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:49:03.688+0530] {_node_pool.py:249} WARNING - Node <Urllib3HttpNode(http://localhost:9200)> has failed for 4 times in a row, putting on 8 second timeout
[2024-06-14T15:49:05.483+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:49:03.690+0530] {dagbag.py:350} ERROR - Failed to import: /home/wsl/airflow/dags/Collect Data/test3.py
Traceback (most recent call last):
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/wsl/airflow/dags/Collect Data/test3.py", line 95, in <module>
    helpers.bulk(es, actions)
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/helpers/actions.py", line 521, in bulk
    for ok, item in streaming_bulk(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/helpers/actions.py", line 436, in streaming_bulk
    for data, (ok, info) in zip(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/helpers/actions.py", line 339, in _process_bulk_chunk
    resp = client.bulk(*args, operations=bulk_actions, **kwargs)  # type: ignore[arg-type]
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/_sync/client/utils.py", line 446, in wrapped
    return api(*args, **kwargs)
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/_sync/client/__init__.py", line 714, in bulk
    return self.perform_request(  # type: ignore[return-value]
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/_sync/client/_base.py", line 271, in perform_request
    response = self._perform_request(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/_sync/client/_base.py", line 316, in _perform_request
    meta, resp_body = self.transport.perform_request(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_transport.py", line 342, in perform_request
    resp = node.perform_request(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_node/_http_urllib3.py", line 202, in perform_request
    raise err from None
elastic_transport.ConnectionError: Connection error caused by: ConnectionError(Connection error caused by: NewConnectionError(<urllib3.connection.HTTPConnection object at 0x7f385970c8b0>: Failed to establish a new connection: [Errno 111] Connection refused))
[2024-06-14T15:49:05.485+0530] {processor.py:842} WARNING - No viable dags retrieved from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T15:49:05.945+0530] {processor.py:183} INFO - Processing /home/wsl/airflow/dags/Collect Data/test3.py took 38.999 seconds
[2024-06-14T15:50:24.353+0530] {processor.py:161} INFO - Started process (PID=77249) to work on /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T15:50:24.357+0530] {processor.py:830} INFO - Processing file /home/wsl/airflow/dags/Collect Data/test3.py for tasks to queue
[2024-06-14T15:50:24.360+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:50:24.359+0530] {dagbag.py:540} INFO - Filling up the DagBag from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T15:50:39.951+0530] {logging_mixin.py:188} INFO - <pyspark.sql.session.SparkSession object at 0x7f3863f1ca60>
[2024-06-14T15:51:01.589+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:51:01.589+0530] {_transport.py:372} INFO - PUT http://localhost:9200/_bulk [status:N/A duration:0.001s]
[2024-06-14T15:51:01.590+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:51:01.590+0530] {_node_pool.py:249} WARNING - Node <Urllib3HttpNode(http://localhost:9200)> has failed for 1 times in a row, putting on 1 second timeout
[2024-06-14T15:51:01.592+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:51:01.590+0530] {_transport.py:415} WARNING - Retrying request after failure (attempt 0 of 3)
Traceback (most recent call last):
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_transport.py", line 342, in perform_request
    resp = node.perform_request(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_node/_http_urllib3.py", line 202, in perform_request
    raise err from None
elastic_transport.ConnectionError: Connection error caused by: NewConnectionError(<urllib3.connection.HTTPConnection object at 0x7f3859700910>: Failed to establish a new connection: [Errno 111] Connection refused)
[2024-06-14T15:51:01.594+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:51:01.593+0530] {_transport.py:372} INFO - PUT http://localhost:9200/_bulk [status:N/A duration:0.001s]
[2024-06-14T15:51:01.594+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:51:01.594+0530] {_node_pool.py:249} WARNING - Node <Urllib3HttpNode(http://localhost:9200)> has failed for 2 times in a row, putting on 2 second timeout
[2024-06-14T15:51:01.595+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:51:01.594+0530] {_transport.py:415} WARNING - Retrying request after failure (attempt 1 of 3)
Traceback (most recent call last):
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_transport.py", line 342, in perform_request
    resp = node.perform_request(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_node/_http_urllib3.py", line 202, in perform_request
    raise err from None
elastic_transport.ConnectionError: Connection error caused by: NewConnectionError(<urllib3.connection.HTTPConnection object at 0x7f3859700d60>: Failed to establish a new connection: [Errno 111] Connection refused)
[2024-06-14T15:51:01.595+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:51:01.595+0530] {_transport.py:372} INFO - PUT http://localhost:9200/_bulk [status:N/A duration:0.000s]
[2024-06-14T15:51:01.596+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:51:01.596+0530] {_node_pool.py:249} WARNING - Node <Urllib3HttpNode(http://localhost:9200)> has failed for 3 times in a row, putting on 4 second timeout
[2024-06-14T15:51:01.596+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:51:01.596+0530] {_transport.py:415} WARNING - Retrying request after failure (attempt 2 of 3)
Traceback (most recent call last):
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_transport.py", line 342, in perform_request
    resp = node.perform_request(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_node/_http_urllib3.py", line 202, in perform_request
    raise err from None
elastic_transport.ConnectionError: Connection error caused by: NewConnectionError(<urllib3.connection.HTTPConnection object at 0x7f3859701000>: Failed to establish a new connection: [Errno 111] Connection refused)
[2024-06-14T15:51:01.597+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:51:01.597+0530] {_transport.py:372} INFO - PUT http://localhost:9200/_bulk [status:N/A duration:0.001s]
[2024-06-14T15:51:01.597+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:51:01.597+0530] {_node_pool.py:249} WARNING - Node <Urllib3HttpNode(http://localhost:9200)> has failed for 4 times in a row, putting on 8 second timeout
[2024-06-14T15:51:01.605+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:51:01.598+0530] {dagbag.py:350} ERROR - Failed to import: /home/wsl/airflow/dags/Collect Data/test3.py
Traceback (most recent call last):
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/wsl/airflow/dags/Collect Data/test3.py", line 95, in <module>
    helpers.bulk(es, actions)
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/helpers/actions.py", line 521, in bulk
    for ok, item in streaming_bulk(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/helpers/actions.py", line 436, in streaming_bulk
    for data, (ok, info) in zip(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/helpers/actions.py", line 339, in _process_bulk_chunk
    resp = client.bulk(*args, operations=bulk_actions, **kwargs)  # type: ignore[arg-type]
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/_sync/client/utils.py", line 446, in wrapped
    return api(*args, **kwargs)
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/_sync/client/__init__.py", line 714, in bulk
    return self.perform_request(  # type: ignore[return-value]
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/_sync/client/_base.py", line 271, in perform_request
    response = self._perform_request(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/_sync/client/_base.py", line 316, in _perform_request
    meta, resp_body = self.transport.perform_request(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_transport.py", line 342, in perform_request
    resp = node.perform_request(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_node/_http_urllib3.py", line 202, in perform_request
    raise err from None
elastic_transport.ConnectionError: Connection error caused by: ConnectionError(Connection error caused by: NewConnectionError(<urllib3.connection.HTTPConnection object at 0x7f3859700910>: Failed to establish a new connection: [Errno 111] Connection refused))
[2024-06-14T15:51:01.606+0530] {processor.py:842} WARNING - No viable dags retrieved from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T15:51:01.625+0530] {processor.py:183} INFO - Processing /home/wsl/airflow/dags/Collect Data/test3.py took 37.292 seconds
[2024-06-14T15:55:25.820+0530] {processor.py:161} INFO - Started process (PID=78298) to work on /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T15:55:25.822+0530] {processor.py:830} INFO - Processing file /home/wsl/airflow/dags/Collect Data/test3.py for tasks to queue
[2024-06-14T15:55:25.824+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:55:25.823+0530] {dagbag.py:540} INFO - Filling up the DagBag from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T15:55:40.390+0530] {logging_mixin.py:188} INFO - <pyspark.sql.session.SparkSession object at 0x7f3863f1c940>
[2024-06-14T15:56:13.650+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:56:13.642+0530] {_transport.py:372} INFO - PUT http://localhost:9200/_bulk [status:N/A duration:0.001s]
[2024-06-14T15:56:13.653+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:56:13.652+0530] {_node_pool.py:249} WARNING - Node <Urllib3HttpNode(http://localhost:9200)> has failed for 1 times in a row, putting on 1 second timeout
[2024-06-14T15:56:13.657+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:56:13.653+0530] {_transport.py:415} WARNING - Retrying request after failure (attempt 0 of 3)
Traceback (most recent call last):
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_transport.py", line 342, in perform_request
    resp = node.perform_request(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_node/_http_urllib3.py", line 202, in perform_request
    raise err from None
elastic_transport.ConnectionError: Connection error caused by: NewConnectionError(<urllib3.connection.HTTPConnection object at 0x7f38599a6500>: Failed to establish a new connection: [Errno 111] Connection refused)
[2024-06-14T15:56:13.658+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:56:13.658+0530] {_transport.py:372} INFO - PUT http://localhost:9200/_bulk [status:N/A duration:0.000s]
[2024-06-14T15:56:13.659+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:56:13.658+0530] {_node_pool.py:249} WARNING - Node <Urllib3HttpNode(http://localhost:9200)> has failed for 2 times in a row, putting on 2 second timeout
[2024-06-14T15:56:13.659+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:56:13.659+0530] {_transport.py:415} WARNING - Retrying request after failure (attempt 1 of 3)
Traceback (most recent call last):
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_transport.py", line 342, in perform_request
    resp = node.perform_request(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_node/_http_urllib3.py", line 202, in perform_request
    raise err from None
elastic_transport.ConnectionError: Connection error caused by: NewConnectionError(<urllib3.connection.HTTPConnection object at 0x7f385ba48730>: Failed to establish a new connection: [Errno 111] Connection refused)
[2024-06-14T15:56:13.660+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:56:13.659+0530] {_transport.py:372} INFO - PUT http://localhost:9200/_bulk [status:N/A duration:0.000s]
[2024-06-14T15:56:13.660+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:56:13.660+0530] {_node_pool.py:249} WARNING - Node <Urllib3HttpNode(http://localhost:9200)> has failed for 3 times in a row, putting on 4 second timeout
[2024-06-14T15:56:13.660+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:56:13.660+0530] {_transport.py:415} WARNING - Retrying request after failure (attempt 2 of 3)
Traceback (most recent call last):
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_transport.py", line 342, in perform_request
    resp = node.perform_request(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_node/_http_urllib3.py", line 202, in perform_request
    raise err from None
elastic_transport.ConnectionError: Connection error caused by: NewConnectionError(<urllib3.connection.HTTPConnection object at 0x7f38642ea050>: Failed to establish a new connection: [Errno 111] Connection refused)
[2024-06-14T15:56:13.661+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:56:13.661+0530] {_transport.py:372} INFO - PUT http://localhost:9200/_bulk [status:N/A duration:0.000s]
[2024-06-14T15:56:13.661+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:56:13.661+0530] {_node_pool.py:249} WARNING - Node <Urllib3HttpNode(http://localhost:9200)> has failed for 4 times in a row, putting on 8 second timeout
[2024-06-14T15:56:13.676+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:56:13.661+0530] {dagbag.py:350} ERROR - Failed to import: /home/wsl/airflow/dags/Collect Data/test3.py
Traceback (most recent call last):
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/wsl/airflow/dags/Collect Data/test3.py", line 95, in <module>
    helpers.bulk(es, actions)
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/helpers/actions.py", line 521, in bulk
    for ok, item in streaming_bulk(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/helpers/actions.py", line 436, in streaming_bulk
    for data, (ok, info) in zip(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/helpers/actions.py", line 339, in _process_bulk_chunk
    resp = client.bulk(*args, operations=bulk_actions, **kwargs)  # type: ignore[arg-type]
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/_sync/client/utils.py", line 446, in wrapped
    return api(*args, **kwargs)
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/_sync/client/__init__.py", line 714, in bulk
    return self.perform_request(  # type: ignore[return-value]
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/_sync/client/_base.py", line 271, in perform_request
    response = self._perform_request(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/_sync/client/_base.py", line 316, in _perform_request
    meta, resp_body = self.transport.perform_request(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_transport.py", line 342, in perform_request
    resp = node.perform_request(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_node/_http_urllib3.py", line 202, in perform_request
    raise err from None
elastic_transport.ConnectionError: Connection error caused by: ConnectionError(Connection error caused by: NewConnectionError(<urllib3.connection.HTTPConnection object at 0x7f38599a6500>: Failed to establish a new connection: [Errno 111] Connection refused))
[2024-06-14T15:56:13.677+0530] {processor.py:842} WARNING - No viable dags retrieved from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T15:56:13.722+0530] {processor.py:183} INFO - Processing /home/wsl/airflow/dags/Collect Data/test3.py took 47.908 seconds
[2024-06-14T15:56:53.243+0530] {processor.py:161} INFO - Started process (PID=79315) to work on /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T15:56:53.246+0530] {processor.py:830} INFO - Processing file /home/wsl/airflow/dags/Collect Data/test3.py for tasks to queue
[2024-06-14T15:56:53.248+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:56:53.247+0530] {dagbag.py:540} INFO - Filling up the DagBag from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T15:57:07.397+0530] {logging_mixin.py:188} INFO - <pyspark.sql.session.SparkSession object at 0x7f3863f18a60>
[2024-06-14T15:57:30.199+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:57:30.199+0530] {_transport.py:372} INFO - PUT http://localhost:9200/_bulk [status:N/A duration:0.001s]
[2024-06-14T15:57:30.199+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:57:30.199+0530] {_node_pool.py:249} WARNING - Node <Urllib3HttpNode(http://localhost:9200)> has failed for 1 times in a row, putting on 1 second timeout
[2024-06-14T15:57:30.200+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:57:30.199+0530] {_transport.py:415} WARNING - Retrying request after failure (attempt 0 of 3)
Traceback (most recent call last):
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_transport.py", line 342, in perform_request
    resp = node.perform_request(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_node/_http_urllib3.py", line 202, in perform_request
    raise err from None
elastic_transport.ConnectionError: Connection error caused by: NewConnectionError(<urllib3.connection.HTTPConnection object at 0x7f38599ba500>: Failed to establish a new connection: [Errno 111] Connection refused)
[2024-06-14T15:57:30.201+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:57:30.201+0530] {_transport.py:372} INFO - PUT http://localhost:9200/_bulk [status:N/A duration:0.000s]
[2024-06-14T15:57:30.201+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:57:30.201+0530] {_node_pool.py:249} WARNING - Node <Urllib3HttpNode(http://localhost:9200)> has failed for 2 times in a row, putting on 2 second timeout
[2024-06-14T15:57:30.201+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:57:30.201+0530] {_transport.py:415} WARNING - Retrying request after failure (attempt 1 of 3)
Traceback (most recent call last):
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_transport.py", line 342, in perform_request
    resp = node.perform_request(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_node/_http_urllib3.py", line 202, in perform_request
    raise err from None
elastic_transport.ConnectionError: Connection error caused by: NewConnectionError(<urllib3.connection.HTTPConnection object at 0x7f3871f74850>: Failed to establish a new connection: [Errno 111] Connection refused)
[2024-06-14T15:57:30.202+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:57:30.202+0530] {_transport.py:372} INFO - PUT http://localhost:9200/_bulk [status:N/A duration:0.000s]
[2024-06-14T15:57:30.202+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:57:30.202+0530] {_node_pool.py:249} WARNING - Node <Urllib3HttpNode(http://localhost:9200)> has failed for 3 times in a row, putting on 4 second timeout
[2024-06-14T15:57:30.203+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:57:30.202+0530] {_transport.py:415} WARNING - Retrying request after failure (attempt 2 of 3)
Traceback (most recent call last):
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_transport.py", line 342, in perform_request
    resp = node.perform_request(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_node/_http_urllib3.py", line 202, in perform_request
    raise err from None
elastic_transport.ConnectionError: Connection error caused by: NewConnectionError(<urllib3.connection.HTTPConnection object at 0x7f38643200d0>: Failed to establish a new connection: [Errno 111] Connection refused)
[2024-06-14T15:57:30.203+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:57:30.203+0530] {_transport.py:372} INFO - PUT http://localhost:9200/_bulk [status:N/A duration:0.000s]
[2024-06-14T15:57:30.204+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:57:30.204+0530] {_node_pool.py:249} WARNING - Node <Urllib3HttpNode(http://localhost:9200)> has failed for 4 times in a row, putting on 8 second timeout
[2024-06-14T15:57:30.206+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:57:30.204+0530] {dagbag.py:350} ERROR - Failed to import: /home/wsl/airflow/dags/Collect Data/test3.py
Traceback (most recent call last):
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/wsl/airflow/dags/Collect Data/test3.py", line 95, in <module>
    helpers.bulk(es, actions)
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/helpers/actions.py", line 521, in bulk
    for ok, item in streaming_bulk(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/helpers/actions.py", line 436, in streaming_bulk
    for data, (ok, info) in zip(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/helpers/actions.py", line 339, in _process_bulk_chunk
    resp = client.bulk(*args, operations=bulk_actions, **kwargs)  # type: ignore[arg-type]
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/_sync/client/utils.py", line 446, in wrapped
    return api(*args, **kwargs)
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/_sync/client/__init__.py", line 714, in bulk
    return self.perform_request(  # type: ignore[return-value]
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/_sync/client/_base.py", line 271, in perform_request
    response = self._perform_request(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/_sync/client/_base.py", line 316, in _perform_request
    meta, resp_body = self.transport.perform_request(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_transport.py", line 342, in perform_request
    resp = node.perform_request(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_node/_http_urllib3.py", line 202, in perform_request
    raise err from None
elastic_transport.ConnectionError: Connection error caused by: ConnectionError(Connection error caused by: NewConnectionError(<urllib3.connection.HTTPConnection object at 0x7f38599ba500>: Failed to establish a new connection: [Errno 111] Connection refused))
[2024-06-14T15:57:30.206+0530] {processor.py:842} WARNING - No viable dags retrieved from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T15:57:30.223+0530] {processor.py:183} INFO - Processing /home/wsl/airflow/dags/Collect Data/test3.py took 36.993 seconds
[2024-06-14T15:58:02.185+0530] {processor.py:161} INFO - Started process (PID=80140) to work on /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T15:58:02.187+0530] {processor.py:830} INFO - Processing file /home/wsl/airflow/dags/Collect Data/test3.py for tasks to queue
[2024-06-14T15:58:02.189+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:58:02.188+0530] {dagbag.py:540} INFO - Filling up the DagBag from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T15:58:12.167+0530] {logging_mixin.py:188} INFO - <pyspark.sql.session.SparkSession object at 0x7f3863f18a60>
[2024-06-14T15:58:27.583+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:58:27.582+0530] {_transport.py:372} INFO - PUT http://localhost:9200/_bulk [status:N/A duration:0.001s]
[2024-06-14T15:58:27.583+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:58:27.583+0530] {_node_pool.py:249} WARNING - Node <Urllib3HttpNode(http://localhost:9200)> has failed for 1 times in a row, putting on 1 second timeout
[2024-06-14T15:58:27.584+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:58:27.583+0530] {_transport.py:415} WARNING - Retrying request after failure (attempt 0 of 3)
Traceback (most recent call last):
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_transport.py", line 342, in perform_request
    resp = node.perform_request(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_node/_http_urllib3.py", line 202, in perform_request
    raise err from None
elastic_transport.ConnectionError: Connection error caused by: NewConnectionError(<urllib3.connection.HTTPConnection object at 0x7f38596f8910>: Failed to establish a new connection: [Errno 111] Connection refused)
[2024-06-14T15:58:27.584+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:58:27.584+0530] {_transport.py:372} INFO - PUT http://localhost:9200/_bulk [status:N/A duration:0.000s]
[2024-06-14T15:58:27.585+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:58:27.585+0530] {_node_pool.py:249} WARNING - Node <Urllib3HttpNode(http://localhost:9200)> has failed for 2 times in a row, putting on 2 second timeout
[2024-06-14T15:58:27.585+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:58:27.585+0530] {_transport.py:415} WARNING - Retrying request after failure (attempt 1 of 3)
Traceback (most recent call last):
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_transport.py", line 342, in perform_request
    resp = node.perform_request(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_node/_http_urllib3.py", line 202, in perform_request
    raise err from None
elastic_transport.ConnectionError: Connection error caused by: NewConnectionError(<urllib3.connection.HTTPConnection object at 0x7f38596f8d60>: Failed to establish a new connection: [Errno 111] Connection refused)
[2024-06-14T15:58:27.586+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:58:27.586+0530] {_transport.py:372} INFO - PUT http://localhost:9200/_bulk [status:N/A duration:0.001s]
[2024-06-14T15:58:27.586+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:58:27.586+0530] {_node_pool.py:249} WARNING - Node <Urllib3HttpNode(http://localhost:9200)> has failed for 3 times in a row, putting on 4 second timeout
[2024-06-14T15:58:27.587+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:58:27.586+0530] {_transport.py:415} WARNING - Retrying request after failure (attempt 2 of 3)
Traceback (most recent call last):
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_transport.py", line 342, in perform_request
    resp = node.perform_request(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_node/_http_urllib3.py", line 202, in perform_request
    raise err from None
elastic_transport.ConnectionError: Connection error caused by: NewConnectionError(<urllib3.connection.HTTPConnection object at 0x7f38596f9000>: Failed to establish a new connection: [Errno 111] Connection refused)
[2024-06-14T15:58:27.588+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:58:27.587+0530] {_transport.py:372} INFO - PUT http://localhost:9200/_bulk [status:N/A duration:0.001s]
[2024-06-14T15:58:27.589+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:58:27.589+0530] {_node_pool.py:249} WARNING - Node <Urllib3HttpNode(http://localhost:9200)> has failed for 4 times in a row, putting on 8 second timeout
[2024-06-14T15:58:27.591+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:58:27.589+0530] {dagbag.py:350} ERROR - Failed to import: /home/wsl/airflow/dags/Collect Data/test3.py
Traceback (most recent call last):
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/wsl/airflow/dags/Collect Data/test3.py", line 95, in <module>
    helpers.bulk(es, actions)
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/helpers/actions.py", line 521, in bulk
    for ok, item in streaming_bulk(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/helpers/actions.py", line 436, in streaming_bulk
    for data, (ok, info) in zip(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/helpers/actions.py", line 339, in _process_bulk_chunk
    resp = client.bulk(*args, operations=bulk_actions, **kwargs)  # type: ignore[arg-type]
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/_sync/client/utils.py", line 446, in wrapped
    return api(*args, **kwargs)
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/_sync/client/__init__.py", line 714, in bulk
    return self.perform_request(  # type: ignore[return-value]
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/_sync/client/_base.py", line 271, in perform_request
    response = self._perform_request(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/_sync/client/_base.py", line 316, in _perform_request
    meta, resp_body = self.transport.perform_request(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_transport.py", line 342, in perform_request
    resp = node.perform_request(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_node/_http_urllib3.py", line 202, in perform_request
    raise err from None
elastic_transport.ConnectionError: Connection error caused by: ConnectionError(Connection error caused by: NewConnectionError(<urllib3.connection.HTTPConnection object at 0x7f38596f8910>: Failed to establish a new connection: [Errno 111] Connection refused))
[2024-06-14T15:58:27.591+0530] {processor.py:842} WARNING - No viable dags retrieved from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T15:58:27.608+0530] {processor.py:183} INFO - Processing /home/wsl/airflow/dags/Collect Data/test3.py took 25.439 seconds
[2024-06-14T15:59:01.875+0530] {processor.py:161} INFO - Started process (PID=80918) to work on /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T15:59:01.877+0530] {processor.py:830} INFO - Processing file /home/wsl/airflow/dags/Collect Data/test3.py for tasks to queue
[2024-06-14T15:59:01.878+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:59:01.877+0530] {dagbag.py:540} INFO - Filling up the DagBag from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T15:59:11.407+0530] {logging_mixin.py:188} INFO - <pyspark.sql.session.SparkSession object at 0x7f3863f1ca60>
[2024-06-14T15:59:26.716+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:59:26.715+0530] {_transport.py:372} INFO - PUT http://localhost:9200/_bulk [status:N/A duration:0.001s]
[2024-06-14T15:59:26.716+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:59:26.716+0530] {_node_pool.py:249} WARNING - Node <Urllib3HttpNode(http://localhost:9200)> has failed for 1 times in a row, putting on 1 second timeout
[2024-06-14T15:59:26.717+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:59:26.716+0530] {_transport.py:415} WARNING - Retrying request after failure (attempt 0 of 3)
Traceback (most recent call last):
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_transport.py", line 342, in perform_request
    resp = node.perform_request(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_node/_http_urllib3.py", line 202, in perform_request
    raise err from None
elastic_transport.ConnectionError: Connection error caused by: NewConnectionError(<urllib3.connection.HTTPConnection object at 0x7f38599a6500>: Failed to establish a new connection: [Errno 111] Connection refused)
[2024-06-14T15:59:26.718+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:59:26.718+0530] {_transport.py:372} INFO - PUT http://localhost:9200/_bulk [status:N/A duration:0.001s]
[2024-06-14T15:59:26.718+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:59:26.718+0530] {_node_pool.py:249} WARNING - Node <Urllib3HttpNode(http://localhost:9200)> has failed for 2 times in a row, putting on 2 second timeout
[2024-06-14T15:59:26.718+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:59:26.718+0530] {_transport.py:415} WARNING - Retrying request after failure (attempt 1 of 3)
Traceback (most recent call last):
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_transport.py", line 342, in perform_request
    resp = node.perform_request(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_node/_http_urllib3.py", line 202, in perform_request
    raise err from None
elastic_transport.ConnectionError: Connection error caused by: NewConnectionError(<urllib3.connection.HTTPConnection object at 0x7f3871f78850>: Failed to establish a new connection: [Errno 111] Connection refused)
[2024-06-14T15:59:26.719+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:59:26.719+0530] {_transport.py:372} INFO - PUT http://localhost:9200/_bulk [status:N/A duration:0.000s]
[2024-06-14T15:59:26.719+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:59:26.719+0530] {_node_pool.py:249} WARNING - Node <Urllib3HttpNode(http://localhost:9200)> has failed for 3 times in a row, putting on 4 second timeout
[2024-06-14T15:59:26.720+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:59:26.720+0530] {_transport.py:415} WARNING - Retrying request after failure (attempt 2 of 3)
Traceback (most recent call last):
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_transport.py", line 342, in perform_request
    resp = node.perform_request(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_node/_http_urllib3.py", line 202, in perform_request
    raise err from None
elastic_transport.ConnectionError: Connection error caused by: NewConnectionError(<urllib3.connection.HTTPConnection object at 0x7f38644c4a30>: Failed to establish a new connection: [Errno 111] Connection refused)
[2024-06-14T15:59:26.721+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:59:26.720+0530] {_transport.py:372} INFO - PUT http://localhost:9200/_bulk [status:N/A duration:0.000s]
[2024-06-14T15:59:26.721+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:59:26.721+0530] {_node_pool.py:249} WARNING - Node <Urllib3HttpNode(http://localhost:9200)> has failed for 4 times in a row, putting on 8 second timeout
[2024-06-14T15:59:26.723+0530] {logging_mixin.py:188} INFO - [2024-06-14T15:59:26.722+0530] {dagbag.py:350} ERROR - Failed to import: /home/wsl/airflow/dags/Collect Data/test3.py
Traceback (most recent call last):
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/wsl/airflow/dags/Collect Data/test3.py", line 95, in <module>
    helpers.bulk(es, actions)
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/helpers/actions.py", line 521, in bulk
    for ok, item in streaming_bulk(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/helpers/actions.py", line 436, in streaming_bulk
    for data, (ok, info) in zip(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/helpers/actions.py", line 339, in _process_bulk_chunk
    resp = client.bulk(*args, operations=bulk_actions, **kwargs)  # type: ignore[arg-type]
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/_sync/client/utils.py", line 446, in wrapped
    return api(*args, **kwargs)
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/_sync/client/__init__.py", line 714, in bulk
    return self.perform_request(  # type: ignore[return-value]
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/_sync/client/_base.py", line 271, in perform_request
    response = self._perform_request(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/_sync/client/_base.py", line 316, in _perform_request
    meta, resp_body = self.transport.perform_request(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_transport.py", line 342, in perform_request
    resp = node.perform_request(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_node/_http_urllib3.py", line 202, in perform_request
    raise err from None
elastic_transport.ConnectionError: Connection error caused by: ConnectionError(Connection error caused by: NewConnectionError(<urllib3.connection.HTTPConnection object at 0x7f38599a6500>: Failed to establish a new connection: [Errno 111] Connection refused))
[2024-06-14T15:59:26.724+0530] {processor.py:842} WARNING - No viable dags retrieved from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T15:59:26.761+0530] {processor.py:183} INFO - Processing /home/wsl/airflow/dags/Collect Data/test3.py took 24.895 seconds
[2024-06-14T16:03:15.704+0530] {processor.py:161} INFO - Started process (PID=81826) to work on /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T16:03:15.706+0530] {processor.py:830} INFO - Processing file /home/wsl/airflow/dags/Collect Data/test3.py for tasks to queue
[2024-06-14T16:03:15.707+0530] {logging_mixin.py:188} INFO - [2024-06-14T16:03:15.707+0530] {dagbag.py:540} INFO - Filling up the DagBag from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T16:03:28.860+0530] {logging_mixin.py:188} INFO - <pyspark.sql.session.SparkSession object at 0x7f3871fd8a60>
[2024-06-14T16:03:50.327+0530] {logging_mixin.py:188} INFO - [2024-06-14T16:03:50.327+0530] {_transport.py:372} INFO - PUT http://localhost:9200/_bulk [status:N/A duration:0.001s]
[2024-06-14T16:03:50.327+0530] {logging_mixin.py:188} INFO - [2024-06-14T16:03:50.327+0530] {_node_pool.py:249} WARNING - Node <Urllib3HttpNode(http://localhost:9200)> has failed for 1 times in a row, putting on 1 second timeout
[2024-06-14T16:03:50.437+0530] {logging_mixin.py:188} INFO - [2024-06-14T16:03:50.328+0530] {_transport.py:415} WARNING - Retrying request after failure (attempt 0 of 3)
Traceback (most recent call last):
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_transport.py", line 342, in perform_request
    resp = node.perform_request(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_node/_http_urllib3.py", line 202, in perform_request
    raise err from None
elastic_transport.ConnectionError: Connection error caused by: NewConnectionError(<urllib3.connection.HTTPConnection object at 0x7f3859704910>: Failed to establish a new connection: [Errno 111] Connection refused)
[2024-06-14T16:03:50.439+0530] {logging_mixin.py:188} INFO - [2024-06-14T16:03:50.439+0530] {_transport.py:372} INFO - PUT http://localhost:9200/_bulk [status:N/A duration:0.001s]
[2024-06-14T16:03:50.440+0530] {logging_mixin.py:188} INFO - [2024-06-14T16:03:50.440+0530] {_node_pool.py:249} WARNING - Node <Urllib3HttpNode(http://localhost:9200)> has failed for 2 times in a row, putting on 2 second timeout
[2024-06-14T16:03:50.441+0530] {logging_mixin.py:188} INFO - [2024-06-14T16:03:50.441+0530] {_transport.py:415} WARNING - Retrying request after failure (attempt 1 of 3)
Traceback (most recent call last):
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_transport.py", line 342, in perform_request
    resp = node.perform_request(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_node/_http_urllib3.py", line 202, in perform_request
    raise err from None
elastic_transport.ConnectionError: Connection error caused by: NewConnectionError(<urllib3.connection.HTTPConnection object at 0x7f3859704d60>: Failed to establish a new connection: [Errno 111] Connection refused)
[2024-06-14T16:03:50.443+0530] {logging_mixin.py:188} INFO - [2024-06-14T16:03:50.443+0530] {_transport.py:372} INFO - PUT http://localhost:9200/_bulk [status:N/A duration:0.001s]
[2024-06-14T16:03:50.444+0530] {logging_mixin.py:188} INFO - [2024-06-14T16:03:50.443+0530] {_node_pool.py:249} WARNING - Node <Urllib3HttpNode(http://localhost:9200)> has failed for 3 times in a row, putting on 4 second timeout
[2024-06-14T16:03:50.445+0530] {logging_mixin.py:188} INFO - [2024-06-14T16:03:50.444+0530] {_transport.py:415} WARNING - Retrying request after failure (attempt 2 of 3)
Traceback (most recent call last):
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_transport.py", line 342, in perform_request
    resp = node.perform_request(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_node/_http_urllib3.py", line 202, in perform_request
    raise err from None
elastic_transport.ConnectionError: Connection error caused by: NewConnectionError(<urllib3.connection.HTTPConnection object at 0x7f3859705000>: Failed to establish a new connection: [Errno 111] Connection refused)
[2024-06-14T16:03:50.447+0530] {logging_mixin.py:188} INFO - [2024-06-14T16:03:50.446+0530] {_transport.py:372} INFO - PUT http://localhost:9200/_bulk [status:N/A duration:0.001s]
[2024-06-14T16:03:50.447+0530] {logging_mixin.py:188} INFO - [2024-06-14T16:03:50.447+0530] {_node_pool.py:249} WARNING - Node <Urllib3HttpNode(http://localhost:9200)> has failed for 4 times in a row, putting on 8 second timeout
[2024-06-14T16:03:50.594+0530] {logging_mixin.py:188} INFO - [2024-06-14T16:03:50.448+0530] {dagbag.py:350} ERROR - Failed to import: /home/wsl/airflow/dags/Collect Data/test3.py
Traceback (most recent call last):
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/wsl/airflow/dags/Collect Data/test3.py", line 95, in <module>
    helpers.bulk(es, actions)
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/helpers/actions.py", line 521, in bulk
    for ok, item in streaming_bulk(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/helpers/actions.py", line 436, in streaming_bulk
    for data, (ok, info) in zip(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/helpers/actions.py", line 339, in _process_bulk_chunk
    resp = client.bulk(*args, operations=bulk_actions, **kwargs)  # type: ignore[arg-type]
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/_sync/client/utils.py", line 446, in wrapped
    return api(*args, **kwargs)
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/_sync/client/__init__.py", line 714, in bulk
    return self.perform_request(  # type: ignore[return-value]
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/_sync/client/_base.py", line 271, in perform_request
    response = self._perform_request(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elasticsearch/_sync/client/_base.py", line 316, in _perform_request
    meta, resp_body = self.transport.perform_request(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_transport.py", line 342, in perform_request
    resp = node.perform_request(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/elastic_transport/_node/_http_urllib3.py", line 202, in perform_request
    raise err from None
elastic_transport.ConnectionError: Connection error caused by: ConnectionError(Connection error caused by: NewConnectionError(<urllib3.connection.HTTPConnection object at 0x7f3859704910>: Failed to establish a new connection: [Errno 111] Connection refused))
[2024-06-14T16:03:50.595+0530] {processor.py:842} WARNING - No viable dags retrieved from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T16:03:50.718+0530] {processor.py:183} INFO - Processing /home/wsl/airflow/dags/Collect Data/test3.py took 35.021 seconds
[2024-06-14T17:07:30.759+0530] {processor.py:161} INFO - Started process (PID=10306) to work on /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T17:07:30.763+0530] {processor.py:830} INFO - Processing file /home/wsl/airflow/dags/Collect Data/test3.py for tasks to queue
[2024-06-14T17:07:30.765+0530] {logging_mixin.py:188} INFO - [2024-06-14T17:07:30.764+0530] {dagbag.py:540} INFO - Filling up the DagBag from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T17:14:04.607+0530] {logging_mixin.py:188} INFO - <pyspark.sql.session.SparkSession object at 0x7f8f30d0b9d0>
[2024-06-14T17:14:23.282+0530] {processor.py:842} WARNING - No viable dags retrieved from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T17:14:23.301+0530] {processor.py:183} INFO - Processing /home/wsl/airflow/dags/Collect Data/test3.py took 412.548 seconds
[2024-06-14T17:37:42.324+0530] {processor.py:161} INFO - Started process (PID=18270) to work on /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T17:37:42.332+0530] {processor.py:830} INFO - Processing file /home/wsl/airflow/dags/Collect Data/test3.py for tasks to queue
[2024-06-14T17:37:42.333+0530] {logging_mixin.py:188} INFO - [2024-06-14T17:37:42.332+0530] {dagbag.py:540} INFO - Filling up the DagBag from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T17:38:33.801+0530] {logging_mixin.py:188} INFO - <pyspark.sql.session.SparkSession object at 0x7fd3cd6bc610>
[2024-06-14T17:44:09.336+0530] {processor.py:842} WARNING - No viable dags retrieved from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T17:44:09.346+0530] {processor.py:183} INFO - Processing /home/wsl/airflow/dags/Collect Data/test3.py took 387.050 seconds
[2024-06-14T17:45:41.519+0530] {processor.py:161} INFO - Started process (PID=20277) to work on /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T17:45:41.521+0530] {processor.py:830} INFO - Processing file /home/wsl/airflow/dags/Collect Data/test3.py for tasks to queue
[2024-06-14T17:45:41.523+0530] {logging_mixin.py:188} INFO - [2024-06-14T17:45:41.522+0530] {dagbag.py:540} INFO - Filling up the DagBag from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T17:45:54.638+0530] {logging_mixin.py:188} INFO - <pyspark.sql.session.SparkSession object at 0x7fd3cd6bc6a0>
[2024-06-14T17:46:13.899+0530] {processor.py:842} WARNING - No viable dags retrieved from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T17:46:13.909+0530] {processor.py:183} INFO - Processing /home/wsl/airflow/dags/Collect Data/test3.py took 32.400 seconds
[2024-06-14T17:46:59.906+0530] {processor.py:161} INFO - Started process (PID=21212) to work on /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T17:46:59.908+0530] {processor.py:830} INFO - Processing file /home/wsl/airflow/dags/Collect Data/test3.py for tasks to queue
[2024-06-14T17:46:59.910+0530] {logging_mixin.py:188} INFO - [2024-06-14T17:46:59.909+0530] {dagbag.py:540} INFO - Filling up the DagBag from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T17:47:18.256+0530] {logging_mixin.py:188} INFO - <pyspark.sql.session.SparkSession object at 0x7fd3cd6bc6a0>
[2024-06-14T17:47:39.464+0530] {processor.py:842} WARNING - No viable dags retrieved from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T17:47:39.471+0530] {processor.py:183} INFO - Processing /home/wsl/airflow/dags/Collect Data/test3.py took 39.575 seconds
[2024-06-14T17:48:16.628+0530] {processor.py:161} INFO - Started process (PID=22092) to work on /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T17:48:16.629+0530] {processor.py:830} INFO - Processing file /home/wsl/airflow/dags/Collect Data/test3.py for tasks to queue
[2024-06-14T17:48:16.630+0530] {logging_mixin.py:188} INFO - [2024-06-14T17:48:16.630+0530] {dagbag.py:540} INFO - Filling up the DagBag from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T17:48:27.702+0530] {logging_mixin.py:188} INFO - <pyspark.sql.session.SparkSession object at 0x7fd3cd776e60>
[2024-06-14T17:48:44.195+0530] {processor.py:842} WARNING - No viable dags retrieved from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T17:48:44.203+0530] {processor.py:183} INFO - Processing /home/wsl/airflow/dags/Collect Data/test3.py took 27.582 seconds
[2024-06-14T17:49:27.268+0530] {processor.py:161} INFO - Started process (PID=22979) to work on /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T17:49:27.270+0530] {processor.py:830} INFO - Processing file /home/wsl/airflow/dags/Collect Data/test3.py for tasks to queue
[2024-06-14T17:49:27.272+0530] {logging_mixin.py:188} INFO - [2024-06-14T17:49:27.271+0530] {dagbag.py:540} INFO - Filling up the DagBag from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T17:49:46.034+0530] {logging_mixin.py:188} INFO - <pyspark.sql.session.SparkSession object at 0x7fd3cd6bc730>
[2024-06-14T17:50:05.563+0530] {processor.py:842} WARNING - No viable dags retrieved from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T17:50:05.612+0530] {processor.py:183} INFO - Processing /home/wsl/airflow/dags/Collect Data/test3.py took 38.350 seconds
[2024-06-14T17:50:57.279+0530] {processor.py:161} INFO - Started process (PID=24002) to work on /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T17:50:57.282+0530] {processor.py:830} INFO - Processing file /home/wsl/airflow/dags/Collect Data/test3.py for tasks to queue
[2024-06-14T17:50:57.284+0530] {logging_mixin.py:188} INFO - [2024-06-14T17:50:57.283+0530] {dagbag.py:540} INFO - Filling up the DagBag from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T17:51:05.998+0530] {logging_mixin.py:188} INFO - <pyspark.sql.session.SparkSession object at 0x7fd3cd77eef0>
[2024-06-14T17:51:29.660+0530] {logging_mixin.py:188} INFO - [2024-06-14T17:51:29.660+0530] {dagbag.py:350} ERROR - Failed to import: /home/wsl/airflow/dags/Collect Data/test3.py
Traceback (most recent call last):
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/wsl/airflow/dags/Collect Data/test3.py", line 86, in <module>
    es = Elasticsearch(
TypeError: Elasticsearch.__init__() got an unexpected keyword argument 'scheme'
[2024-06-14T17:51:29.661+0530] {processor.py:842} WARNING - No viable dags retrieved from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T17:51:35.112+0530] {processor.py:183} INFO - Processing /home/wsl/airflow/dags/Collect Data/test3.py took 37.844 seconds
[2024-06-14T17:53:33.296+0530] {processor.py:161} INFO - Started process (PID=25695) to work on /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T17:53:33.298+0530] {processor.py:830} INFO - Processing file /home/wsl/airflow/dags/Collect Data/test3.py for tasks to queue
[2024-06-14T17:53:33.300+0530] {logging_mixin.py:188} INFO - [2024-06-14T17:53:33.299+0530] {dagbag.py:540} INFO - Filling up the DagBag from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T17:53:43.119+0530] {logging_mixin.py:188} INFO - <pyspark.sql.session.SparkSession object at 0x7fd3cd6bc790>
[2024-06-14T17:53:57.735+0530] {logging_mixin.py:188} INFO - [2024-06-14T17:53:57.735+0530] {dagbag.py:350} ERROR - Failed to import: /home/wsl/airflow/dags/Collect Data/test3.py
Traceback (most recent call last):
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/wsl/airflow/dags/Collect Data/test3.py", line 86, in <module>
    es = Elasticsearch(
TypeError: Elasticsearch.__init__() got an unexpected keyword argument 'scheme'
[2024-06-14T17:53:57.736+0530] {processor.py:842} WARNING - No viable dags retrieved from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T17:53:57.751+0530] {processor.py:183} INFO - Processing /home/wsl/airflow/dags/Collect Data/test3.py took 24.466 seconds
[2024-06-14T17:54:49.817+0530] {processor.py:161} INFO - Started process (PID=26639) to work on /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T17:54:49.871+0530] {processor.py:830} INFO - Processing file /home/wsl/airflow/dags/Collect Data/test3.py for tasks to queue
[2024-06-14T17:54:49.873+0530] {logging_mixin.py:188} INFO - [2024-06-14T17:54:49.872+0530] {dagbag.py:540} INFO - Filling up the DagBag from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T17:54:59.824+0530] {logging_mixin.py:188} INFO - <pyspark.sql.session.SparkSession object at 0x7fd3cd77f520>
[2024-06-14T17:55:16.928+0530] {logging_mixin.py:188} INFO - [2024-06-14T17:55:16.927+0530] {dagbag.py:350} ERROR - Failed to import: /home/wsl/airflow/dags/Collect Data/test3.py
Traceback (most recent call last):
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/wsl/airflow/dags/Collect Data/test3.py", line 86, in <module>
    es = Elasticsearch(
TypeError: Elasticsearch.__init__() got an unexpected keyword argument 'scheme'
[2024-06-14T17:55:16.928+0530] {processor.py:842} WARNING - No viable dags retrieved from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T17:55:16.947+0530] {processor.py:183} INFO - Processing /home/wsl/airflow/dags/Collect Data/test3.py took 27.149 seconds
[2024-06-14T17:56:08.048+0530] {processor.py:161} INFO - Started process (PID=27601) to work on /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T17:56:08.061+0530] {processor.py:830} INFO - Processing file /home/wsl/airflow/dags/Collect Data/test3.py for tasks to queue
[2024-06-14T17:56:08.063+0530] {logging_mixin.py:188} INFO - [2024-06-14T17:56:08.062+0530] {dagbag.py:540} INFO - Filling up the DagBag from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T17:56:23.642+0530] {logging_mixin.py:188} INFO - <pyspark.sql.session.SparkSession object at 0x7fd3cd6bc790>
[2024-06-14T17:56:42.195+0530] {logging_mixin.py:188} INFO - [2024-06-14T17:56:42.194+0530] {dagbag.py:350} ERROR - Failed to import: /home/wsl/airflow/dags/Collect Data/test3.py
Traceback (most recent call last):
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/wsl/airflow/dags/Collect Data/test3.py", line 86, in <module>
    es = Elasticsearch(
TypeError: Elasticsearch.__init__() got an unexpected keyword argument 'scheme'
[2024-06-14T17:56:42.196+0530] {processor.py:842} WARNING - No viable dags retrieved from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T17:56:51.041+0530] {processor.py:183} INFO - Processing /home/wsl/airflow/dags/Collect Data/test3.py took 43.002 seconds
[2024-06-14T17:58:11.685+0530] {processor.py:161} INFO - Started process (PID=28988) to work on /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T17:58:12.173+0530] {processor.py:830} INFO - Processing file /home/wsl/airflow/dags/Collect Data/test3.py for tasks to queue
[2024-06-14T17:58:12.176+0530] {logging_mixin.py:188} INFO - [2024-06-14T17:58:12.175+0530] {dagbag.py:540} INFO - Filling up the DagBag from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T17:58:25.473+0530] {logging_mixin.py:188} INFO - <pyspark.sql.session.SparkSession object at 0x7fd3cd77b640>
[2024-06-14T17:58:39.873+0530] {logging_mixin.py:188} INFO - [2024-06-14T17:58:39.872+0530] {dagbag.py:350} ERROR - Failed to import: /home/wsl/airflow/dags/Collect Data/test3.py
Traceback (most recent call last):
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/wsl/airflow/dags/Collect Data/test3.py", line 86, in <module>
    es = Elasticsearch(
TypeError: Elasticsearch.__init__() got an unexpected keyword argument 'scheme'
[2024-06-14T17:58:39.873+0530] {processor.py:842} WARNING - No viable dags retrieved from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T17:58:39.989+0530] {processor.py:183} INFO - Processing /home/wsl/airflow/dags/Collect Data/test3.py took 28.312 seconds
[2024-06-14T17:59:42.077+0530] {processor.py:161} INFO - Started process (PID=30015) to work on /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T17:59:42.080+0530] {processor.py:830} INFO - Processing file /home/wsl/airflow/dags/Collect Data/test3.py for tasks to queue
[2024-06-14T17:59:42.082+0530] {logging_mixin.py:188} INFO - [2024-06-14T17:59:42.082+0530] {dagbag.py:540} INFO - Filling up the DagBag from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T17:59:51.205+0530] {logging_mixin.py:188} INFO - <pyspark.sql.session.SparkSession object at 0x7fd3d982a4d0>
[2024-06-14T18:00:08.131+0530] {logging_mixin.py:188} INFO - [2024-06-14T18:00:08.130+0530] {dagbag.py:350} ERROR - Failed to import: /home/wsl/airflow/dags/Collect Data/test3.py
Traceback (most recent call last):
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/wsl/airflow/dags/Collect Data/test3.py", line 86, in <module>
    es = Elasticsearch(
TypeError: Elasticsearch.__init__() got an unexpected keyword argument 'scheme'
[2024-06-14T18:00:08.132+0530] {processor.py:842} WARNING - No viable dags retrieved from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T18:00:12.049+0530] {processor.py:183} INFO - Processing /home/wsl/airflow/dags/Collect Data/test3.py took 29.987 seconds
[2024-06-14T18:01:01.267+0530] {processor.py:161} INFO - Started process (PID=30921) to work on /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T18:01:01.269+0530] {processor.py:830} INFO - Processing file /home/wsl/airflow/dags/Collect Data/test3.py for tasks to queue
[2024-06-14T18:01:01.271+0530] {logging_mixin.py:188} INFO - [2024-06-14T18:01:01.270+0530] {dagbag.py:540} INFO - Filling up the DagBag from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T18:01:18.024+0530] {logging_mixin.py:188} INFO - <pyspark.sql.session.SparkSession object at 0x7fd3db64ef50>
[2024-06-14T18:01:41.942+0530] {processor.py:842} WARNING - No viable dags retrieved from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T18:01:42.044+0530] {processor.py:183} INFO - Processing /home/wsl/airflow/dags/Collect Data/test3.py took 40.790 seconds
[2024-06-14T18:05:02.568+0530] {processor.py:161} INFO - Started process (PID=32807) to work on /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T18:05:02.570+0530] {processor.py:830} INFO - Processing file /home/wsl/airflow/dags/Collect Data/test3.py for tasks to queue
[2024-06-14T18:05:02.576+0530] {logging_mixin.py:188} INFO - [2024-06-14T18:05:02.576+0530] {dagbag.py:540} INFO - Filling up the DagBag from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T18:05:40.101+0530] {logging_mixin.py:188} INFO - <pyspark.sql.session.SparkSession object at 0x7f8167a0beb0>
[2024-06-14T18:06:23.664+0530] {processor.py:842} WARNING - No viable dags retrieved from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T18:06:23.675+0530] {processor.py:183} INFO - Processing /home/wsl/airflow/dags/Collect Data/test3.py took 81.123 seconds
[2024-06-14T18:08:00.754+0530] {processor.py:161} INFO - Started process (PID=34409) to work on /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T18:08:00.755+0530] {processor.py:830} INFO - Processing file /home/wsl/airflow/dags/Collect Data/test3.py for tasks to queue
[2024-06-14T18:08:00.757+0530] {logging_mixin.py:188} INFO - [2024-06-14T18:08:00.757+0530] {dagbag.py:540} INFO - Filling up the DagBag from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T18:08:16.676+0530] {logging_mixin.py:188} INFO - <pyspark.sql.session.SparkSession object at 0x7f81677bada0>
[2024-06-14T18:08:47.919+0530] {processor.py:842} WARNING - No viable dags retrieved from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T18:08:47.927+0530] {processor.py:183} INFO - Processing /home/wsl/airflow/dags/Collect Data/test3.py took 47.180 seconds
[2024-06-14T18:10:11.499+0530] {processor.py:161} INFO - Started process (PID=35741) to work on /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T18:10:11.501+0530] {processor.py:830} INFO - Processing file /home/wsl/airflow/dags/Collect Data/test3.py for tasks to queue
[2024-06-14T18:10:11.503+0530] {logging_mixin.py:188} INFO - [2024-06-14T18:10:11.503+0530] {dagbag.py:540} INFO - Filling up the DagBag from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T18:10:27.720+0530] {logging_mixin.py:188} INFO - <pyspark.sql.session.SparkSession object at 0x7f81677c2e60>
[2024-06-14T18:10:50.205+0530] {processor.py:842} WARNING - No viable dags retrieved from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T18:10:50.213+0530] {processor.py:183} INFO - Processing /home/wsl/airflow/dags/Collect Data/test3.py took 38.733 seconds
[2024-06-14T18:12:22.792+0530] {processor.py:161} INFO - Started process (PID=37158) to work on /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T18:12:22.800+0530] {processor.py:830} INFO - Processing file /home/wsl/airflow/dags/Collect Data/test3.py for tasks to queue
[2024-06-14T18:12:22.803+0530] {logging_mixin.py:188} INFO - [2024-06-14T18:12:22.802+0530] {dagbag.py:540} INFO - Filling up the DagBag from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T18:12:34.327+0530] {logging_mixin.py:188} INFO - <pyspark.sql.session.SparkSession object at 0x7f81677c3070>
[2024-06-14T18:12:52.029+0530] {processor.py:842} WARNING - No viable dags retrieved from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T18:12:53.274+0530] {processor.py:183} INFO - Processing /home/wsl/airflow/dags/Collect Data/test3.py took 30.492 seconds
[2024-06-14T18:14:05.946+0530] {processor.py:161} INFO - Started process (PID=38452) to work on /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T18:14:05.948+0530] {processor.py:830} INFO - Processing file /home/wsl/airflow/dags/Collect Data/test3.py for tasks to queue
[2024-06-14T18:14:05.949+0530] {logging_mixin.py:188} INFO - [2024-06-14T18:14:05.949+0530] {dagbag.py:540} INFO - Filling up the DagBag from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T18:14:26.569+0530] {logging_mixin.py:188} INFO - <pyspark.sql.session.SparkSession object at 0x7f8167641cf0>
[2024-06-14T18:14:43.470+0530] {processor.py:842} WARNING - No viable dags retrieved from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T18:14:43.477+0530] {processor.py:183} INFO - Processing /home/wsl/airflow/dags/Collect Data/test3.py took 37.544 seconds
[2024-06-14T18:16:16.885+0530] {processor.py:161} INFO - Started process (PID=39712) to work on /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T18:16:16.887+0530] {processor.py:830} INFO - Processing file /home/wsl/airflow/dags/Collect Data/test3.py for tasks to queue
[2024-06-14T18:16:16.889+0530] {logging_mixin.py:188} INFO - [2024-06-14T18:16:16.888+0530] {dagbag.py:540} INFO - Filling up the DagBag from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T18:16:30.285+0530] {logging_mixin.py:188} INFO - <pyspark.sql.session.SparkSession object at 0x7f81675d31c0>
[2024-06-14T18:16:57.128+0530] {processor.py:842} WARNING - No viable dags retrieved from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T18:16:57.136+0530] {processor.py:183} INFO - Processing /home/wsl/airflow/dags/Collect Data/test3.py took 40.265 seconds
[2024-06-14T18:24:38.007+0530] {processor.py:161} INFO - Started process (PID=44895) to work on /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T18:24:38.009+0530] {processor.py:830} INFO - Processing file /home/wsl/airflow/dags/Collect Data/test3.py for tasks to queue
[2024-06-14T18:24:38.011+0530] {logging_mixin.py:188} INFO - [2024-06-14T18:24:38.010+0530] {dagbag.py:540} INFO - Filling up the DagBag from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T18:24:56.100+0530] {logging_mixin.py:188} INFO - <pyspark.sql.session.SparkSession object at 0x7fa52ac979d0>
[2024-06-14T18:25:19.757+0530] {processor.py:842} WARNING - No viable dags retrieved from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T18:25:19.764+0530] {processor.py:183} INFO - Processing /home/wsl/airflow/dags/Collect Data/test3.py took 41.771 seconds
[2024-06-14T18:27:18.327+0530] {processor.py:161} INFO - Started process (PID=46582) to work on /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T18:27:18.329+0530] {processor.py:830} INFO - Processing file /home/wsl/airflow/dags/Collect Data/test3.py for tasks to queue
[2024-06-14T18:27:18.331+0530] {logging_mixin.py:188} INFO - [2024-06-14T18:27:18.330+0530] {dagbag.py:540} INFO - Filling up the DagBag from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T18:27:31.124+0530] {logging_mixin.py:188} INFO - <pyspark.sql.session.SparkSession object at 0x7fa52abac370>
[2024-06-14T18:27:51.427+0530] {processor.py:842} WARNING - No viable dags retrieved from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T18:27:51.434+0530] {processor.py:183} INFO - Processing /home/wsl/airflow/dags/Collect Data/test3.py took 33.123 seconds
[2024-06-14T18:28:46.363+0530] {processor.py:161} INFO - Started process (PID=47738) to work on /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T18:28:46.368+0530] {processor.py:830} INFO - Processing file /home/wsl/airflow/dags/Collect Data/test3.py for tasks to queue
[2024-06-14T18:28:46.376+0530] {logging_mixin.py:188} INFO - [2024-06-14T18:28:46.375+0530] {dagbag.py:540} INFO - Filling up the DagBag from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T18:29:00.104+0530] {logging_mixin.py:188} INFO - <pyspark.sql.session.SparkSession object at 0x7fa52abac400>
[2024-06-14T18:29:18.814+0530] {processor.py:842} WARNING - No viable dags retrieved from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T18:29:18.822+0530] {processor.py:183} INFO - Processing /home/wsl/airflow/dags/Collect Data/test3.py took 32.480 seconds
[2024-06-14T18:29:59.617+0530] {processor.py:161} INFO - Started process (PID=48630) to work on /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T18:29:59.618+0530] {processor.py:830} INFO - Processing file /home/wsl/airflow/dags/Collect Data/test3.py for tasks to queue
[2024-06-14T18:29:59.619+0530] {logging_mixin.py:188} INFO - [2024-06-14T18:29:59.619+0530] {dagbag.py:540} INFO - Filling up the DagBag from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T18:30:11.733+0530] {logging_mixin.py:188} INFO - <pyspark.sql.session.SparkSession object at 0x7fa52ac733a0>
[2024-06-14T18:30:40.409+0530] {processor.py:842} WARNING - No viable dags retrieved from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T18:30:45.426+0530] {processor.py:186} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlite3.OperationalError: database is locked

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 843, in process_file
    DagFileProcessor.update_import_errors(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 615, in update_import_errors
    session.execute(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 1665, in execute
    ) = compile_state_cls.orm_pre_session_exec(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/orm/persistence.py", line 1852, in orm_pre_session_exec
    update_options = cls._do_pre_synchronize_fetch(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/orm/persistence.py", line 2088, in _do_pre_synchronize_fetch
    result = session.execute(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) database is locked
[SQL: SELECT import_error.id 
FROM import_error 
WHERE (import_error.filename LIKE ? || '%')]
[parameters: ('/home/wsl/airflow/dags/Collect Data/test3.py',)]
(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2024-06-14T18:31:31.407+0530] {processor.py:161} INFO - Started process (PID=49671) to work on /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T18:31:31.446+0530] {processor.py:830} INFO - Processing file /home/wsl/airflow/dags/Collect Data/test3.py for tasks to queue
[2024-06-14T18:31:31.448+0530] {logging_mixin.py:188} INFO - [2024-06-14T18:31:31.447+0530] {dagbag.py:540} INFO - Filling up the DagBag from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T18:32:01.284+0530] {logging_mixin.py:188} INFO - <pyspark.sql.session.SparkSession object at 0x7fa52ac93b80>
[2024-06-14T18:32:21.558+0530] {processor.py:842} WARNING - No viable dags retrieved from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T18:32:26.579+0530] {processor.py:186} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlite3.OperationalError: database is locked

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 843, in process_file
    DagFileProcessor.update_import_errors(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 615, in update_import_errors
    session.execute(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 1665, in execute
    ) = compile_state_cls.orm_pre_session_exec(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/orm/persistence.py", line 1852, in orm_pre_session_exec
    update_options = cls._do_pre_synchronize_fetch(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/orm/persistence.py", line 2088, in _do_pre_synchronize_fetch
    result = session.execute(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) database is locked
[SQL: SELECT import_error.id 
FROM import_error 
WHERE (import_error.filename LIKE ? || '%')]
[parameters: ('/home/wsl/airflow/dags/Collect Data/test3.py',)]
(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2024-06-14T19:31:03.867+0530] {processor.py:161} INFO - Started process (PID=62155) to work on /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T19:31:03.870+0530] {processor.py:830} INFO - Processing file /home/wsl/airflow/dags/Collect Data/test3.py for tasks to queue
[2024-06-14T19:31:03.871+0530] {logging_mixin.py:188} INFO - [2024-06-14T19:31:03.870+0530] {dagbag.py:540} INFO - Filling up the DagBag from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T19:31:12.914+0530] {logging_mixin.py:188} INFO - <pyspark.sql.session.SparkSession object at 0x7f1c591de080>
[2024-06-14T19:31:30.810+0530] {logging_mixin.py:188} INFO - Data saved successfully as Parquet file at /home/wsl/airflow/dags/Collect Data/world.parquet
[2024-06-14T19:31:30.811+0530] {processor.py:842} WARNING - No viable dags retrieved from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T19:31:30.830+0530] {processor.py:183} INFO - Processing /home/wsl/airflow/dags/Collect Data/test3.py took 26.968 seconds
[2024-06-14T19:32:36.657+0530] {processor.py:161} INFO - Started process (PID=63331) to work on /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T19:32:36.659+0530] {processor.py:830} INFO - Processing file /home/wsl/airflow/dags/Collect Data/test3.py for tasks to queue
[2024-06-14T19:32:36.661+0530] {logging_mixin.py:188} INFO - [2024-06-14T19:32:36.660+0530] {dagbag.py:540} INFO - Filling up the DagBag from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T19:32:42.879+0530] {logging_mixin.py:188} INFO - <pyspark.sql.session.SparkSession object at 0x7f1c59206c80>
[2024-06-14T19:32:56.865+0530] {logging_mixin.py:188} INFO - Data saved successfully as Parquet file at /home/wsl/airflow/dags/Collect Data/world.parquet
[2024-06-14T19:32:56.866+0530] {processor.py:842} WARNING - No viable dags retrieved from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T19:32:56.885+0530] {processor.py:183} INFO - Processing /home/wsl/airflow/dags/Collect Data/test3.py took 20.237 seconds
[2024-06-14T19:33:36.817+0530] {processor.py:161} INFO - Started process (PID=64149) to work on /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T19:33:36.820+0530] {processor.py:830} INFO - Processing file /home/wsl/airflow/dags/Collect Data/test3.py for tasks to queue
[2024-06-14T19:33:36.821+0530] {logging_mixin.py:188} INFO - [2024-06-14T19:33:36.821+0530] {dagbag.py:540} INFO - Filling up the DagBag from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T19:33:44.067+0530] {logging_mixin.py:188} INFO - <pyspark.sql.session.SparkSession object at 0x7f1c59206b60>
[2024-06-14T19:34:01.611+0530] {logging_mixin.py:188} INFO - Data saved successfully as Parquet file at /home/wsl/airflow/dags/Collect Data/world.parquet
[2024-06-14T19:34:01.612+0530] {processor.py:842} WARNING - No viable dags retrieved from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T19:34:01.648+0530] {processor.py:183} INFO - Processing /home/wsl/airflow/dags/Collect Data/test3.py took 24.844 seconds
[2024-06-14T19:34:34.381+0530] {processor.py:161} INFO - Started process (PID=65000) to work on /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T19:34:34.383+0530] {processor.py:830} INFO - Processing file /home/wsl/airflow/dags/Collect Data/test3.py for tasks to queue
[2024-06-14T19:34:34.384+0530] {logging_mixin.py:188} INFO - [2024-06-14T19:34:34.383+0530] {dagbag.py:540} INFO - Filling up the DagBag from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T19:34:40.521+0530] {logging_mixin.py:188} INFO - <pyspark.sql.session.SparkSession object at 0x7f1c59206a40>
[2024-06-14T19:34:54.481+0530] {logging_mixin.py:188} INFO - Data saved successfully as Parquet file at /home/wsl/airflow/dags/Collect Data/world.parquet
[2024-06-14T19:34:54.482+0530] {processor.py:842} WARNING - No viable dags retrieved from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T19:34:54.499+0530] {processor.py:183} INFO - Processing /home/wsl/airflow/dags/Collect Data/test3.py took 20.124 seconds
[2024-06-14T19:35:39.491+0530] {processor.py:161} INFO - Started process (PID=65785) to work on /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T19:35:39.492+0530] {processor.py:830} INFO - Processing file /home/wsl/airflow/dags/Collect Data/test3.py for tasks to queue
[2024-06-14T19:35:39.493+0530] {logging_mixin.py:188} INFO - [2024-06-14T19:35:39.493+0530] {dagbag.py:540} INFO - Filling up the DagBag from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T19:35:46.105+0530] {logging_mixin.py:188} INFO - <pyspark.sql.session.SparkSession object at 0x7f1c592068c0>
[2024-06-14T19:35:59.345+0530] {logging_mixin.py:188} INFO - Data saved successfully as Parquet file at /home/wsl/airflow/dags/Collect Data/world.parquet
[2024-06-14T19:35:59.345+0530] {processor.py:842} WARNING - No viable dags retrieved from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T19:35:59.363+0530] {processor.py:183} INFO - Processing /home/wsl/airflow/dags/Collect Data/test3.py took 19.880 seconds
[2024-06-14T19:36:44.730+0530] {processor.py:161} INFO - Started process (PID=66662) to work on /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T19:36:44.733+0530] {processor.py:830} INFO - Processing file /home/wsl/airflow/dags/Collect Data/test3.py for tasks to queue
[2024-06-14T19:36:44.735+0530] {logging_mixin.py:188} INFO - [2024-06-14T19:36:44.735+0530] {dagbag.py:540} INFO - Filling up the DagBag from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T19:36:52.884+0530] {logging_mixin.py:188} INFO - <pyspark.sql.session.SparkSession object at 0x7f1c59206440>
[2024-06-14T19:37:10.107+0530] {logging_mixin.py:188} INFO - Data saved successfully as Parquet file at /home/wsl/airflow/dags/Collect Data/world.parquet
[2024-06-14T19:37:10.108+0530] {processor.py:842} WARNING - No viable dags retrieved from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T19:37:10.128+0530] {processor.py:183} INFO - Processing /home/wsl/airflow/dags/Collect Data/test3.py took 25.414 seconds
[2024-06-14T19:38:20.024+0530] {processor.py:161} INFO - Started process (PID=67982) to work on /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T19:38:20.026+0530] {processor.py:830} INFO - Processing file /home/wsl/airflow/dags/Collect Data/test3.py for tasks to queue
[2024-06-14T19:38:20.027+0530] {logging_mixin.py:188} INFO - [2024-06-14T19:38:20.026+0530] {dagbag.py:540} INFO - Filling up the DagBag from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T19:38:26.265+0530] {logging_mixin.py:188} INFO - <pyspark.sql.session.SparkSession object at 0x7f1c59206440>
[2024-06-14T19:38:40.103+0530] {logging_mixin.py:188} INFO - Data saved successfully as Parquet file at /home/wsl/airflow/dags/Collect Data/world.parquet
[2024-06-14T19:38:40.104+0530] {processor.py:842} WARNING - No viable dags retrieved from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T19:38:40.121+0530] {processor.py:183} INFO - Processing /home/wsl/airflow/dags/Collect Data/test3.py took 20.112 seconds
[2024-06-14T19:39:22.062+0530] {processor.py:161} INFO - Started process (PID=68873) to work on /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T19:39:22.065+0530] {processor.py:830} INFO - Processing file /home/wsl/airflow/dags/Collect Data/test3.py for tasks to queue
[2024-06-14T19:39:22.066+0530] {logging_mixin.py:188} INFO - [2024-06-14T19:39:22.066+0530] {dagbag.py:540} INFO - Filling up the DagBag from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T19:39:29.972+0530] {logging_mixin.py:188} INFO - <pyspark.sql.session.SparkSession object at 0x7f1c59206b60>
[2024-06-14T19:39:44.765+0530] {logging_mixin.py:188} INFO - Data saved successfully as Parquet file at /home/wsl/airflow/dags/Collect Data/world.parquet
[2024-06-14T19:39:44.766+0530] {processor.py:842} WARNING - No viable dags retrieved from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T19:39:44.792+0530] {processor.py:183} INFO - Processing /home/wsl/airflow/dags/Collect Data/test3.py took 22.740 seconds
[2024-06-14T19:40:17.242+0530] {processor.py:161} INFO - Started process (PID=69399) to work on /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T19:40:17.244+0530] {processor.py:830} INFO - Processing file /home/wsl/airflow/dags/Collect Data/test3.py for tasks to queue
[2024-06-14T19:40:17.246+0530] {logging_mixin.py:188} INFO - [2024-06-14T19:40:17.245+0530] {dagbag.py:540} INFO - Filling up the DagBag from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T19:40:26.743+0530] {logging_mixin.py:188} INFO - <pyspark.sql.session.SparkSession object at 0x7f1c59206c50>
[2024-06-14T19:40:40.994+0530] {logging_mixin.py:188} INFO - Data saved successfully as Parquet file at /home/wsl/airflow/dags/Collect Data/world.parquet
[2024-06-14T19:40:40.995+0530] {processor.py:842} WARNING - No viable dags retrieved from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T19:40:41.021+0530] {processor.py:183} INFO - Processing /home/wsl/airflow/dags/Collect Data/test3.py took 23.790 seconds
[2024-06-14T19:41:25.597+0530] {processor.py:161} INFO - Started process (PID=70499) to work on /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T19:41:25.599+0530] {processor.py:830} INFO - Processing file /home/wsl/airflow/dags/Collect Data/test3.py for tasks to queue
[2024-06-14T19:41:25.600+0530] {logging_mixin.py:188} INFO - [2024-06-14T19:41:25.600+0530] {dagbag.py:540} INFO - Filling up the DagBag from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T19:41:32.131+0530] {logging_mixin.py:188} INFO - <pyspark.sql.session.SparkSession object at 0x7f1c59206c80>
[2024-06-14T19:41:48.038+0530] {logging_mixin.py:188} INFO - Data saved successfully as Parquet file at /home/wsl/airflow/dags/Collect Data/world.parquet
[2024-06-14T19:41:48.039+0530] {processor.py:842} WARNING - No viable dags retrieved from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T19:41:48.058+0530] {processor.py:183} INFO - Processing /home/wsl/airflow/dags/Collect Data/test3.py took 22.467 seconds
[2024-06-14T19:56:55.832+0530] {processor.py:161} INFO - Started process (PID=77641) to work on /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T19:56:55.845+0530] {processor.py:830} INFO - Processing file /home/wsl/airflow/dags/Collect Data/test3.py for tasks to queue
[2024-06-14T19:56:55.846+0530] {logging_mixin.py:188} INFO - [2024-06-14T19:56:55.846+0530] {dagbag.py:540} INFO - Filling up the DagBag from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T19:57:03.751+0530] {logging_mixin.py:188} INFO - <pyspark.sql.session.SparkSession object at 0x7f0c06aae800>
[2024-06-14T19:57:14.083+0530] {processor.py:842} WARNING - No viable dags retrieved from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T19:57:19.113+0530] {processor.py:186} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlite3.OperationalError: database is locked

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 843, in process_file
    DagFileProcessor.update_import_errors(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 615, in update_import_errors
    session.execute(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 1665, in execute
    ) = compile_state_cls.orm_pre_session_exec(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/orm/persistence.py", line 1852, in orm_pre_session_exec
    update_options = cls._do_pre_synchronize_fetch(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/orm/persistence.py", line 2088, in _do_pre_synchronize_fetch
    result = session.execute(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) database is locked
[SQL: SELECT import_error.id 
FROM import_error 
WHERE (import_error.filename LIKE ? || '%')]
[parameters: ('/home/wsl/airflow/dags/Collect Data/test3.py',)]
(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2024-06-14T19:57:58.759+0530] {processor.py:161} INFO - Started process (PID=78096) to work on /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T19:57:58.855+0530] {processor.py:830} INFO - Processing file /home/wsl/airflow/dags/Collect Data/test3.py for tasks to queue
[2024-06-14T19:57:58.857+0530] {logging_mixin.py:188} INFO - [2024-06-14T19:57:58.856+0530] {dagbag.py:540} INFO - Filling up the DagBag from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T19:58:07.790+0530] {logging_mixin.py:188} INFO - <pyspark.sql.session.SparkSession object at 0x7f0c06ab29e0>
[2024-06-14T19:58:15.891+0530] {processor.py:842} WARNING - No viable dags retrieved from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T19:58:15.905+0530] {processor.py:183} INFO - Processing /home/wsl/airflow/dags/Collect Data/test3.py took 17.158 seconds
[2024-06-14T20:00:12.510+0530] {processor.py:161} INFO - Started process (PID=79777) to work on /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T20:00:12.512+0530] {processor.py:830} INFO - Processing file /home/wsl/airflow/dags/Collect Data/test3.py for tasks to queue
[2024-06-14T20:00:12.513+0530] {logging_mixin.py:188} INFO - [2024-06-14T20:00:12.512+0530] {dagbag.py:540} INFO - Filling up the DagBag from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T20:00:18.702+0530] {logging_mixin.py:188} INFO - <pyspark.sql.session.SparkSession object at 0x7f0c06a7df00>
[2024-06-14T20:00:25.884+0530] {processor.py:842} WARNING - No viable dags retrieved from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T20:00:25.897+0530] {processor.py:183} INFO - Processing /home/wsl/airflow/dags/Collect Data/test3.py took 13.400 seconds
[2024-06-14T20:01:05.509+0530] {processor.py:161} INFO - Started process (PID=80458) to work on /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T20:01:05.511+0530] {processor.py:830} INFO - Processing file /home/wsl/airflow/dags/Collect Data/test3.py for tasks to queue
[2024-06-14T20:01:05.513+0530] {logging_mixin.py:188} INFO - [2024-06-14T20:01:05.512+0530] {dagbag.py:540} INFO - Filling up the DagBag from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T20:01:12.915+0530] {logging_mixin.py:188} INFO - <pyspark.sql.session.SparkSession object at 0x7f0c06a7dc90>
[2024-06-14T20:01:20.062+0530] {processor.py:842} WARNING - No viable dags retrieved from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T20:01:20.077+0530] {processor.py:183} INFO - Processing /home/wsl/airflow/dags/Collect Data/test3.py took 14.575 seconds
[2024-06-14T20:01:56.228+0530] {processor.py:161} INFO - Started process (PID=81086) to work on /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T20:01:56.230+0530] {processor.py:830} INFO - Processing file /home/wsl/airflow/dags/Collect Data/test3.py for tasks to queue
[2024-06-14T20:01:56.231+0530] {logging_mixin.py:188} INFO - [2024-06-14T20:01:56.230+0530] {dagbag.py:540} INFO - Filling up the DagBag from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T20:02:03.240+0530] {logging_mixin.py:188} INFO - <pyspark.sql.session.SparkSession object at 0x7f0c06a79e10>
[2024-06-14T20:02:25.491+0530] {logging_mixin.py:188} INFO - Data saved successfully as Parquet file at /home/wsl/airflow/dags/Collect Data/world.parquet
[2024-06-14T20:02:25.492+0530] {processor.py:842} WARNING - No viable dags retrieved from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T20:02:25.743+0530] {processor.py:183} INFO - Processing /home/wsl/airflow/dags/Collect Data/test3.py took 29.523 seconds
[2024-06-14T20:03:41.730+0530] {processor.py:161} INFO - Started process (PID=82477) to work on /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T20:03:41.732+0530] {processor.py:830} INFO - Processing file /home/wsl/airflow/dags/Collect Data/test3.py for tasks to queue
[2024-06-14T20:03:41.733+0530] {logging_mixin.py:188} INFO - [2024-06-14T20:03:41.732+0530] {dagbag.py:540} INFO - Filling up the DagBag from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T20:03:48.259+0530] {logging_mixin.py:188} INFO - <pyspark.sql.session.SparkSession object at 0x7f0c06a96fb0>
[2024-06-14T20:04:02.896+0530] {logging_mixin.py:188} INFO - Data saved successfully as Parquet file at /home/wsl/airflow/dags/Collect Data/world.parquet
[2024-06-14T20:04:02.897+0530] {processor.py:842} WARNING - No viable dags retrieved from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T20:04:02.914+0530] {processor.py:183} INFO - Processing /home/wsl/airflow/dags/Collect Data/test3.py took 21.190 seconds
[2024-06-14T20:05:14.459+0530] {processor.py:161} INFO - Started process (PID=83669) to work on /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T20:05:14.462+0530] {processor.py:830} INFO - Processing file /home/wsl/airflow/dags/Collect Data/test3.py for tasks to queue
[2024-06-14T20:05:14.463+0530] {logging_mixin.py:188} INFO - [2024-06-14T20:05:14.462+0530] {dagbag.py:540} INFO - Filling up the DagBag from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T20:05:23.745+0530] {logging_mixin.py:188} INFO - <pyspark.sql.session.SparkSession object at 0x7f0c06a8a110>
[2024-06-14T20:05:43.316+0530] {logging_mixin.py:188} INFO - Data saved successfully as Parquet file at /home/wsl/airflow/dags/Collect Data/world.parquet
[2024-06-14T20:05:43.317+0530] {processor.py:842} WARNING - No viable dags retrieved from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T20:05:48.345+0530] {processor.py:186} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlite3.OperationalError: database is locked

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 843, in process_file
    DagFileProcessor.update_import_errors(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 615, in update_import_errors
    session.execute(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 1665, in execute
    ) = compile_state_cls.orm_pre_session_exec(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/orm/persistence.py", line 1852, in orm_pre_session_exec
    update_options = cls._do_pre_synchronize_fetch(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/orm/persistence.py", line 2088, in _do_pre_synchronize_fetch
    result = session.execute(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) database is locked
[SQL: SELECT import_error.id 
FROM import_error 
WHERE (import_error.filename LIKE ? || '%')]
[parameters: ('/home/wsl/airflow/dags/Collect Data/test3.py',)]
(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2024-06-14T20:06:31.672+0530] {processor.py:161} INFO - Started process (PID=84592) to work on /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T20:06:31.674+0530] {processor.py:830} INFO - Processing file /home/wsl/airflow/dags/Collect Data/test3.py for tasks to queue
[2024-06-14T20:06:31.676+0530] {logging_mixin.py:188} INFO - [2024-06-14T20:06:31.675+0530] {dagbag.py:540} INFO - Filling up the DagBag from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T20:06:38.741+0530] {logging_mixin.py:188} INFO - <pyspark.sql.session.SparkSession object at 0x7f0c06a8a3b0>
[2024-06-14T20:06:52.803+0530] {logging_mixin.py:188} INFO - Data saved successfully as Parquet file at /home/wsl/airflow/dags/Collect Data/world.parquet
[2024-06-14T20:06:52.803+0530] {processor.py:842} WARNING - No viable dags retrieved from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T20:06:52.819+0530] {processor.py:183} INFO - Processing /home/wsl/airflow/dags/Collect Data/test3.py took 21.157 seconds
[2024-06-14T20:07:25.766+0530] {processor.py:161} INFO - Started process (PID=85364) to work on /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T20:07:25.768+0530] {processor.py:830} INFO - Processing file /home/wsl/airflow/dags/Collect Data/test3.py for tasks to queue
[2024-06-14T20:07:25.769+0530] {logging_mixin.py:188} INFO - [2024-06-14T20:07:25.768+0530] {dagbag.py:540} INFO - Filling up the DagBag from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T20:07:32.153+0530] {logging_mixin.py:188} INFO - <pyspark.sql.session.SparkSession object at 0x7f0c06a8a2c0>
[2024-06-14T20:07:47.288+0530] {logging_mixin.py:188} INFO - Data saved successfully as Parquet file at /home/wsl/airflow/dags/Collect Data/world.parquet
[2024-06-14T20:07:47.289+0530] {processor.py:842} WARNING - No viable dags retrieved from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T20:07:48.034+0530] {processor.py:183} INFO - Processing /home/wsl/airflow/dags/Collect Data/test3.py took 22.280 seconds
[2024-06-14T20:08:38.710+0530] {processor.py:161} INFO - Started process (PID=86263) to work on /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T20:08:38.746+0530] {processor.py:830} INFO - Processing file /home/wsl/airflow/dags/Collect Data/test3.py for tasks to queue
[2024-06-14T20:08:38.751+0530] {logging_mixin.py:188} INFO - [2024-06-14T20:08:38.749+0530] {dagbag.py:540} INFO - Filling up the DagBag from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T20:08:46.386+0530] {logging_mixin.py:188} INFO - <pyspark.sql.session.SparkSession object at 0x7f0c06a8ab90>
[2024-06-14T20:09:00.142+0530] {logging_mixin.py:188} INFO - Data saved successfully as Parquet file at /home/wsl/airflow/dags/Collect Data/world.parquet
[2024-06-14T20:09:00.143+0530] {processor.py:842} WARNING - No viable dags retrieved from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T20:09:00.167+0530] {processor.py:183} INFO - Processing /home/wsl/airflow/dags/Collect Data/test3.py took 21.469 seconds
[2024-06-14T20:09:39.009+0530] {processor.py:161} INFO - Started process (PID=87147) to work on /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T20:09:39.011+0530] {processor.py:830} INFO - Processing file /home/wsl/airflow/dags/Collect Data/test3.py for tasks to queue
[2024-06-14T20:09:39.013+0530] {logging_mixin.py:188} INFO - [2024-06-14T20:09:39.012+0530] {dagbag.py:540} INFO - Filling up the DagBag from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T20:09:46.516+0530] {logging_mixin.py:188} INFO - <pyspark.sql.session.SparkSession object at 0x7f0c06a8ac50>
[2024-06-14T20:10:00.930+0530] {logging_mixin.py:188} INFO - Data saved successfully as Parquet file at /home/wsl/airflow/dags/Collect Data/world.parquet
[2024-06-14T20:10:00.931+0530] {processor.py:842} WARNING - No viable dags retrieved from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T20:10:00.979+0530] {processor.py:183} INFO - Processing /home/wsl/airflow/dags/Collect Data/test3.py took 21.983 seconds
[2024-06-14T20:10:47.352+0530] {processor.py:161} INFO - Started process (PID=88080) to work on /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T20:10:47.354+0530] {processor.py:830} INFO - Processing file /home/wsl/airflow/dags/Collect Data/test3.py for tasks to queue
[2024-06-14T20:10:47.355+0530] {logging_mixin.py:188} INFO - [2024-06-14T20:10:47.355+0530] {dagbag.py:540} INFO - Filling up the DagBag from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T20:10:55.314+0530] {logging_mixin.py:188} INFO - <pyspark.sql.session.SparkSession object at 0x7f0c06a8ac50>
[2024-06-14T20:11:08.896+0530] {logging_mixin.py:188} INFO - Data saved successfully as Parquet file at /home/wsl/airflow/dags/Collect Data/world.parquet
[2024-06-14T20:11:08.897+0530] {processor.py:842} WARNING - No viable dags retrieved from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T20:11:08.911+0530] {processor.py:183} INFO - Processing /home/wsl/airflow/dags/Collect Data/test3.py took 21.570 seconds
[2024-06-14T20:11:48.533+0530] {processor.py:161} INFO - Started process (PID=88619) to work on /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T20:11:48.534+0530] {processor.py:830} INFO - Processing file /home/wsl/airflow/dags/Collect Data/test3.py for tasks to queue
[2024-06-14T20:11:48.535+0530] {logging_mixin.py:188} INFO - [2024-06-14T20:11:48.535+0530] {dagbag.py:540} INFO - Filling up the DagBag from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T20:11:58.265+0530] {logging_mixin.py:188} INFO - <pyspark.sql.session.SparkSession object at 0x7f0c06a86b60>
[2024-06-14T20:12:15.248+0530] {logging_mixin.py:188} INFO - Data saved successfully as Parquet file at /home/wsl/airflow/dags/Collect Data/world.parquet
[2024-06-14T20:12:15.249+0530] {processor.py:842} WARNING - No viable dags retrieved from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T20:12:15.280+0530] {processor.py:183} INFO - Processing /home/wsl/airflow/dags/Collect Data/test3.py took 26.754 seconds
[2024-06-14T20:13:25.612+0530] {processor.py:161} INFO - Started process (PID=89966) to work on /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T20:13:25.614+0530] {processor.py:830} INFO - Processing file /home/wsl/airflow/dags/Collect Data/test3.py for tasks to queue
[2024-06-14T20:13:25.615+0530] {logging_mixin.py:188} INFO - [2024-06-14T20:13:25.614+0530] {dagbag.py:540} INFO - Filling up the DagBag from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T20:13:32.588+0530] {logging_mixin.py:188} INFO - <pyspark.sql.session.SparkSession object at 0x7f0c06a8ac80>
[2024-06-14T20:13:49.787+0530] {logging_mixin.py:188} INFO - Data saved successfully as Parquet file at /home/wsl/airflow/dags/Collect Data/world.parquet
[2024-06-14T20:13:49.787+0530] {processor.py:842} WARNING - No viable dags retrieved from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T20:13:49.801+0530] {processor.py:183} INFO - Processing /home/wsl/airflow/dags/Collect Data/test3.py took 24.196 seconds
[2024-06-14T20:14:46.888+0530] {processor.py:161} INFO - Started process (PID=91597) to work on /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T20:14:46.904+0530] {processor.py:830} INFO - Processing file /home/wsl/airflow/dags/Collect Data/test3.py for tasks to queue
[2024-06-14T20:14:46.906+0530] {logging_mixin.py:188} INFO - [2024-06-14T20:14:46.905+0530] {dagbag.py:540} INFO - Filling up the DagBag from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T20:14:57.976+0530] {logging_mixin.py:188} INFO - <pyspark.sql.session.SparkSession object at 0x7f0c068969e0>
[2024-06-14T20:15:19.919+0530] {logging_mixin.py:188} INFO - Data saved successfully as Parquet file at /home/wsl/airflow/dags/Collect Data/world.parquet
[2024-06-14T20:15:19.920+0530] {processor.py:842} WARNING - No viable dags retrieved from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T20:15:23.665+0530] {processor.py:183} INFO - Processing /home/wsl/airflow/dags/Collect Data/test3.py took 36.822 seconds
[2024-06-14T20:16:23.155+0530] {processor.py:161} INFO - Started process (PID=93118) to work on /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T20:16:23.220+0530] {processor.py:830} INFO - Processing file /home/wsl/airflow/dags/Collect Data/test3.py for tasks to queue
[2024-06-14T20:16:23.222+0530] {logging_mixin.py:188} INFO - [2024-06-14T20:16:23.221+0530] {dagbag.py:540} INFO - Filling up the DagBag from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T20:16:42.244+0530] {logging_mixin.py:188} INFO - <pyspark.sql.session.SparkSession object at 0x7f0c06896b90>
[2024-06-14T20:17:19.310+0530] {logging_mixin.py:188} INFO - Data saved successfully as Parquet file at /home/wsl/airflow/dags/Collect Data/world.parquet
[2024-06-14T20:17:19.313+0530] {processor.py:842} WARNING - No viable dags retrieved from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T20:17:19.337+0530] {processor.py:183} INFO - Processing /home/wsl/airflow/dags/Collect Data/test3.py took 56.228 seconds
[2024-06-14T20:18:19.368+0530] {processor.py:161} INFO - Started process (PID=94722) to work on /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T20:18:19.370+0530] {processor.py:830} INFO - Processing file /home/wsl/airflow/dags/Collect Data/test3.py for tasks to queue
[2024-06-14T20:18:19.371+0530] {logging_mixin.py:188} INFO - [2024-06-14T20:18:19.370+0530] {dagbag.py:540} INFO - Filling up the DagBag from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T20:18:30.173+0530] {logging_mixin.py:188} INFO - <pyspark.sql.session.SparkSession object at 0x7f0c068969e0>
[2024-06-14T20:18:48.743+0530] {logging_mixin.py:188} INFO - Data saved successfully as Parquet file at /home/wsl/airflow/dags/Collect Data/world.parquet
[2024-06-14T20:18:48.744+0530] {processor.py:842} WARNING - No viable dags retrieved from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T20:18:52.203+0530] {processor.py:183} INFO - Processing /home/wsl/airflow/dags/Collect Data/test3.py took 32.844 seconds
[2024-06-14T20:19:45.927+0530] {processor.py:161} INFO - Started process (PID=96044) to work on /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T20:19:45.929+0530] {processor.py:830} INFO - Processing file /home/wsl/airflow/dags/Collect Data/test3.py for tasks to queue
[2024-06-14T20:19:45.930+0530] {logging_mixin.py:188} INFO - [2024-06-14T20:19:45.929+0530] {dagbag.py:540} INFO - Filling up the DagBag from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T20:19:52.536+0530] {logging_mixin.py:188} INFO - <pyspark.sql.session.SparkSession object at 0x7f0c06896ce0>
[2024-06-14T20:20:15.285+0530] {logging_mixin.py:188} INFO - Data saved successfully as Parquet file at /home/wsl/airflow/dags/Collect Data/world.parquet
[2024-06-14T20:20:15.286+0530] {processor.py:842} WARNING - No viable dags retrieved from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T20:20:15.301+0530] {processor.py:183} INFO - Processing /home/wsl/airflow/dags/Collect Data/test3.py took 29.389 seconds
[2024-06-14T20:21:42.128+0530] {processor.py:161} INFO - Started process (PID=97306) to work on /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T20:21:42.140+0530] {processor.py:830} INFO - Processing file /home/wsl/airflow/dags/Collect Data/test3.py for tasks to queue
[2024-06-14T20:21:42.142+0530] {logging_mixin.py:188} INFO - [2024-06-14T20:21:42.141+0530] {dagbag.py:540} INFO - Filling up the DagBag from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T20:21:52.635+0530] {logging_mixin.py:188} INFO - <pyspark.sql.session.SparkSession object at 0x7f0c06896e60>
[2024-06-14T20:22:11.691+0530] {logging_mixin.py:188} INFO - Data saved successfully as Parquet file at /home/wsl/airflow/dags/Collect Data/world.parquet
[2024-06-14T20:22:11.692+0530] {processor.py:842} WARNING - No viable dags retrieved from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T20:22:13.546+0530] {processor.py:183} INFO - Processing /home/wsl/airflow/dags/Collect Data/test3.py took 31.434 seconds
[2024-06-14T20:24:00.912+0530] {processor.py:161} INFO - Started process (PID=98629) to work on /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T20:24:00.915+0530] {processor.py:830} INFO - Processing file /home/wsl/airflow/dags/Collect Data/test3.py for tasks to queue
[2024-06-14T20:24:00.917+0530] {logging_mixin.py:188} INFO - [2024-06-14T20:24:00.916+0530] {dagbag.py:540} INFO - Filling up the DagBag from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T21:04:24.641+0530] {logging_mixin.py:188} INFO - <pyspark.sql.session.SparkSession object at 0x7f0c068967a0>
[2024-06-14T21:05:31.563+0530] {logging_mixin.py:188} INFO - Data saved successfully as Parquet file at /home/wsl/airflow/dags/Collect Data/world.parquet
[2024-06-14T21:05:31.587+0530] {processor.py:842} WARNING - No viable dags retrieved from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T21:05:31.746+0530] {processor.py:183} INFO - Processing /home/wsl/airflow/dags/Collect Data/test3.py took 2490.850 seconds
[2024-06-14T23:30:36.215+0530] {processor.py:161} INFO - Started process (PID=15632) to work on /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T23:30:36.217+0530] {processor.py:830} INFO - Processing file /home/wsl/airflow/dags/Collect Data/test3.py for tasks to queue
[2024-06-14T23:30:36.218+0530] {logging_mixin.py:188} INFO - [2024-06-14T23:30:36.217+0530] {dagbag.py:540} INFO - Filling up the DagBag from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T23:30:50.922+0530] {logging_mixin.py:188} INFO - <pyspark.sql.session.SparkSession object at 0x7f30931a92a0>
[2024-06-14T23:31:56.468+0530] {logging_mixin.py:188} INFO - Data saved successfully as Parquet file at /home/wsl/airflow/dags/Collect Data/world.parquet
[2024-06-14T23:31:56.469+0530] {processor.py:842} WARNING - No viable dags retrieved from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T23:31:56.506+0530] {processor.py:183} INFO - Processing /home/wsl/airflow/dags/Collect Data/test3.py took 80.300 seconds
[2024-06-14T23:34:10.816+0530] {processor.py:161} INFO - Started process (PID=17736) to work on /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T23:34:10.820+0530] {processor.py:830} INFO - Processing file /home/wsl/airflow/dags/Collect Data/test3.py for tasks to queue
[2024-06-14T23:34:10.823+0530] {logging_mixin.py:188} INFO - [2024-06-14T23:34:10.822+0530] {dagbag.py:540} INFO - Filling up the DagBag from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T23:34:17.938+0530] {logging_mixin.py:188} INFO - <pyspark.sql.session.SparkSession object at 0x7f30931a5de0>
[2024-06-14T23:34:37.917+0530] {logging_mixin.py:188} INFO - Data saved successfully as Parquet file at /home/wsl/airflow/dags/Collect Data/world.parquet
[2024-06-14T23:34:37.917+0530] {processor.py:842} WARNING - No viable dags retrieved from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-14T23:34:37.946+0530] {processor.py:183} INFO - Processing /home/wsl/airflow/dags/Collect Data/test3.py took 27.148 seconds
[2024-06-15T00:48:26.660+0530] {processor.py:161} INFO - Started process (PID=19996) to work on /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-15T00:48:26.880+0530] {processor.py:830} INFO - Processing file /home/wsl/airflow/dags/Collect Data/test3.py for tasks to queue
[2024-06-15T00:48:26.882+0530] {logging_mixin.py:188} INFO - [2024-06-15T00:48:26.881+0530] {dagbag.py:540} INFO - Filling up the DagBag from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-15T00:48:35.574+0530] {logging_mixin.py:188} INFO - <pyspark.sql.session.SparkSession object at 0x7f30931a5e10>
[2024-06-15T00:48:52.405+0530] {logging_mixin.py:188} INFO - Data saved successfully as Parquet file at /home/wsl/airflow/dags/Collect Data/world.parquet
[2024-06-15T00:48:52.406+0530] {processor.py:842} WARNING - No viable dags retrieved from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-15T00:48:57.425+0530] {processor.py:186} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlite3.OperationalError: database is locked

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 843, in process_file
    DagFileProcessor.update_import_errors(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 615, in update_import_errors
    session.execute(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 1665, in execute
    ) = compile_state_cls.orm_pre_session_exec(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/orm/persistence.py", line 1852, in orm_pre_session_exec
    update_options = cls._do_pre_synchronize_fetch(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/orm/persistence.py", line 2088, in _do_pre_synchronize_fetch
    result = session.execute(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) database is locked
[SQL: SELECT import_error.id 
FROM import_error 
WHERE (import_error.filename LIKE ? || '%')]
[parameters: ('/home/wsl/airflow/dags/Collect Data/test3.py',)]
(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2024-06-15T00:50:23.837+0530] {processor.py:161} INFO - Started process (PID=21406) to work on /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-15T00:50:24.171+0530] {processor.py:830} INFO - Processing file /home/wsl/airflow/dags/Collect Data/test3.py for tasks to queue
[2024-06-15T00:50:24.172+0530] {logging_mixin.py:188} INFO - [2024-06-15T00:50:24.171+0530] {dagbag.py:540} INFO - Filling up the DagBag from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-15T00:50:31.516+0530] {logging_mixin.py:188} INFO - <pyspark.sql.session.SparkSession object at 0x7f30931a9d20>
[2024-06-15T00:50:50.944+0530] {logging_mixin.py:188} INFO - Data saved successfully as Parquet file at /home/wsl/airflow/dags/Collect Data/world.parquet
[2024-06-15T00:50:50.944+0530] {processor.py:842} WARNING - No viable dags retrieved from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-15T00:50:55.967+0530] {processor.py:186} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlite3.OperationalError: database is locked

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 843, in process_file
    DagFileProcessor.update_import_errors(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 615, in update_import_errors
    session.execute(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 1665, in execute
    ) = compile_state_cls.orm_pre_session_exec(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/orm/persistence.py", line 1852, in orm_pre_session_exec
    update_options = cls._do_pre_synchronize_fetch(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/orm/persistence.py", line 2088, in _do_pre_synchronize_fetch
    result = session.execute(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) database is locked
[SQL: SELECT import_error.id 
FROM import_error 
WHERE (import_error.filename LIKE ? || '%')]
[parameters: ('/home/wsl/airflow/dags/Collect Data/test3.py',)]
(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2024-06-15T00:51:49.033+0530] {processor.py:161} INFO - Started process (PID=22489) to work on /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-15T00:51:49.036+0530] {processor.py:830} INFO - Processing file /home/wsl/airflow/dags/Collect Data/test3.py for tasks to queue
[2024-06-15T00:51:49.037+0530] {logging_mixin.py:188} INFO - [2024-06-15T00:51:49.037+0530] {dagbag.py:540} INFO - Filling up the DagBag from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-15T00:51:55.393+0530] {logging_mixin.py:188} INFO - <pyspark.sql.session.SparkSession object at 0x7f30931a9c30>
[2024-06-15T00:52:09.649+0530] {logging_mixin.py:188} INFO - Data saved successfully as Parquet file at /home/wsl/airflow/dags/Collect Data/world.parquet
[2024-06-15T00:52:09.649+0530] {processor.py:842} WARNING - No viable dags retrieved from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-15T00:52:09.660+0530] {processor.py:183} INFO - Processing /home/wsl/airflow/dags/Collect Data/test3.py took 20.637 seconds
[2024-06-15T00:52:51.950+0530] {processor.py:161} INFO - Started process (PID=23388) to work on /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-15T00:52:51.953+0530] {processor.py:830} INFO - Processing file /home/wsl/airflow/dags/Collect Data/test3.py for tasks to queue
[2024-06-15T00:52:51.954+0530] {logging_mixin.py:188} INFO - [2024-06-15T00:52:51.954+0530] {dagbag.py:540} INFO - Filling up the DagBag from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-15T00:52:58.193+0530] {logging_mixin.py:188} INFO - <pyspark.sql.session.SparkSession object at 0x7f30931a9d50>
[2024-06-15T00:53:13.059+0530] {logging_mixin.py:188} INFO - Data saved successfully as Parquet file at /home/wsl/airflow/dags/Collect Data/world.parquet
[2024-06-15T00:53:13.059+0530] {processor.py:842} WARNING - No viable dags retrieved from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-15T00:53:13.075+0530] {processor.py:183} INFO - Processing /home/wsl/airflow/dags/Collect Data/test3.py took 21.133 seconds
[2024-06-15T00:54:01.857+0530] {processor.py:161} INFO - Started process (PID=24329) to work on /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-15T00:54:01.861+0530] {processor.py:830} INFO - Processing file /home/wsl/airflow/dags/Collect Data/test3.py for tasks to queue
[2024-06-15T00:54:01.862+0530] {logging_mixin.py:188} INFO - [2024-06-15T00:54:01.862+0530] {dagbag.py:540} INFO - Filling up the DagBag from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-15T00:54:08.347+0530] {logging_mixin.py:188} INFO - <pyspark.sql.session.SparkSession object at 0x7f309f955900>
[2024-06-15T00:54:22.876+0530] {logging_mixin.py:188} INFO - Data saved successfully as Parquet file at /home/wsl/airflow/dags/Collect Data/world.parquet
[2024-06-15T00:54:22.876+0530] {processor.py:842} WARNING - No viable dags retrieved from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-15T00:54:22.889+0530] {processor.py:183} INFO - Processing /home/wsl/airflow/dags/Collect Data/test3.py took 21.049 seconds
[2024-06-15T00:55:03.706+0530] {processor.py:161} INFO - Started process (PID=25259) to work on /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-15T00:55:03.710+0530] {processor.py:830} INFO - Processing file /home/wsl/airflow/dags/Collect Data/test3.py for tasks to queue
[2024-06-15T00:55:03.712+0530] {logging_mixin.py:188} INFO - [2024-06-15T00:55:03.711+0530] {dagbag.py:540} INFO - Filling up the DagBag from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-15T00:55:10.540+0530] {logging_mixin.py:188} INFO - <pyspark.sql.session.SparkSession object at 0x7f30931a9db0>
[2024-06-15T00:55:25.356+0530] {logging_mixin.py:188} INFO - Data saved successfully as Parquet file at /home/wsl/airflow/dags/Collect Data/world.parquet
[2024-06-15T00:55:25.357+0530] {processor.py:842} WARNING - No viable dags retrieved from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-15T00:55:25.368+0530] {processor.py:183} INFO - Processing /home/wsl/airflow/dags/Collect Data/test3.py took 21.673 seconds
[2024-06-15T00:56:08.659+0530] {processor.py:161} INFO - Started process (PID=26196) to work on /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-15T00:56:08.663+0530] {processor.py:830} INFO - Processing file /home/wsl/airflow/dags/Collect Data/test3.py for tasks to queue
[2024-06-15T00:56:08.664+0530] {logging_mixin.py:188} INFO - [2024-06-15T00:56:08.664+0530] {dagbag.py:540} INFO - Filling up the DagBag from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-15T00:56:15.446+0530] {logging_mixin.py:188} INFO - <pyspark.sql.session.SparkSession object at 0x7f30931a9ed0>
[2024-06-15T00:56:29.982+0530] {logging_mixin.py:188} INFO - Data saved successfully as Parquet file at /home/wsl/airflow/dags/Collect Data/world.parquet
[2024-06-15T00:56:29.983+0530] {processor.py:842} WARNING - No viable dags retrieved from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-15T00:56:29.996+0530] {processor.py:183} INFO - Processing /home/wsl/airflow/dags/Collect Data/test3.py took 21.349 seconds
[2024-06-15T00:57:14.871+0530] {processor.py:161} INFO - Started process (PID=27225) to work on /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-15T00:57:14.873+0530] {processor.py:830} INFO - Processing file /home/wsl/airflow/dags/Collect Data/test3.py for tasks to queue
[2024-06-15T00:57:14.874+0530] {logging_mixin.py:188} INFO - [2024-06-15T00:57:14.874+0530] {dagbag.py:540} INFO - Filling up the DagBag from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-15T00:57:21.175+0530] {logging_mixin.py:188} INFO - <pyspark.sql.session.SparkSession object at 0x7f3093084220>
[2024-06-15T00:57:37.874+0530] {logging_mixin.py:188} INFO - Data saved successfully as Parquet file at /home/wsl/airflow/dags/Collect Data/world.parquet
[2024-06-15T00:57:37.875+0530] {processor.py:842} WARNING - No viable dags retrieved from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-15T00:57:37.888+0530] {processor.py:183} INFO - Processing /home/wsl/airflow/dags/Collect Data/test3.py took 23.029 seconds
[2024-06-15T00:58:28.262+0530] {processor.py:161} INFO - Started process (PID=28291) to work on /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-15T00:58:28.264+0530] {processor.py:830} INFO - Processing file /home/wsl/airflow/dags/Collect Data/test3.py for tasks to queue
[2024-06-15T00:58:28.265+0530] {logging_mixin.py:188} INFO - [2024-06-15T00:58:28.265+0530] {dagbag.py:540} INFO - Filling up the DagBag from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-15T00:58:34.640+0530] {logging_mixin.py:188} INFO - <pyspark.sql.session.SparkSession object at 0x7f30931adcc0>
[2024-06-15T00:58:52.336+0530] {logging_mixin.py:188} INFO - Data saved successfully as Parquet file at /home/wsl/airflow/dags/Collect Data/world.parquet
[2024-06-15T00:58:52.337+0530] {processor.py:842} WARNING - No viable dags retrieved from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-15T00:58:52.350+0530] {processor.py:183} INFO - Processing /home/wsl/airflow/dags/Collect Data/test3.py took 24.093 seconds
[2024-06-15T00:59:50.389+0530] {processor.py:161} INFO - Started process (PID=29252) to work on /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-15T00:59:50.391+0530] {processor.py:830} INFO - Processing file /home/wsl/airflow/dags/Collect Data/test3.py for tasks to queue
[2024-06-15T00:59:50.392+0530] {logging_mixin.py:188} INFO - [2024-06-15T00:59:50.392+0530] {dagbag.py:540} INFO - Filling up the DagBag from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-15T00:59:56.783+0530] {logging_mixin.py:188} INFO - <pyspark.sql.session.SparkSession object at 0x7f3093088040>
[2024-06-15T01:00:11.578+0530] {logging_mixin.py:188} INFO - Data saved successfully as Parquet file at /home/wsl/airflow/dags/Collect Data/world.parquet
[2024-06-15T01:00:11.579+0530] {processor.py:842} WARNING - No viable dags retrieved from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-15T01:00:11.605+0530] {processor.py:183} INFO - Processing /home/wsl/airflow/dags/Collect Data/test3.py took 21.224 seconds
[2024-06-15T01:01:00.462+0530] {processor.py:161} INFO - Started process (PID=30339) to work on /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-15T01:01:00.464+0530] {processor.py:830} INFO - Processing file /home/wsl/airflow/dags/Collect Data/test3.py for tasks to queue
[2024-06-15T01:01:00.465+0530] {logging_mixin.py:188} INFO - [2024-06-15T01:01:00.465+0530] {dagbag.py:540} INFO - Filling up the DagBag from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-15T01:01:07.406+0530] {logging_mixin.py:188} INFO - <pyspark.sql.session.SparkSession object at 0x7f30931adab0>
[2024-06-15T01:01:23.612+0530] {logging_mixin.py:188} INFO - Data saved successfully as Parquet file at /home/wsl/airflow/dags/Collect Data/world.parquet
[2024-06-15T01:01:23.612+0530] {processor.py:842} WARNING - No viable dags retrieved from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-15T01:01:23.623+0530] {processor.py:183} INFO - Processing /home/wsl/airflow/dags/Collect Data/test3.py took 23.181 seconds
[2024-06-15T01:02:05.689+0530] {processor.py:161} INFO - Started process (PID=31321) to work on /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-15T01:02:05.691+0530] {processor.py:830} INFO - Processing file /home/wsl/airflow/dags/Collect Data/test3.py for tasks to queue
[2024-06-15T01:02:05.692+0530] {logging_mixin.py:188} INFO - [2024-06-15T01:02:05.692+0530] {dagbag.py:540} INFO - Filling up the DagBag from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-15T01:02:13.039+0530] {logging_mixin.py:188} INFO - <pyspark.sql.session.SparkSession object at 0x7f3093143640>
[2024-06-15T01:02:27.899+0530] {logging_mixin.py:188} INFO - Data saved successfully as Parquet file at /home/wsl/airflow/dags/Collect Data/world.parquet
[2024-06-15T01:02:27.900+0530] {processor.py:842} WARNING - No viable dags retrieved from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-15T01:02:27.914+0530] {processor.py:183} INFO - Processing /home/wsl/airflow/dags/Collect Data/test3.py took 22.232 seconds
[2024-06-15T01:03:14.563+0530] {processor.py:161} INFO - Started process (PID=32285) to work on /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-15T01:03:14.566+0530] {processor.py:830} INFO - Processing file /home/wsl/airflow/dags/Collect Data/test3.py for tasks to queue
[2024-06-15T01:03:14.567+0530] {logging_mixin.py:188} INFO - [2024-06-15T01:03:14.567+0530] {dagbag.py:540} INFO - Filling up the DagBag from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-15T01:03:21.621+0530] {logging_mixin.py:188} INFO - <pyspark.sql.session.SparkSession object at 0x7f30931ad6c0>
[2024-06-15T01:03:38.745+0530] {logging_mixin.py:188} INFO - Data saved successfully as Parquet file at /home/wsl/airflow/dags/Collect Data/world.parquet
[2024-06-15T01:03:38.746+0530] {processor.py:842} WARNING - No viable dags retrieved from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-15T01:03:38.760+0530] {processor.py:183} INFO - Processing /home/wsl/airflow/dags/Collect Data/test3.py took 24.206 seconds
[2024-06-15T01:04:23.136+0530] {processor.py:161} INFO - Started process (PID=33194) to work on /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-15T01:04:23.138+0530] {processor.py:830} INFO - Processing file /home/wsl/airflow/dags/Collect Data/test3.py for tasks to queue
[2024-06-15T01:04:23.140+0530] {logging_mixin.py:188} INFO - [2024-06-15T01:04:23.139+0530] {dagbag.py:540} INFO - Filling up the DagBag from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-15T01:04:29.736+0530] {logging_mixin.py:188} INFO - <pyspark.sql.session.SparkSession object at 0x7f3093143910>
[2024-06-15T01:04:43.742+0530] {logging_mixin.py:188} INFO - Data saved successfully as Parquet file at /home/wsl/airflow/dags/Collect Data/world.parquet
[2024-06-15T01:04:43.743+0530] {processor.py:842} WARNING - No viable dags retrieved from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-15T01:04:43.793+0530] {processor.py:183} INFO - Processing /home/wsl/airflow/dags/Collect Data/test3.py took 20.665 seconds
[2024-06-15T01:05:24.708+0530] {processor.py:161} INFO - Started process (PID=34154) to work on /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-15T01:05:24.710+0530] {processor.py:830} INFO - Processing file /home/wsl/airflow/dags/Collect Data/test3.py for tasks to queue
[2024-06-15T01:05:24.711+0530] {logging_mixin.py:188} INFO - [2024-06-15T01:05:24.711+0530] {dagbag.py:540} INFO - Filling up the DagBag from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-15T01:05:31.103+0530] {logging_mixin.py:188} INFO - <pyspark.sql.session.SparkSession object at 0x7f30a0b542e0>
[2024-06-15T01:05:47.799+0530] {logging_mixin.py:188} INFO - Data saved successfully as Parquet file at /home/wsl/airflow/dags/Collect Data/world.parquet
[2024-06-15T01:05:47.799+0530] {processor.py:842} WARNING - No viable dags retrieved from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-15T01:05:49.047+0530] {processor.py:183} INFO - Processing /home/wsl/airflow/dags/Collect Data/test3.py took 24.348 seconds
[2024-06-15T01:06:29.238+0530] {processor.py:161} INFO - Started process (PID=35128) to work on /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-15T01:06:29.243+0530] {processor.py:830} INFO - Processing file /home/wsl/airflow/dags/Collect Data/test3.py for tasks to queue
[2024-06-15T01:06:29.245+0530] {logging_mixin.py:188} INFO - [2024-06-15T01:06:29.244+0530] {dagbag.py:540} INFO - Filling up the DagBag from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-15T01:06:36.029+0530] {logging_mixin.py:188} INFO - <pyspark.sql.session.SparkSession object at 0x7f309f4fb520>
[2024-06-15T01:06:51.187+0530] {logging_mixin.py:188} INFO - Data saved successfully as Parquet file at /home/wsl/airflow/dags/Collect Data/world.parquet
[2024-06-15T01:06:51.187+0530] {processor.py:842} WARNING - No viable dags retrieved from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-15T01:06:51.197+0530] {processor.py:183} INFO - Processing /home/wsl/airflow/dags/Collect Data/test3.py took 21.968 seconds
[2024-06-15T01:07:29.402+0530] {processor.py:161} INFO - Started process (PID=36044) to work on /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-15T01:07:29.441+0530] {processor.py:830} INFO - Processing file /home/wsl/airflow/dags/Collect Data/test3.py for tasks to queue
[2024-06-15T01:07:29.443+0530] {logging_mixin.py:188} INFO - [2024-06-15T01:07:29.442+0530] {dagbag.py:540} INFO - Filling up the DagBag from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-15T01:07:36.473+0530] {logging_mixin.py:188} INFO - <pyspark.sql.session.SparkSession object at 0x7f30a0b0bcd0>
[2024-06-15T01:07:50.199+0530] {logging_mixin.py:188} INFO - Data saved successfully as Parquet file at /home/wsl/airflow/dags/Collect Data/world.parquet
[2024-06-15T01:07:50.200+0530] {processor.py:842} WARNING - No viable dags retrieved from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-15T01:07:50.221+0530] {processor.py:183} INFO - Processing /home/wsl/airflow/dags/Collect Data/test3.py took 20.832 seconds
[2024-06-15T01:08:25.592+0530] {processor.py:161} INFO - Started process (PID=36994) to work on /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-15T01:08:25.594+0530] {processor.py:830} INFO - Processing file /home/wsl/airflow/dags/Collect Data/test3.py for tasks to queue
[2024-06-15T01:08:25.596+0530] {logging_mixin.py:188} INFO - [2024-06-15T01:08:25.595+0530] {dagbag.py:540} INFO - Filling up the DagBag from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-15T01:08:31.573+0530] {logging_mixin.py:188} INFO - <pyspark.sql.session.SparkSession object at 0x7f30a0b0fd90>
[2024-06-15T01:08:45.049+0530] {logging_mixin.py:188} INFO - Data saved successfully as Parquet file at /home/wsl/airflow/dags/Collect Data/world.parquet
[2024-06-15T01:08:45.050+0530] {processor.py:842} WARNING - No viable dags retrieved from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-15T01:08:45.063+0530] {processor.py:183} INFO - Processing /home/wsl/airflow/dags/Collect Data/test3.py took 19.483 seconds
[2024-06-15T01:09:22.618+0530] {processor.py:161} INFO - Started process (PID=37935) to work on /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-15T01:09:22.621+0530] {processor.py:830} INFO - Processing file /home/wsl/airflow/dags/Collect Data/test3.py for tasks to queue
[2024-06-15T01:09:22.622+0530] {logging_mixin.py:188} INFO - [2024-06-15T01:09:22.621+0530] {dagbag.py:540} INFO - Filling up the DagBag from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-15T01:09:28.858+0530] {logging_mixin.py:188} INFO - <pyspark.sql.session.SparkSession object at 0x7f3092da0850>
[2024-06-15T01:09:47.026+0530] {logging_mixin.py:188} INFO - Data saved successfully as Parquet file at /home/wsl/airflow/dags/Collect Data/world.parquet
[2024-06-15T01:09:47.027+0530] {processor.py:842} WARNING - No viable dags retrieved from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-15T01:09:52.051+0530] {processor.py:186} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlite3.OperationalError: database is locked

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 843, in process_file
    DagFileProcessor.update_import_errors(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 615, in update_import_errors
    session.execute(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 1665, in execute
    ) = compile_state_cls.orm_pre_session_exec(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/orm/persistence.py", line 1852, in orm_pre_session_exec
    update_options = cls._do_pre_synchronize_fetch(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/orm/persistence.py", line 2088, in _do_pre_synchronize_fetch
    result = session.execute(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) database is locked
[SQL: SELECT import_error.id 
FROM import_error 
WHERE (import_error.filename LIKE ? || '%')]
[parameters: ('/home/wsl/airflow/dags/Collect Data/test3.py',)]
(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2024-06-15T01:10:42.912+0530] {processor.py:161} INFO - Started process (PID=38896) to work on /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-15T01:10:43.415+0530] {processor.py:830} INFO - Processing file /home/wsl/airflow/dags/Collect Data/test3.py for tasks to queue
[2024-06-15T01:10:43.416+0530] {logging_mixin.py:188} INFO - [2024-06-15T01:10:43.415+0530] {dagbag.py:540} INFO - Filling up the DagBag from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-15T01:10:51.689+0530] {logging_mixin.py:188} INFO - <pyspark.sql.session.SparkSession object at 0x7f30a0b0be20>
[2024-06-15T01:11:17.584+0530] {logging_mixin.py:188} INFO - Data saved successfully as Parquet file at /home/wsl/airflow/dags/Collect Data/world.parquet
[2024-06-15T01:11:17.585+0530] {processor.py:842} WARNING - No viable dags retrieved from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-15T01:11:17.875+0530] {processor.py:183} INFO - Processing /home/wsl/airflow/dags/Collect Data/test3.py took 34.972 seconds
[2024-06-15T01:12:15.144+0530] {processor.py:161} INFO - Started process (PID=40006) to work on /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-15T01:12:15.146+0530] {processor.py:830} INFO - Processing file /home/wsl/airflow/dags/Collect Data/test3.py for tasks to queue
[2024-06-15T01:12:15.147+0530] {logging_mixin.py:188} INFO - [2024-06-15T01:12:15.147+0530] {dagbag.py:540} INFO - Filling up the DagBag from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-15T01:12:22.564+0530] {logging_mixin.py:188} INFO - <pyspark.sql.session.SparkSession object at 0x7f30a0b0ffd0>
[2024-06-15T01:12:47.274+0530] {logging_mixin.py:188} INFO - Data saved successfully as Parquet file at /home/wsl/airflow/dags/Collect Data/world.parquet
[2024-06-15T01:12:47.278+0530] {processor.py:842} WARNING - No viable dags retrieved from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-15T01:12:52.958+0530] {processor.py:186} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlite3.OperationalError: database is locked

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 843, in process_file
    DagFileProcessor.update_import_errors(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 615, in update_import_errors
    session.execute(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 1665, in execute
    ) = compile_state_cls.orm_pre_session_exec(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/orm/persistence.py", line 1852, in orm_pre_session_exec
    update_options = cls._do_pre_synchronize_fetch(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/orm/persistence.py", line 2088, in _do_pre_synchronize_fetch
    result = session.execute(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) database is locked
[SQL: SELECT import_error.id 
FROM import_error 
WHERE (import_error.filename LIKE ? || '%')]
[parameters: ('/home/wsl/airflow/dags/Collect Data/test3.py',)]
(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2024-06-15T01:13:52.688+0530] {processor.py:161} INFO - Started process (PID=41144) to work on /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-15T01:13:53.193+0530] {processor.py:830} INFO - Processing file /home/wsl/airflow/dags/Collect Data/test3.py for tasks to queue
[2024-06-15T01:13:53.198+0530] {logging_mixin.py:188} INFO - [2024-06-15T01:13:53.196+0530] {dagbag.py:540} INFO - Filling up the DagBag from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-15T01:14:03.864+0530] {logging_mixin.py:188} INFO - <pyspark.sql.session.SparkSession object at 0x7f3092da4790>
[2024-06-15T01:14:26.502+0530] {logging_mixin.py:188} INFO - Data saved successfully as Parquet file at /home/wsl/airflow/dags/Collect Data/world.parquet
[2024-06-15T01:14:26.503+0530] {processor.py:842} WARNING - No viable dags retrieved from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-15T01:14:30.463+0530] {processor.py:183} INFO - Processing /home/wsl/airflow/dags/Collect Data/test3.py took 37.783 seconds
[2024-06-15T01:16:18.289+0530] {processor.py:161} INFO - Started process (PID=42493) to work on /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-15T01:16:18.306+0530] {processor.py:830} INFO - Processing file /home/wsl/airflow/dags/Collect Data/test3.py for tasks to queue
[2024-06-15T01:16:18.307+0530] {logging_mixin.py:188} INFO - [2024-06-15T01:16:18.307+0530] {dagbag.py:540} INFO - Filling up the DagBag from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-15T01:16:25.724+0530] {logging_mixin.py:188} INFO - <pyspark.sql.session.SparkSession object at 0x7f3092da08b0>
[2024-06-15T01:16:43.601+0530] {logging_mixin.py:188} INFO - Data saved successfully as Parquet file at /home/wsl/airflow/dags/Collect Data/world.parquet
[2024-06-15T01:16:43.602+0530] {processor.py:842} WARNING - No viable dags retrieved from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-15T01:16:43.630+0530] {processor.py:183} INFO - Processing /home/wsl/airflow/dags/Collect Data/test3.py took 25.347 seconds
[2024-06-15T01:17:50.653+0530] {processor.py:161} INFO - Started process (PID=43672) to work on /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-15T01:17:50.656+0530] {processor.py:830} INFO - Processing file /home/wsl/airflow/dags/Collect Data/test3.py for tasks to queue
[2024-06-15T01:17:50.658+0530] {logging_mixin.py:188} INFO - [2024-06-15T01:17:50.657+0530] {dagbag.py:540} INFO - Filling up the DagBag from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-15T01:17:57.394+0530] {logging_mixin.py:188} INFO - <pyspark.sql.session.SparkSession object at 0x7f3092da4820>
[2024-06-15T01:18:14.055+0530] {logging_mixin.py:188} INFO - Data saved successfully as Parquet file at /home/wsl/airflow/dags/Collect Data/world.parquet
[2024-06-15T01:18:14.058+0530] {processor.py:842} WARNING - No viable dags retrieved from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-15T01:18:14.079+0530] {processor.py:183} INFO - Processing /home/wsl/airflow/dags/Collect Data/test3.py took 23.440 seconds
[2024-06-15T01:19:13.150+0530] {processor.py:161} INFO - Started process (PID=44522) to work on /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-15T01:19:13.153+0530] {processor.py:830} INFO - Processing file /home/wsl/airflow/dags/Collect Data/test3.py for tasks to queue
[2024-06-15T01:19:13.154+0530] {logging_mixin.py:188} INFO - [2024-06-15T01:19:13.154+0530] {dagbag.py:540} INFO - Filling up the DagBag from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-15T01:19:19.716+0530] {logging_mixin.py:188} INFO - <pyspark.sql.session.SparkSession object at 0x7f3092da4940>
[2024-06-15T01:19:34.688+0530] {logging_mixin.py:188} INFO - Data saved successfully as Parquet file at /home/wsl/airflow/dags/Collect Data/world.parquet
[2024-06-15T01:19:34.689+0530] {processor.py:842} WARNING - No viable dags retrieved from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-15T01:19:34.701+0530] {processor.py:183} INFO - Processing /home/wsl/airflow/dags/Collect Data/test3.py took 21.564 seconds
[2024-06-15T01:20:24.018+0530] {processor.py:161} INFO - Started process (PID=45062) to work on /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-15T01:20:24.020+0530] {processor.py:830} INFO - Processing file /home/wsl/airflow/dags/Collect Data/test3.py for tasks to queue
[2024-06-15T01:20:24.021+0530] {logging_mixin.py:188} INFO - [2024-06-15T01:20:24.021+0530] {dagbag.py:540} INFO - Filling up the DagBag from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-15T01:20:33.453+0530] {logging_mixin.py:188} INFO - <pyspark.sql.session.SparkSession object at 0x7f3092da4a60>
[2024-06-15T01:20:35.649+0530] {logging_mixin.py:188} INFO - [2024-06-15T01:20:35.626+0530] {dagbag.py:350} ERROR - Failed to import: /home/wsl/airflow/dags/Collect Data/test3.py
Traceback (most recent call last):
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/wsl/airflow/dags/Collect Data/test3.py", line 24, in <module>
    europe = process_json(
  File "/home/wsl/airflow/dags/Collect Data/test3.py", line 17, in process_json
    df = spark.read.format("json").option('multiline', 'true').option("inferschema", 'true').load(file_path)
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/pyspark/sql/readwriter.py", line 307, in load
    return self._df(self._jreader.load(path))
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/pyspark/errors/exceptions/captured.py", line 185, in deco
    raise converted from None
pyspark.errors.exceptions.captured.AnalysisException: [PATH_NOT_FOUND] Path does not exist: file:/home/wsl/airflow/dags/Collect Data/europe.json.
[2024-06-15T01:20:35.655+0530] {processor.py:842} WARNING - No viable dags retrieved from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-15T01:20:35.847+0530] {processor.py:183} INFO - Processing /home/wsl/airflow/dags/Collect Data/test3.py took 11.838 seconds
[2024-06-15T01:21:21.296+0530] {processor.py:161} INFO - Started process (PID=45465) to work on /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-15T01:21:21.360+0530] {processor.py:830} INFO - Processing file /home/wsl/airflow/dags/Collect Data/test3.py for tasks to queue
[2024-06-15T01:21:21.361+0530] {logging_mixin.py:188} INFO - [2024-06-15T01:21:21.360+0530] {dagbag.py:540} INFO - Filling up the DagBag from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-15T01:21:30.573+0530] {logging_mixin.py:188} INFO - <pyspark.sql.session.SparkSession object at 0x7f3092da4b80>
[2024-06-15T01:21:52.090+0530] {logging_mixin.py:188} INFO - Data saved successfully as Parquet file at /home/wsl/airflow/dags/Collect Data/world.parquet
[2024-06-15T01:21:52.090+0530] {processor.py:842} WARNING - No viable dags retrieved from /home/wsl/airflow/dags/Collect Data/test3.py
[2024-06-15T01:21:54.982+0530] {processor.py:183} INFO - Processing /home/wsl/airflow/dags/Collect Data/test3.py took 33.695 seconds
