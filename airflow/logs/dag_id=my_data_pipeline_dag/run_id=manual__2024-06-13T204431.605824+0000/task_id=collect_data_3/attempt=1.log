[2024-06-14T02:24:17.648+0530] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-14T02:24:17.686+0530] {taskinstance.py:2073} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: my_data_pipeline_dag.collect_data_3 manual__2024-06-13T20:44:31.605824+00:00 [queued]>
[2024-06-14T02:24:17.696+0530] {taskinstance.py:2073} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: my_data_pipeline_dag.collect_data_3 manual__2024-06-13T20:44:31.605824+00:00 [queued]>
[2024-06-14T02:24:17.696+0530] {taskinstance.py:2303} INFO - Starting attempt 1 of 2
[2024-06-14T02:24:17.782+0530] {taskinstance.py:2327} INFO - Executing <Task(BashOperator): collect_data_3> on 2024-06-13 20:44:31.605824+00:00
[2024-06-14T02:24:17.790+0530] {standard_task_runner.py:63} INFO - Started process 29320 to run task
[2024-06-14T02:24:17.796+0530] {standard_task_runner.py:90} INFO - Running: ['airflow', 'tasks', 'run', 'my_data_pipeline_dag', 'collect_data_3', 'manual__2024-06-13T20:44:31.605824+00:00', '--job-id', '93', '--raw', '--subdir', 'DAGS_FOLDER/my_first_dag.py', '--cfg-path', '/tmp/tmpi46xp0te']
[2024-06-14T02:24:17.798+0530] {standard_task_runner.py:91} INFO - Job 93: Subtask collect_data_3
[2024-06-14T02:24:17.848+0530] {task_command.py:426} INFO - Running <TaskInstance: my_data_pipeline_dag.collect_data_3 manual__2024-06-13T20:44:31.605824+00:00 [running]> on host DESKTOP-J05K55U.
[2024-06-14T02:24:17.940+0530] {taskinstance.py:2644} INFO - Exporting env vars: AIRFLOW_CTX_DAG_EMAIL='airflow@example.com' AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='my_data_pipeline_dag' AIRFLOW_CTX_TASK_ID='collect_data_3' AIRFLOW_CTX_EXECUTION_DATE='2024-06-13T20:44:31.605824+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-06-13T20:44:31.605824+00:00'
[2024-06-14T02:24:17.942+0530] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-14T02:24:17.942+0530] {subprocess.py:63} INFO - Tmp dir root location: /tmp
[2024-06-14T02:24:17.943+0530] {subprocess.py:75} INFO - Running command: ['/usr/bin/bash', '-c', 'python "/home/wsl/airflow/dags/Collect Data/test.py"']
[2024-06-14T02:24:17.956+0530] {subprocess.py:86} INFO - Output:
[2024-06-14T02:26:16.039+0530] {subprocess.py:93} INFO - 24/06/14 02:26:16 WARN Utils: Your hostname, DESKTOP-J05K55U resolves to a loopback address: 127.0.1.1; using 172.31.56.255 instead (on interface eth0)
[2024-06-14T02:26:16.047+0530] {subprocess.py:93} INFO - 24/06/14 02:26:16 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
[2024-06-14T02:26:17.624+0530] {subprocess.py:93} INFO - :: loading settings :: url = jar:file:/home/wsl/airflow_venv/lib/python3.10/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml
[2024-06-14T02:26:17.906+0530] {subprocess.py:93} INFO - Ivy Default Cache set to: /home/wsl/.ivy2/cache
[2024-06-14T02:26:17.912+0530] {subprocess.py:93} INFO - The jars for the packages stored in: /home/wsl/.ivy2/jars
[2024-06-14T02:26:17.919+0530] {subprocess.py:93} INFO - org.elasticsearch#elasticsearch-hadoop added as a dependency
[2024-06-14T02:26:17.922+0530] {subprocess.py:93} INFO - :: resolving dependencies :: org.apache.spark#spark-submit-parent-b06cf899-7402-43fc-b531-861ef52133f2;1.0
[2024-06-14T02:26:17.922+0530] {subprocess.py:93} INFO - 	confs: [default]
[2024-06-14T02:26:18.248+0530] {subprocess.py:93} INFO - 	found org.elasticsearch#elasticsearch-hadoop;8.6.2 in central
[2024-06-14T02:26:18.339+0530] {subprocess.py:93} INFO - 	found commons-logging#commons-logging;1.1.1 in central
[2024-06-14T02:26:18.385+0530] {subprocess.py:93} INFO - 	found commons-codec#commons-codec;1.4 in central
[2024-06-14T02:26:18.432+0530] {subprocess.py:93} INFO - 	found javax.xml.bind#jaxb-api;2.3.1 in central
[2024-06-14T02:26:18.515+0530] {subprocess.py:93} INFO - 	found org.apache.hive#hive-service;3.1.2 in central
[2024-06-14T02:26:18.585+0530] {subprocess.py:93} INFO - 	found org.apache.hive#hive-exec;3.1.2 in central
[2024-06-14T02:26:18.632+0530] {subprocess.py:93} INFO - 	found org.apache.hive#hive-metastore;3.1.2 in central
[2024-06-14T02:26:18.663+0530] {subprocess.py:93} INFO - 	found org.apache.pig#pig;0.15.0 in central
[2024-06-14T02:26:18.739+0530] {subprocess.py:93} INFO - 	found org.apache.spark#spark-yarn_2.11;2.3.0 in central
[2024-06-14T02:26:18.763+0530] {subprocess.py:93} INFO - 	found org.scala-lang#scala-reflect;2.11.12 in central
[2024-06-14T02:26:18.793+0530] {subprocess.py:93} INFO - 	found org.apache.storm#storm-core;1.0.6 in central
[2024-06-14T02:26:18.831+0530] {subprocess.py:93} INFO - 	found org.apache.hadoop#hadoop-client;3.1.2 in central
[2024-06-14T02:26:18.870+0530] {subprocess.py:93} INFO - 	found org.apache.hadoop#hadoop-common;3.1.2 in central
[2024-06-14T02:26:18.898+0530] {subprocess.py:93} INFO - 	found org.apache.hadoop#hadoop-mapreduce-client-core;3.1.2 in central
[2024-06-14T02:26:18.917+0530] {subprocess.py:93} INFO - 	found joda-time#joda-time;2.9.3 in central
[2024-06-14T02:26:18.986+0530] {subprocess.py:93} INFO - :: resolution report :: resolve 1014ms :: artifacts dl 49ms
[2024-06-14T02:26:18.987+0530] {subprocess.py:93} INFO - 	:: modules in use:
[2024-06-14T02:26:18.987+0530] {subprocess.py:93} INFO - 	commons-codec#commons-codec;1.4 from central in [default]
[2024-06-14T02:26:18.987+0530] {subprocess.py:93} INFO - 	commons-logging#commons-logging;1.1.1 from central in [default]
[2024-06-14T02:26:18.988+0530] {subprocess.py:93} INFO - 	javax.xml.bind#jaxb-api;2.3.1 from central in [default]
[2024-06-14T02:26:18.988+0530] {subprocess.py:93} INFO - 	joda-time#joda-time;2.9.3 from central in [default]
[2024-06-14T02:26:18.988+0530] {subprocess.py:93} INFO - 	org.apache.hadoop#hadoop-client;3.1.2 from central in [default]
[2024-06-14T02:26:18.988+0530] {subprocess.py:93} INFO - 	org.apache.hadoop#hadoop-common;3.1.2 from central in [default]
[2024-06-14T02:26:18.989+0530] {subprocess.py:93} INFO - 	org.apache.hadoop#hadoop-mapreduce-client-core;3.1.2 from central in [default]
[2024-06-14T02:26:18.989+0530] {subprocess.py:93} INFO - 	org.apache.hive#hive-exec;3.1.2 from central in [default]
[2024-06-14T02:26:18.989+0530] {subprocess.py:93} INFO - 	org.apache.hive#hive-metastore;3.1.2 from central in [default]
[2024-06-14T02:26:18.990+0530] {subprocess.py:93} INFO - 	org.apache.hive#hive-service;3.1.2 from central in [default]
[2024-06-14T02:26:18.990+0530] {subprocess.py:93} INFO - 	org.apache.pig#pig;0.15.0 from central in [default]
[2024-06-14T02:26:18.990+0530] {subprocess.py:93} INFO - 	org.apache.spark#spark-yarn_2.11;2.3.0 from central in [default]
[2024-06-14T02:26:18.990+0530] {subprocess.py:93} INFO - 	org.apache.storm#storm-core;1.0.6 from central in [default]
[2024-06-14T02:26:18.991+0530] {subprocess.py:93} INFO - 	org.elasticsearch#elasticsearch-hadoop;8.6.2 from central in [default]
[2024-06-14T02:26:18.991+0530] {subprocess.py:93} INFO - 	org.scala-lang#scala-reflect;2.11.12 from central in [default]
[2024-06-14T02:26:18.992+0530] {subprocess.py:93} INFO - 	---------------------------------------------------------------------
[2024-06-14T02:26:18.992+0530] {subprocess.py:93} INFO - 	|                  |            modules            ||   artifacts   |
[2024-06-14T02:26:18.992+0530] {subprocess.py:93} INFO - 	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
[2024-06-14T02:26:18.993+0530] {subprocess.py:93} INFO - 	---------------------------------------------------------------------
[2024-06-14T02:26:18.993+0530] {subprocess.py:93} INFO - 	|      default     |   15  |   0   |   0   |   0   ||   15  |   0   |
[2024-06-14T02:26:18.993+0530] {subprocess.py:93} INFO - 	---------------------------------------------------------------------
[2024-06-14T02:26:19.001+0530] {subprocess.py:93} INFO - :: retrieving :: org.apache.spark#spark-submit-parent-b06cf899-7402-43fc-b531-861ef52133f2
[2024-06-14T02:26:19.002+0530] {subprocess.py:93} INFO - 	confs: [default]
[2024-06-14T02:26:19.020+0530] {subprocess.py:93} INFO - 	0 artifacts copied, 15 already retrieved (0kB/18ms)
[2024-06-14T02:26:20.036+0530] {subprocess.py:93} INFO - 24/06/14 02:26:20 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[2024-06-14T02:26:20.759+0530] {subprocess.py:93} INFO - Setting default log level to "WARN".
[2024-06-14T02:26:20.763+0530] {subprocess.py:93} INFO - To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[2024-06-14T02:39:08.267+0530] {subprocess.py:93} INFO - 24/06/14 02:39:07 WARN NettyRpcEnv: Ignored failure: java.util.concurrent.TimeoutException: Cannot receive any reply from 172.31.56.255:38347 in 10000 milliseconds
[2024-06-14T02:40:08.845+0530] {subprocess.py:93} INFO - 24/06/14 02:39:21 ERROR Inbox: Ignoring error
[2024-06-14T02:40:11.598+0530] {subprocess.py:93} INFO - java.lang.NullPointerException
[2024-06-14T02:40:14.885+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:677)
[2024-06-14T02:40:14.936+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:40:14.941+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:40:14.942+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:40:14.942+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:40:14.942+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:40:14.942+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:40:14.942+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:40:14.942+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:40:14.942+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:40:14.942+0530] {subprocess.py:93} INFO - 24/06/14 02:39:41 WARN Executor: Issue communicating with driver in heartbeater
[2024-06-14T02:40:14.942+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:40:14.943+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:40:14.943+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:40:14.943+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:40:14.943+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2024-06-14T02:40:14.943+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2024-06-14T02:40:14.943+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2024-06-14T02:40:14.943+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2024-06-14T02:40:14.943+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2024-06-14T02:40:14.943+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2024-06-14T02:40:14.943+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:40:14.944+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2024-06-14T02:40:14.944+0530] {subprocess.py:93} INFO - 	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2024-06-14T02:40:14.944+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2024-06-14T02:40:14.944+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2024-06-14T02:40:14.944+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2024-06-14T02:40:14.944+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:40:14.944+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:40:14.944+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:40:14.944+0530] {subprocess.py:93} INFO - Caused by: java.lang.NullPointerException
[2024-06-14T02:40:14.944+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:677)
[2024-06-14T02:40:14.945+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:40:14.945+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:40:14.945+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:40:14.945+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:40:14.945+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:40:14.945+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:40:14.945+0530] {subprocess.py:93} INFO - 	... 3 more
[2024-06-14T02:40:41.514+0530] {subprocess.py:93} INFO - 24/06/14 02:40:39 ERROR Inbox: Ignoring error
[2024-06-14T02:40:42.004+0530] {subprocess.py:93} INFO - java.lang.NullPointerException
[2024-06-14T02:40:42.039+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:677)
[2024-06-14T02:40:42.039+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:40:42.039+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:40:42.040+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:40:42.040+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:40:42.040+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:40:42.040+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:40:42.040+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:40:42.040+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:40:42.040+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:40:42.041+0530] {subprocess.py:93} INFO - 24/06/14 02:40:39 WARN Executor: Issue communicating with driver in heartbeater
[2024-06-14T02:40:42.041+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:40:42.041+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:40:42.041+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:40:42.041+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:40:42.041+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2024-06-14T02:40:42.042+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2024-06-14T02:40:42.042+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2024-06-14T02:40:42.042+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2024-06-14T02:40:42.042+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2024-06-14T02:40:42.042+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2024-06-14T02:40:42.043+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:40:42.043+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2024-06-14T02:40:42.043+0530] {subprocess.py:93} INFO - 	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2024-06-14T02:40:42.043+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2024-06-14T02:40:42.043+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2024-06-14T02:40:42.043+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2024-06-14T02:40:42.043+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:40:42.044+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:40:42.044+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:40:42.044+0530] {subprocess.py:93} INFO - Caused by: java.lang.NullPointerException
[2024-06-14T02:40:42.044+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:677)
[2024-06-14T02:40:42.044+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:40:42.044+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:40:42.044+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:40:42.044+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:40:42.044+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:40:42.044+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:40:42.044+0530] {subprocess.py:93} INFO - 	... 3 more
[2024-06-14T02:40:43.019+0530] {subprocess.py:93} INFO - 24/06/14 02:40:42 ERROR Inbox: Ignoring error
[2024-06-14T02:40:43.262+0530] {subprocess.py:93} INFO - java.lang.NullPointerException
[2024-06-14T02:40:43.267+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:677)
[2024-06-14T02:40:43.268+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:40:43.268+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:40:43.268+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:40:43.268+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:40:43.268+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:40:43.268+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:40:43.269+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:40:43.269+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:40:43.269+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:40:43.269+0530] {subprocess.py:93} INFO - 24/06/14 02:40:42 WARN Executor: Issue communicating with driver in heartbeater
[2024-06-14T02:40:43.269+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:40:43.269+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:40:43.269+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:40:43.270+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:40:43.270+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2024-06-14T02:40:43.270+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2024-06-14T02:40:43.270+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2024-06-14T02:40:43.270+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2024-06-14T02:40:43.270+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2024-06-14T02:40:43.271+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2024-06-14T02:40:43.271+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:40:43.271+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2024-06-14T02:40:43.271+0530] {subprocess.py:93} INFO - 	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2024-06-14T02:40:43.271+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2024-06-14T02:40:43.271+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2024-06-14T02:40:43.271+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2024-06-14T02:40:43.271+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:40:43.272+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:40:43.272+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:40:43.272+0530] {subprocess.py:93} INFO - Caused by: java.lang.NullPointerException
[2024-06-14T02:40:43.272+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:677)
[2024-06-14T02:40:43.272+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:40:43.273+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:40:43.273+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:40:43.273+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:40:43.273+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:40:43.274+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:40:43.274+0530] {subprocess.py:93} INFO - 	... 3 more
[2024-06-14T02:40:43.899+0530] {subprocess.py:93} INFO - 24/06/14 02:40:43 ERROR Inbox: Ignoring error
[2024-06-14T02:40:44.127+0530] {subprocess.py:93} INFO - java.lang.NullPointerException
[2024-06-14T02:40:44.131+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:677)
[2024-06-14T02:40:44.131+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:40:44.132+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:40:44.132+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:40:44.132+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:40:44.132+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:40:44.132+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:40:44.132+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:40:44.132+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:40:44.133+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:40:44.133+0530] {subprocess.py:93} INFO - 24/06/14 02:40:43 WARN Executor: Issue communicating with driver in heartbeater
[2024-06-14T02:40:44.133+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:40:44.133+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:40:44.133+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:40:44.133+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:40:44.133+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2024-06-14T02:40:44.134+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2024-06-14T02:40:44.134+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2024-06-14T02:40:44.134+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2024-06-14T02:40:44.134+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2024-06-14T02:40:44.134+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2024-06-14T02:40:44.134+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:40:44.134+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2024-06-14T02:40:44.134+0530] {subprocess.py:93} INFO - 	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2024-06-14T02:40:44.135+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2024-06-14T02:40:44.135+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2024-06-14T02:40:44.135+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2024-06-14T02:40:44.135+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:40:44.135+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:40:44.135+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:40:44.136+0530] {subprocess.py:93} INFO - Caused by: java.lang.NullPointerException
[2024-06-14T02:40:44.136+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:677)
[2024-06-14T02:40:44.136+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:40:44.136+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:40:44.136+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:40:44.136+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:40:44.136+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:40:44.136+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:40:44.137+0530] {subprocess.py:93} INFO - 	... 3 more
[2024-06-14T02:40:45.962+0530] {subprocess.py:93} INFO - 24/06/14 02:40:45 ERROR Inbox: Ignoring error
[2024-06-14T02:40:46.308+0530] {subprocess.py:93} INFO - java.lang.NullPointerException
[2024-06-14T02:40:46.339+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:677)
[2024-06-14T02:40:46.339+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:40:46.340+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:40:46.340+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:40:46.340+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:40:46.340+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:40:46.340+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:40:46.340+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:40:46.341+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:40:46.341+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:40:46.341+0530] {subprocess.py:93} INFO - 24/06/14 02:40:45 WARN Executor: Issue communicating with driver in heartbeater
[2024-06-14T02:40:46.341+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:40:46.341+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:40:46.341+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:40:46.342+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:40:46.342+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2024-06-14T02:40:46.342+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2024-06-14T02:40:46.342+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2024-06-14T02:40:46.343+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2024-06-14T02:40:46.343+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2024-06-14T02:40:46.343+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2024-06-14T02:40:46.343+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:40:46.344+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2024-06-14T02:40:46.344+0530] {subprocess.py:93} INFO - 	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2024-06-14T02:40:46.344+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2024-06-14T02:40:46.344+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2024-06-14T02:40:46.345+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2024-06-14T02:40:46.345+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:40:46.345+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:40:46.346+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:40:46.350+0530] {subprocess.py:93} INFO - Caused by: java.lang.NullPointerException
[2024-06-14T02:40:46.351+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:677)
[2024-06-14T02:40:46.352+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:40:46.352+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:40:46.352+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:40:46.353+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:40:46.353+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:40:46.353+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:40:46.353+0530] {subprocess.py:93} INFO - 	... 3 more
[2024-06-14T02:41:01.901+0530] {subprocess.py:93} INFO - 24/06/14 02:40:59 ERROR Inbox: Ignoring error
[2024-06-14T02:41:02.630+0530] {subprocess.py:93} INFO - java.lang.NullPointerException
[2024-06-14T02:41:04.435+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:677)
[2024-06-14T02:41:05.155+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:41:05.569+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:41:05.911+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:41:05.922+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:41:05.922+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:41:05.922+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:41:05.923+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:41:05.923+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:41:05.923+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:41:05.923+0530] {subprocess.py:93} INFO - 24/06/14 02:40:59 WARN Executor: Issue communicating with driver in heartbeater
[2024-06-14T02:41:05.923+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:41:05.924+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:41:05.924+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:41:05.924+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:41:05.924+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2024-06-14T02:41:05.924+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2024-06-14T02:41:05.924+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2024-06-14T02:41:05.925+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2024-06-14T02:41:05.925+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2024-06-14T02:41:05.925+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2024-06-14T02:41:05.925+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:41:05.925+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2024-06-14T02:41:05.925+0530] {subprocess.py:93} INFO - 	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2024-06-14T02:41:05.926+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2024-06-14T02:41:05.926+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2024-06-14T02:41:05.926+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2024-06-14T02:41:05.927+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:41:05.927+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:41:05.927+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:41:05.927+0530] {subprocess.py:93} INFO - Caused by: java.lang.NullPointerException
[2024-06-14T02:41:05.927+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:677)
[2024-06-14T02:41:05.927+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:41:05.927+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:41:05.927+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:41:05.927+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:41:05.927+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:41:05.928+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:41:05.928+0530] {subprocess.py:93} INFO - 	... 3 more
[2024-06-14T02:41:14.351+0530] {subprocess.py:93} INFO - 24/06/14 02:41:13 ERROR Inbox: Ignoring error
[2024-06-14T02:41:14.908+0530] {subprocess.py:93} INFO - java.lang.NullPointerException
[2024-06-14T02:41:15.061+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:677)
[2024-06-14T02:41:15.061+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:41:15.062+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:41:15.062+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:41:15.062+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:41:15.062+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:41:15.063+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:41:15.063+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:41:15.064+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:41:15.064+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:41:15.064+0530] {subprocess.py:93} INFO - 24/06/14 02:41:13 WARN Executor: Issue communicating with driver in heartbeater
[2024-06-14T02:41:15.065+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:41:15.065+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:41:15.065+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:41:15.066+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:41:15.067+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2024-06-14T02:41:15.067+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2024-06-14T02:41:15.067+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2024-06-14T02:41:15.067+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2024-06-14T02:41:15.067+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2024-06-14T02:41:15.068+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2024-06-14T02:41:15.071+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:41:15.071+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2024-06-14T02:41:15.071+0530] {subprocess.py:93} INFO - 	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2024-06-14T02:41:15.071+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2024-06-14T02:41:15.071+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2024-06-14T02:41:15.072+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2024-06-14T02:41:15.072+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:41:15.072+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:41:15.072+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:41:15.072+0530] {subprocess.py:93} INFO - Caused by: java.lang.NullPointerException
[2024-06-14T02:41:15.072+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:677)
[2024-06-14T02:41:15.072+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:41:15.072+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:41:15.073+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:41:15.135+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:41:15.136+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:41:15.136+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:41:15.137+0530] {subprocess.py:93} INFO - 	... 3 more
[2024-06-14T02:41:20.951+0530] {subprocess.py:93} INFO - 24/06/14 02:41:20 ERROR Inbox: Ignoring error
[2024-06-14T02:41:21.117+0530] {subprocess.py:93} INFO - java.lang.NullPointerException
[2024-06-14T02:41:21.244+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:677)
[2024-06-14T02:41:21.258+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:41:21.259+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:41:21.259+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:41:21.259+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:41:21.259+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:41:21.259+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:41:21.260+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:41:21.260+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:41:21.260+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:41:21.260+0530] {subprocess.py:93} INFO - 24/06/14 02:41:20 WARN Executor: Issue communicating with driver in heartbeater
[2024-06-14T02:41:21.260+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:41:21.261+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:41:21.261+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:41:21.261+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:41:21.261+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2024-06-14T02:41:21.261+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2024-06-14T02:41:21.262+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2024-06-14T02:41:21.262+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2024-06-14T02:41:21.262+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2024-06-14T02:41:21.262+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2024-06-14T02:41:21.262+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:41:21.262+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2024-06-14T02:41:21.263+0530] {subprocess.py:93} INFO - 	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2024-06-14T02:41:21.263+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2024-06-14T02:41:21.263+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2024-06-14T02:41:21.263+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2024-06-14T02:41:21.264+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:41:21.264+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:41:21.264+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:41:21.264+0530] {subprocess.py:93} INFO - Caused by: java.lang.NullPointerException
[2024-06-14T02:41:21.265+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:677)
[2024-06-14T02:41:21.265+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:41:21.265+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:41:21.265+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:41:21.266+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:41:21.266+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:41:21.266+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:41:21.266+0530] {subprocess.py:93} INFO - 	... 3 more
[2024-06-14T02:41:26.335+0530] {subprocess.py:93} INFO - 24/06/14 02:41:25 ERROR Inbox: Ignoring error
[2024-06-14T02:41:26.572+0530] {subprocess.py:93} INFO - java.lang.NullPointerException
[2024-06-14T02:41:26.809+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:677)
[2024-06-14T02:41:26.816+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:41:26.816+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:41:26.816+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:41:26.817+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:41:26.817+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:41:26.817+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:41:26.817+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:41:26.817+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:41:26.817+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:41:26.817+0530] {subprocess.py:93} INFO - 24/06/14 02:41:25 WARN Executor: Issue communicating with driver in heartbeater
[2024-06-14T02:41:26.817+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:41:26.817+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:41:26.817+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:41:26.818+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:41:26.818+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2024-06-14T02:41:26.818+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2024-06-14T02:41:26.818+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2024-06-14T02:41:26.818+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2024-06-14T02:41:26.818+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2024-06-14T02:41:26.818+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2024-06-14T02:41:26.819+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:41:26.819+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2024-06-14T02:41:26.819+0530] {subprocess.py:93} INFO - 	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2024-06-14T02:41:26.819+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2024-06-14T02:41:26.819+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2024-06-14T02:41:26.819+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2024-06-14T02:41:26.819+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:41:26.819+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:41:26.820+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:41:26.820+0530] {subprocess.py:93} INFO - Caused by: java.lang.NullPointerException
[2024-06-14T02:41:26.820+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:677)
[2024-06-14T02:41:26.820+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:41:26.820+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:41:26.820+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:41:26.820+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:41:26.820+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:41:26.821+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:41:26.821+0530] {subprocess.py:93} INFO - 	... 3 more
[2024-06-14T02:41:49.205+0530] {subprocess.py:93} INFO - 24/06/14 02:41:47 ERROR Inbox: Ignoring error
[2024-06-14T02:41:50.325+0530] {subprocess.py:93} INFO - java.lang.NullPointerException
[2024-06-14T02:41:51.035+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:677)
[2024-06-14T02:41:52.521+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:41:52.844+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:41:53.292+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:41:53.293+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:41:53.293+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:41:53.294+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:41:53.294+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:41:53.294+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:41:53.294+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:41:53.298+0530] {subprocess.py:93} INFO - 24/06/14 02:41:47 WARN Executor: Issue communicating with driver in heartbeater
[2024-06-14T02:41:53.299+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:41:53.299+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:41:53.299+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:41:53.299+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:41:53.300+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2024-06-14T02:41:53.300+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2024-06-14T02:41:53.300+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2024-06-14T02:41:53.300+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2024-06-14T02:41:53.300+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2024-06-14T02:41:53.300+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2024-06-14T02:41:53.301+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:41:53.301+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2024-06-14T02:41:53.301+0530] {subprocess.py:93} INFO - 	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2024-06-14T02:41:53.301+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2024-06-14T02:41:53.302+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2024-06-14T02:41:53.302+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2024-06-14T02:41:53.302+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:41:53.302+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:41:53.302+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:41:53.302+0530] {subprocess.py:93} INFO - Caused by: java.lang.NullPointerException
[2024-06-14T02:41:53.303+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:677)
[2024-06-14T02:41:53.303+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:41:53.304+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:41:53.304+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:41:53.304+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:41:53.304+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:41:53.304+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:41:53.304+0530] {subprocess.py:93} INFO - 	... 3 more
[2024-06-14T02:42:14.817+0530] {subprocess.py:93} INFO - 24/06/14 02:42:14 ERROR Inbox: Ignoring error
[2024-06-14T02:42:14.937+0530] {subprocess.py:93} INFO - java.lang.NullPointerException
[2024-06-14T02:42:14.938+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:677)
[2024-06-14T02:42:14.938+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:42:14.939+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:42:14.939+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:42:14.939+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:42:14.939+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:42:14.939+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:42:14.939+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:42:14.939+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:42:14.939+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:42:14.940+0530] {subprocess.py:93} INFO - 24/06/14 02:42:14 WARN Executor: Issue communicating with driver in heartbeater
[2024-06-14T02:42:14.940+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:42:14.940+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:42:14.940+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:42:14.940+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:42:14.940+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2024-06-14T02:42:14.940+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2024-06-14T02:42:14.940+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2024-06-14T02:42:14.940+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2024-06-14T02:42:14.940+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2024-06-14T02:42:14.941+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2024-06-14T02:42:14.941+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:42:14.941+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2024-06-14T02:42:14.941+0530] {subprocess.py:93} INFO - 	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2024-06-14T02:42:14.941+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2024-06-14T02:42:14.942+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2024-06-14T02:42:14.943+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2024-06-14T02:42:14.944+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:42:14.945+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:42:14.945+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:42:14.946+0530] {subprocess.py:93} INFO - Caused by: java.lang.NullPointerException
[2024-06-14T02:42:14.946+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:677)
[2024-06-14T02:42:14.946+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:42:14.946+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:42:14.947+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:42:14.947+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:42:14.948+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:42:14.948+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:42:14.949+0530] {subprocess.py:93} INFO - 	... 3 more
[2024-06-14T02:42:14.949+0530] {subprocess.py:93} INFO - 24/06/14 02:42:14 WARN Executor: Issue communicating with driver in heartbeater
[2024-06-14T02:42:14.949+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:42:14.950+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:42:14.950+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:42:14.950+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:42:14.951+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2024-06-14T02:42:14.951+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2024-06-14T02:42:14.951+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2024-06-14T02:42:14.951+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2024-06-14T02:42:14.952+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2024-06-14T02:42:14.952+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2024-06-14T02:42:14.952+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:42:14.952+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2024-06-14T02:42:14.953+0530] {subprocess.py:93} INFO - 	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2024-06-14T02:42:14.953+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2024-06-14T02:42:14.953+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2024-06-14T02:42:14.953+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2024-06-14T02:42:14.953+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:42:14.954+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:42:14.954+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:42:14.954+0530] {subprocess.py:93} INFO - Caused by: java.lang.NullPointerException
[2024-06-14T02:42:14.955+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:677)
[2024-06-14T02:42:14.955+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:42:14.955+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:42:14.956+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:42:14.956+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:42:14.956+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:42:14.956+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:42:14.956+0530] {subprocess.py:93} INFO - 	... 3 more
[2024-06-14T02:42:14.957+0530] {subprocess.py:93} INFO - 24/06/14 02:42:14 ERROR Inbox: Ignoring error
[2024-06-14T02:42:14.957+0530] {subprocess.py:93} INFO - java.lang.NullPointerException
[2024-06-14T02:42:14.957+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:677)
[2024-06-14T02:42:14.957+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:42:14.957+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:42:14.957+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:42:14.957+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:42:14.957+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:42:14.958+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:42:14.958+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:42:14.958+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:42:14.958+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:42:15.813+0530] {subprocess.py:93} INFO - 24/06/14 02:42:15 ERROR Inbox: Ignoring error
[2024-06-14T02:42:15.994+0530] {subprocess.py:93} INFO - java.lang.NullPointerException
[2024-06-14T02:42:16.023+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:677)
[2024-06-14T02:42:16.023+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:42:16.024+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:42:16.024+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:42:16.024+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:42:16.024+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:42:16.024+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:42:16.024+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:42:16.024+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:42:16.025+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:42:16.025+0530] {subprocess.py:93} INFO - 24/06/14 02:42:15 WARN Executor: Issue communicating with driver in heartbeater
[2024-06-14T02:42:16.025+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:42:16.025+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:42:16.025+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:42:16.025+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:42:16.025+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2024-06-14T02:42:16.025+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2024-06-14T02:42:16.025+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2024-06-14T02:42:16.026+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2024-06-14T02:42:16.026+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2024-06-14T02:42:16.026+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2024-06-14T02:42:16.026+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:42:16.026+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2024-06-14T02:42:16.026+0530] {subprocess.py:93} INFO - 	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2024-06-14T02:42:16.026+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2024-06-14T02:42:16.026+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2024-06-14T02:42:16.027+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2024-06-14T02:42:16.027+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:42:16.027+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:42:16.027+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:42:16.027+0530] {subprocess.py:93} INFO - Caused by: java.lang.NullPointerException
[2024-06-14T02:42:16.027+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:677)
[2024-06-14T02:42:16.027+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:42:16.027+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:42:16.027+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:42:16.028+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:42:16.028+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:42:16.028+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:42:16.028+0530] {subprocess.py:93} INFO - 	... 3 more
[2024-06-14T02:42:18.468+0530] {subprocess.py:93} INFO - 24/06/14 02:42:18 ERROR Inbox: Ignoring error
[2024-06-14T02:42:18.625+0530] {subprocess.py:93} INFO - java.lang.NullPointerException
[2024-06-14T02:42:18.630+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:677)
[2024-06-14T02:42:18.631+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:42:18.631+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:42:18.631+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:42:18.631+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:42:18.631+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:42:18.631+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:42:18.632+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:42:18.632+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:42:18.632+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:42:18.632+0530] {subprocess.py:93} INFO - 24/06/14 02:42:18 WARN Executor: Issue communicating with driver in heartbeater
[2024-06-14T02:42:18.632+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:42:18.632+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:42:18.632+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:42:18.632+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:42:18.632+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2024-06-14T02:42:18.632+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2024-06-14T02:42:18.633+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2024-06-14T02:42:18.633+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2024-06-14T02:42:18.633+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2024-06-14T02:42:18.633+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2024-06-14T02:42:18.633+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:42:18.633+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2024-06-14T02:42:18.633+0530] {subprocess.py:93} INFO - 	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2024-06-14T02:42:18.634+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2024-06-14T02:42:18.634+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2024-06-14T02:42:18.634+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2024-06-14T02:42:18.634+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:42:18.634+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:42:18.634+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:42:18.634+0530] {subprocess.py:93} INFO - Caused by: java.lang.NullPointerException
[2024-06-14T02:42:18.634+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:677)
[2024-06-14T02:42:18.634+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:42:18.635+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:42:18.635+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:42:18.635+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:42:18.635+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:42:18.635+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:42:18.635+0530] {subprocess.py:93} INFO - 	... 3 more
[2024-06-14T02:42:28.289+0530] {subprocess.py:93} INFO - 24/06/14 02:42:27 ERROR Inbox: Ignoring error
[2024-06-14T02:42:29.073+0530] {subprocess.py:93} INFO - java.lang.NullPointerException
[2024-06-14T02:42:29.762+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:677)
[2024-06-14T02:42:30.312+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:42:31.074+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:42:31.795+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:42:32.183+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:42:32.548+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:42:33.648+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:42:35.458+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:42:35.822+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:42:36.997+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:42:37.372+0530] {subprocess.py:93} INFO - 24/06/14 02:42:27 WARN Executor: Issue communicating with driver in heartbeater
[2024-06-14T02:42:38.147+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:42:39.409+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:42:39.941+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:42:40.065+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:42:40.065+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2024-06-14T02:42:40.065+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2024-06-14T02:42:40.066+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2024-06-14T02:42:40.066+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2024-06-14T02:42:40.066+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2024-06-14T02:42:40.066+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2024-06-14T02:42:40.066+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:42:40.067+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2024-06-14T02:42:40.067+0530] {subprocess.py:93} INFO - 	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2024-06-14T02:42:40.067+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2024-06-14T02:42:40.067+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2024-06-14T02:42:40.067+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2024-06-14T02:42:40.067+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:42:40.067+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:42:40.067+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:42:40.068+0530] {subprocess.py:93} INFO - Caused by: java.lang.NullPointerException
[2024-06-14T02:42:40.068+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:677)
[2024-06-14T02:42:40.068+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:42:40.068+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:42:40.068+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:42:40.068+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:42:40.068+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:42:40.068+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:42:40.068+0530] {subprocess.py:93} INFO - 	... 3 more
[2024-06-14T02:42:41.237+0530] {subprocess.py:93} INFO - 24/06/14 02:42:40 ERROR Inbox: Ignoring error
[2024-06-14T02:42:41.868+0530] {subprocess.py:93} INFO - java.lang.NullPointerException
[2024-06-14T02:42:42.901+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:677)
[2024-06-14T02:42:43.494+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:42:43.938+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:42:44.216+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:42:44.674+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:42:45.077+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:42:45.548+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:42:45.820+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:42:46.047+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:42:46.091+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:42:46.091+0530] {subprocess.py:93} INFO - 24/06/14 02:42:40 WARN Executor: Issue communicating with driver in heartbeater
[2024-06-14T02:42:46.092+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:42:46.092+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:42:46.092+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:42:46.092+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:42:46.093+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2024-06-14T02:42:46.093+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2024-06-14T02:42:46.093+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2024-06-14T02:42:46.094+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2024-06-14T02:42:46.094+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2024-06-14T02:42:46.094+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2024-06-14T02:42:46.095+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:42:46.095+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2024-06-14T02:42:46.095+0530] {subprocess.py:93} INFO - 	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2024-06-14T02:42:46.095+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2024-06-14T02:42:46.096+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2024-06-14T02:42:46.096+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2024-06-14T02:42:46.096+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:42:46.096+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:42:46.097+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:42:46.097+0530] {subprocess.py:93} INFO - Caused by: java.lang.NullPointerException
[2024-06-14T02:42:46.097+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:677)
[2024-06-14T02:42:46.097+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:42:46.098+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:42:46.098+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:42:46.098+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:42:46.098+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:42:46.099+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:42:46.099+0530] {subprocess.py:93} INFO - 	... 3 more
[2024-06-14T02:42:50.929+0530] {subprocess.py:93} INFO - 24/06/14 02:42:50 ERROR Inbox: Ignoring error
[2024-06-14T02:42:51.474+0530] {subprocess.py:93} INFO - java.lang.NullPointerException
[2024-06-14T02:42:52.010+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:677)
[2024-06-14T02:42:52.897+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:42:54.080+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:42:55.288+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:42:56.571+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:42:57.134+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:42:57.331+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:42:57.331+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:42:57.332+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:42:57.332+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:42:57.332+0530] {subprocess.py:93} INFO - 24/06/14 02:42:50 WARN Executor: Issue communicating with driver in heartbeater
[2024-06-14T02:42:57.333+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:42:57.333+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:42:57.334+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:42:57.334+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:42:57.334+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2024-06-14T02:42:57.334+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2024-06-14T02:42:57.334+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2024-06-14T02:42:57.334+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2024-06-14T02:42:57.335+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2024-06-14T02:42:57.335+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2024-06-14T02:42:57.335+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:42:57.335+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2024-06-14T02:42:57.335+0530] {subprocess.py:93} INFO - 	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2024-06-14T02:42:57.335+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2024-06-14T02:42:57.335+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2024-06-14T02:42:57.335+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2024-06-14T02:42:57.335+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:42:57.336+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:42:57.336+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:42:57.336+0530] {subprocess.py:93} INFO - Caused by: java.lang.NullPointerException
[2024-06-14T02:42:57.336+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:677)
[2024-06-14T02:42:57.336+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:42:57.336+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:42:57.336+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:42:57.336+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:42:57.336+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:42:57.336+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:42:57.337+0530] {subprocess.py:93} INFO - 	... 3 more
[2024-06-14T02:43:00.160+0530] {subprocess.py:93} INFO - 24/06/14 02:42:58 ERROR Inbox: Ignoring error
[2024-06-14T02:43:00.638+0530] {subprocess.py:93} INFO - java.lang.NullPointerException
[2024-06-14T02:43:01.605+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:677)
[2024-06-14T02:43:02.166+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:43:02.227+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:43:02.227+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:43:02.228+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:43:02.228+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:43:02.228+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:43:02.228+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:43:02.229+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:43:02.229+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:43:02.236+0530] {subprocess.py:93} INFO - 24/06/14 02:42:58 WARN Executor: Issue communicating with driver in heartbeater
[2024-06-14T02:43:02.236+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:43:02.236+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:43:02.237+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:43:02.237+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:43:02.237+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2024-06-14T02:43:02.237+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2024-06-14T02:43:02.237+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2024-06-14T02:43:02.238+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2024-06-14T02:43:02.238+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2024-06-14T02:43:02.238+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2024-06-14T02:43:02.238+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:43:02.239+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2024-06-14T02:43:02.239+0530] {subprocess.py:93} INFO - 	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2024-06-14T02:43:02.239+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2024-06-14T02:43:02.239+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2024-06-14T02:43:02.239+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2024-06-14T02:43:02.239+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:43:02.240+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:43:02.240+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:43:02.240+0530] {subprocess.py:93} INFO - Caused by: java.lang.NullPointerException
[2024-06-14T02:43:02.240+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:677)
[2024-06-14T02:43:02.241+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:43:02.242+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:43:02.242+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:43:02.243+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:43:02.244+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:43:02.244+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:43:02.244+0530] {subprocess.py:93} INFO - 	... 3 more
[2024-06-14T02:43:08.590+0530] {subprocess.py:93} INFO - 24/06/14 02:43:07 ERROR Inbox: Ignoring error
[2024-06-14T02:43:09.750+0530] {subprocess.py:93} INFO - java.lang.NullPointerException
[2024-06-14T02:43:10.263+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:677)
[2024-06-14T02:43:10.631+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:43:10.680+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:43:10.680+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:43:10.680+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:43:10.681+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:43:10.681+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:43:10.681+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:43:10.681+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:43:10.681+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:43:10.695+0530] {subprocess.py:93} INFO - 24/06/14 02:43:07 WARN Executor: Issue communicating with driver in heartbeater
[2024-06-14T02:43:10.695+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:43:10.696+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:43:10.696+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:43:10.696+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:43:10.696+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2024-06-14T02:43:10.697+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2024-06-14T02:43:10.697+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2024-06-14T02:43:10.697+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2024-06-14T02:43:10.697+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2024-06-14T02:43:10.697+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2024-06-14T02:43:10.697+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:43:10.697+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2024-06-14T02:43:10.697+0530] {subprocess.py:93} INFO - 	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2024-06-14T02:43:10.698+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2024-06-14T02:43:10.698+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2024-06-14T02:43:10.698+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2024-06-14T02:43:10.698+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:43:10.698+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:43:10.698+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:43:10.698+0530] {subprocess.py:93} INFO - Caused by: java.lang.NullPointerException
[2024-06-14T02:43:10.698+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:677)
[2024-06-14T02:43:10.698+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:43:10.699+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:43:10.699+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:43:10.699+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:43:10.699+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:43:10.700+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:43:10.700+0530] {subprocess.py:93} INFO - 	... 3 more
[2024-06-14T02:43:47.391+0530] {subprocess.py:93} INFO - 24/06/14 02:43:46 ERROR Inbox: Ignoring error
[2024-06-14T02:43:47.522+0530] {subprocess.py:93} INFO - java.lang.NullPointerException
[2024-06-14T02:43:47.522+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:677)
[2024-06-14T02:43:47.523+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:43:47.523+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:43:47.523+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:43:47.523+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:43:47.524+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:43:47.524+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:43:47.524+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:43:47.524+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:43:47.525+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:43:47.525+0530] {subprocess.py:93} INFO - 24/06/14 02:43:46 WARN Executor: Issue communicating with driver in heartbeater
[2024-06-14T02:43:47.525+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:43:47.525+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:43:47.525+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:43:47.525+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:43:47.525+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2024-06-14T02:43:47.526+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2024-06-14T02:43:47.526+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2024-06-14T02:43:47.526+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2024-06-14T02:43:47.526+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2024-06-14T02:43:47.526+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2024-06-14T02:43:47.526+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:43:47.527+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2024-06-14T02:43:47.527+0530] {subprocess.py:93} INFO - 	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2024-06-14T02:43:47.527+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2024-06-14T02:43:47.527+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2024-06-14T02:43:47.527+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2024-06-14T02:43:47.527+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:43:47.528+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:43:47.528+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:43:47.528+0530] {subprocess.py:93} INFO - Caused by: java.lang.NullPointerException
[2024-06-14T02:43:47.528+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:677)
[2024-06-14T02:43:47.528+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:43:47.529+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:43:47.529+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:43:47.529+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:43:47.529+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:43:47.530+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:43:47.530+0530] {subprocess.py:93} INFO - 	... 3 more
[2024-06-14T02:43:56.522+0530] {subprocess.py:93} INFO - 24/06/14 02:43:55 ERROR Inbox: Ignoring error
[2024-06-14T02:43:56.671+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:43:56.672+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:43:56.672+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:43:56.672+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:43:56.672+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2024-06-14T02:43:56.672+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2024-06-14T02:43:56.673+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2024-06-14T02:43:56.673+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2024-06-14T02:43:56.673+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2024-06-14T02:43:56.673+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2024-06-14T02:43:56.673+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2024-06-14T02:43:56.673+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2024-06-14T02:43:56.673+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:43:56.673+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:43:56.674+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:43:56.674+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:43:56.674+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:43:56.674+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:43:56.674+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:43:56.675+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:43:56.675+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:43:56.675+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.56.255:38347
[2024-06-14T02:43:56.675+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2024-06-14T02:43:56.675+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2024-06-14T02:43:56.676+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2024-06-14T02:43:56.676+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2024-06-14T02:43:56.676+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:43:56.676+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:43:56.676+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:43:56.676+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:43:56.676+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:43:56.677+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:43:56.677+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:43:56.677+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:43:56.677+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:43:56.677+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:43:56.677+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:43:56.678+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:43:56.678+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:43:56.678+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:43:56.678+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:43:56.678+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:43:56.678+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:43:56.678+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:43:56.678+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:43:56.678+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:43:56.679+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:43:56.679+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:43:56.679+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:43:56.679+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2024-06-14T02:43:56.679+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2024-06-14T02:43:56.679+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:43:56.680+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2024-06-14T02:43:56.680+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2024-06-14T02:43:56.680+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2024-06-14T02:43:56.681+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2024-06-14T02:43:56.681+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2024-06-14T02:43:56.681+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2024-06-14T02:43:56.681+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:43:56.681+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:43:56.687+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:43:56.688+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:43:56.688+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2024-06-14T02:43:56.688+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2024-06-14T02:43:56.689+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2024-06-14T02:43:56.689+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2024-06-14T02:43:56.689+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2024-06-14T02:43:56.690+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2024-06-14T02:43:56.690+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:43:56.690+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:43:56.692+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:43:56.692+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:43:56.693+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:43:56.693+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:43:56.693+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:43:56.694+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:43:56.694+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:43:56.694+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:43:56.695+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success(Promise.scala:86)
[2024-06-14T02:43:56.695+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success$(Promise.scala:86)
[2024-06-14T02:43:56.695+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2024-06-14T02:43:56.695+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2024-06-14T02:43:56.696+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2024-06-14T02:43:56.696+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2024-06-14T02:43:56.696+0530] {subprocess.py:93} INFO - 	... 8 more
[2024-06-14T02:43:56.697+0530] {subprocess.py:93} INFO - 24/06/14 02:43:55 WARN Executor: Issue communicating with driver in heartbeater
[2024-06-14T02:43:56.697+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:43:56.698+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:43:56.698+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:43:56.698+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:43:56.698+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2024-06-14T02:43:56.699+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2024-06-14T02:43:56.699+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2024-06-14T02:43:56.699+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2024-06-14T02:43:56.699+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2024-06-14T02:43:56.699+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2024-06-14T02:43:56.700+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:43:56.700+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2024-06-14T02:43:56.700+0530] {subprocess.py:93} INFO - 	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2024-06-14T02:43:56.700+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2024-06-14T02:43:56.701+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2024-06-14T02:43:56.701+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2024-06-14T02:43:56.701+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:43:56.702+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:43:56.702+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:43:56.702+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:43:56.702+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:43:56.703+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:43:56.703+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:43:56.703+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2024-06-14T02:43:56.703+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2024-06-14T02:43:56.703+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2024-06-14T02:43:56.704+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2024-06-14T02:43:56.704+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2024-06-14T02:43:56.704+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2024-06-14T02:43:56.704+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2024-06-14T02:43:56.705+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2024-06-14T02:43:56.705+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:43:56.705+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:43:56.706+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:43:56.706+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:43:56.706+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:43:56.707+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:43:56.707+0530] {subprocess.py:93} INFO - 	... 3 more
[2024-06-14T02:43:56.707+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.56.255:38347
[2024-06-14T02:43:56.707+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2024-06-14T02:43:56.707+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2024-06-14T02:43:56.708+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2024-06-14T02:43:56.708+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2024-06-14T02:43:56.708+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:43:56.709+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:43:56.709+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:43:56.709+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:43:56.709+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:43:56.710+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:43:56.710+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:43:56.710+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:43:56.711+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:43:56.711+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:43:56.711+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:43:56.711+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:43:56.712+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:43:56.712+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:43:56.712+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:43:56.712+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:43:56.712+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:43:56.713+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:43:56.713+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:43:56.713+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:43:56.713+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:43:56.714+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:43:56.714+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:43:56.714+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2024-06-14T02:43:56.714+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2024-06-14T02:43:56.714+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:43:56.714+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2024-06-14T02:43:56.714+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2024-06-14T02:43:56.715+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2024-06-14T02:43:56.715+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2024-06-14T02:43:56.715+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2024-06-14T02:43:56.715+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2024-06-14T02:43:56.715+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:43:56.715+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:43:56.716+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:43:56.716+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:43:56.716+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2024-06-14T02:43:56.716+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2024-06-14T02:43:56.716+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2024-06-14T02:43:56.716+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2024-06-14T02:43:56.717+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2024-06-14T02:43:56.718+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2024-06-14T02:43:56.718+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:43:56.718+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:43:56.718+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:43:56.718+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:43:56.719+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:43:56.719+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:43:56.719+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:43:56.719+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:43:56.719+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:43:56.719+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:43:56.719+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success(Promise.scala:86)
[2024-06-14T02:43:56.719+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success$(Promise.scala:86)
[2024-06-14T02:43:56.720+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2024-06-14T02:43:56.720+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2024-06-14T02:43:56.720+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2024-06-14T02:43:56.720+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2024-06-14T02:43:56.720+0530] {subprocess.py:93} INFO - 	... 8 more
[2024-06-14T02:43:58.320+0530] {subprocess.py:93} INFO - 24/06/14 02:43:57 ERROR Inbox: Ignoring error
[2024-06-14T02:43:58.470+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:43:58.478+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:43:58.479+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:43:58.479+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:43:58.479+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2024-06-14T02:43:58.479+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2024-06-14T02:43:58.479+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2024-06-14T02:43:58.479+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2024-06-14T02:43:58.480+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2024-06-14T02:43:58.480+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2024-06-14T02:43:58.480+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2024-06-14T02:43:58.480+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2024-06-14T02:43:58.480+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:43:58.480+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:43:58.481+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:43:58.481+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:43:58.481+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:43:58.481+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:43:58.481+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:43:58.482+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:43:58.482+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:43:58.482+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.56.255:38347
[2024-06-14T02:43:58.482+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2024-06-14T02:43:58.482+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2024-06-14T02:43:58.482+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2024-06-14T02:43:58.483+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2024-06-14T02:43:58.483+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:43:58.483+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:43:58.483+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:43:58.483+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:43:58.483+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:43:58.484+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:43:58.484+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:43:58.484+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:43:58.484+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:43:58.484+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:43:58.484+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:43:58.484+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:43:58.485+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:43:58.485+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:43:58.485+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:43:58.485+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:43:58.485+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:43:58.485+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:43:58.486+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:43:58.486+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:43:58.486+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:43:58.486+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:43:58.486+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:43:58.486+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2024-06-14T02:43:58.487+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2024-06-14T02:43:58.487+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:43:58.487+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2024-06-14T02:43:58.487+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2024-06-14T02:43:58.487+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2024-06-14T02:43:58.487+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2024-06-14T02:43:58.488+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2024-06-14T02:43:58.488+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2024-06-14T02:43:58.488+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:43:58.488+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:43:58.488+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:43:58.488+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:43:58.488+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2024-06-14T02:43:58.489+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2024-06-14T02:43:58.489+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2024-06-14T02:43:58.489+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2024-06-14T02:43:58.489+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2024-06-14T02:43:58.489+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2024-06-14T02:43:58.489+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:43:58.490+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:43:58.490+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:43:58.490+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:43:58.490+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:43:58.490+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:43:58.490+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:43:58.490+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:43:58.491+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:43:58.491+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:43:58.491+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success(Promise.scala:86)
[2024-06-14T02:43:58.492+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success$(Promise.scala:86)
[2024-06-14T02:43:58.492+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2024-06-14T02:43:58.492+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2024-06-14T02:43:58.492+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2024-06-14T02:43:58.492+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2024-06-14T02:43:58.492+0530] {subprocess.py:93} INFO - 	... 8 more
[2024-06-14T02:43:58.492+0530] {subprocess.py:93} INFO - 24/06/14 02:43:57 WARN Executor: Issue communicating with driver in heartbeater
[2024-06-14T02:43:58.493+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:43:58.493+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:43:58.493+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:43:58.493+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:43:58.493+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2024-06-14T02:43:58.493+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2024-06-14T02:43:58.493+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2024-06-14T02:43:58.493+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2024-06-14T02:43:58.493+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2024-06-14T02:43:58.494+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2024-06-14T02:43:58.494+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:43:58.494+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2024-06-14T02:43:58.494+0530] {subprocess.py:93} INFO - 	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2024-06-14T02:43:58.494+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2024-06-14T02:43:58.494+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2024-06-14T02:43:58.494+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2024-06-14T02:43:58.494+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:43:58.494+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:43:58.495+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:43:58.495+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:43:58.495+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:43:58.495+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:43:58.495+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:43:58.495+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2024-06-14T02:43:58.495+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2024-06-14T02:43:58.496+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2024-06-14T02:43:58.496+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2024-06-14T02:43:58.497+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2024-06-14T02:43:58.497+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2024-06-14T02:43:58.497+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2024-06-14T02:43:58.497+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2024-06-14T02:43:58.498+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:43:58.498+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:43:58.498+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:43:58.498+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:43:58.498+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:43:58.498+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:43:58.498+0530] {subprocess.py:93} INFO - 	... 3 more
[2024-06-14T02:43:58.498+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.56.255:38347
[2024-06-14T02:43:58.499+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2024-06-14T02:43:58.499+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2024-06-14T02:43:58.499+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2024-06-14T02:43:58.499+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2024-06-14T02:43:58.499+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:43:58.499+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:43:58.499+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:43:58.499+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:43:58.500+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:43:58.500+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:43:58.500+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:43:58.500+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:43:58.500+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:43:58.500+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:43:58.500+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:43:58.500+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:43:58.500+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:43:58.500+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:43:58.501+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:43:58.501+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:43:58.501+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:43:58.501+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:43:58.501+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:43:58.501+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:43:58.502+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:43:58.502+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:43:58.502+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:43:58.502+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2024-06-14T02:43:58.503+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2024-06-14T02:43:58.503+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:43:58.503+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2024-06-14T02:43:58.503+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2024-06-14T02:43:58.503+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2024-06-14T02:43:58.504+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2024-06-14T02:43:58.504+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2024-06-14T02:43:58.504+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2024-06-14T02:43:58.504+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:43:58.504+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:43:58.504+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:43:58.504+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:43:58.505+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2024-06-14T02:43:58.505+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2024-06-14T02:43:58.505+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2024-06-14T02:43:58.505+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2024-06-14T02:43:58.505+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2024-06-14T02:43:58.505+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2024-06-14T02:43:58.505+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:43:58.506+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:43:58.506+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:43:58.507+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:43:58.507+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:43:58.507+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:43:58.508+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:43:58.508+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:43:58.508+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:43:58.509+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:43:58.509+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success(Promise.scala:86)
[2024-06-14T02:43:58.509+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success$(Promise.scala:86)
[2024-06-14T02:43:58.509+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2024-06-14T02:43:58.510+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2024-06-14T02:43:58.510+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2024-06-14T02:43:58.510+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2024-06-14T02:43:58.510+0530] {subprocess.py:93} INFO - 	... 8 more
[2024-06-14T02:44:01.318+0530] {subprocess.py:93} INFO - 24/06/14 02:43:59 ERROR Inbox: Ignoring error
[2024-06-14T02:44:01.770+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:44:01.933+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:44:02.559+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:44:03.394+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:44:03.395+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2024-06-14T02:44:03.395+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2024-06-14T02:44:03.395+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2024-06-14T02:44:03.395+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2024-06-14T02:44:03.395+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2024-06-14T02:44:03.395+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2024-06-14T02:44:03.395+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2024-06-14T02:44:03.396+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2024-06-14T02:44:03.396+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:44:03.396+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:44:03.396+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:44:03.396+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:44:03.396+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:44:03.396+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:44:03.396+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:44:03.396+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:44:03.396+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:44:03.396+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.56.255:38347
[2024-06-14T02:44:03.397+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2024-06-14T02:44:03.397+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2024-06-14T02:44:03.397+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2024-06-14T02:44:03.397+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2024-06-14T02:44:03.397+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:44:03.397+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:44:03.397+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:44:03.397+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:44:03.397+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:44:03.397+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:44:03.397+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:44:03.397+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:44:03.398+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:44:03.398+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:44:03.398+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:44:03.398+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:44:03.398+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:44:03.398+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:44:03.398+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:44:03.398+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:44:03.398+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:44:03.398+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:44:03.398+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:44:03.398+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:44:03.399+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:44:03.399+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:44:03.399+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:44:03.399+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2024-06-14T02:44:03.399+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2024-06-14T02:44:03.399+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:44:03.399+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2024-06-14T02:44:03.399+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2024-06-14T02:44:03.399+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2024-06-14T02:44:03.399+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2024-06-14T02:44:03.399+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2024-06-14T02:44:03.400+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2024-06-14T02:44:03.400+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:44:03.400+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:44:03.400+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:44:03.400+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:44:03.400+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2024-06-14T02:44:03.400+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2024-06-14T02:44:03.400+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2024-06-14T02:44:03.400+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2024-06-14T02:44:03.400+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2024-06-14T02:44:03.400+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2024-06-14T02:44:03.401+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:44:03.401+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:44:03.401+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:44:03.401+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:44:03.401+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:44:03.401+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:44:03.401+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:44:03.401+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:44:03.401+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:44:03.401+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:44:03.401+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success(Promise.scala:86)
[2024-06-14T02:44:03.402+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success$(Promise.scala:86)
[2024-06-14T02:44:03.402+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2024-06-14T02:44:03.402+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2024-06-14T02:44:03.402+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2024-06-14T02:44:03.402+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2024-06-14T02:44:03.402+0530] {subprocess.py:93} INFO - 	... 8 more
[2024-06-14T02:44:03.402+0530] {subprocess.py:93} INFO - 24/06/14 02:43:59 WARN Executor: Issue communicating with driver in heartbeater
[2024-06-14T02:44:03.402+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:44:03.402+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:44:03.402+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:44:03.402+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:44:03.402+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2024-06-14T02:44:03.403+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2024-06-14T02:44:03.403+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2024-06-14T02:44:03.403+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2024-06-14T02:44:03.403+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2024-06-14T02:44:03.403+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2024-06-14T02:44:03.403+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:44:03.403+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2024-06-14T02:44:03.403+0530] {subprocess.py:93} INFO - 	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2024-06-14T02:44:03.403+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2024-06-14T02:44:03.403+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2024-06-14T02:44:03.403+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2024-06-14T02:44:03.404+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:44:03.404+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:44:03.404+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:44:03.404+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:44:03.404+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:44:03.404+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:44:03.404+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:44:03.404+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2024-06-14T02:44:03.404+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2024-06-14T02:44:03.404+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2024-06-14T02:44:03.404+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2024-06-14T02:44:03.405+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2024-06-14T02:44:03.405+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2024-06-14T02:44:03.405+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2024-06-14T02:44:03.405+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2024-06-14T02:44:03.405+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:44:03.405+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:44:03.405+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:44:03.405+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:44:03.405+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:44:03.405+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:44:03.406+0530] {subprocess.py:93} INFO - 	... 3 more
[2024-06-14T02:44:03.406+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.56.255:38347
[2024-06-14T02:44:03.406+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2024-06-14T02:44:03.406+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2024-06-14T02:44:03.406+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2024-06-14T02:44:03.406+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2024-06-14T02:44:03.406+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:44:03.406+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:44:03.406+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:44:03.406+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:44:03.406+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:44:03.407+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:44:03.407+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:44:03.407+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:44:03.407+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:44:03.407+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:44:03.407+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:44:03.407+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:44:03.407+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:44:03.407+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:44:03.407+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:44:03.407+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:44:03.407+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:44:03.408+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:44:03.408+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:44:03.408+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:44:03.408+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:44:03.408+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:44:03.408+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:44:03.408+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2024-06-14T02:44:03.408+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2024-06-14T02:44:03.408+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:44:03.408+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2024-06-14T02:44:03.408+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2024-06-14T02:44:03.409+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2024-06-14T02:44:03.409+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2024-06-14T02:44:03.409+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2024-06-14T02:44:03.409+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2024-06-14T02:44:03.409+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:44:03.409+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:44:03.409+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:44:03.409+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:44:03.409+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2024-06-14T02:44:03.409+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2024-06-14T02:44:03.409+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2024-06-14T02:44:03.409+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2024-06-14T02:44:03.410+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2024-06-14T02:44:03.410+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2024-06-14T02:44:03.410+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:44:03.410+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:44:03.410+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:44:03.410+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:44:03.410+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:44:03.410+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:44:03.410+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:44:03.410+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:44:03.410+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:44:03.410+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:44:03.411+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success(Promise.scala:86)
[2024-06-14T02:44:03.411+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success$(Promise.scala:86)
[2024-06-14T02:44:03.411+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2024-06-14T02:44:03.411+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2024-06-14T02:44:03.411+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2024-06-14T02:44:03.411+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2024-06-14T02:44:03.411+0530] {subprocess.py:93} INFO - 	... 8 more
[2024-06-14T02:44:17.968+0530] {subprocess.py:93} INFO - 24/06/14 02:44:14 ERROR Inbox: Ignoring error
[2024-06-14T02:44:18.204+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:44:18.360+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:44:18.361+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:44:18.361+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:44:18.361+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2024-06-14T02:44:18.361+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2024-06-14T02:44:18.362+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2024-06-14T02:44:18.362+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2024-06-14T02:44:18.362+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2024-06-14T02:44:18.362+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2024-06-14T02:44:18.362+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2024-06-14T02:44:18.362+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2024-06-14T02:44:18.362+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:44:18.362+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:44:18.362+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:44:18.362+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:44:18.363+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:44:18.363+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:44:18.363+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:44:18.363+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:44:18.363+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:44:18.363+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.56.255:38347
[2024-06-14T02:44:18.364+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2024-06-14T02:44:18.364+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2024-06-14T02:44:18.364+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2024-06-14T02:44:18.364+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2024-06-14T02:44:18.364+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:44:18.364+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:44:18.364+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:44:18.364+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:44:18.365+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:44:18.365+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:44:18.365+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:44:18.365+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:44:18.365+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:44:18.365+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:44:18.365+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:44:18.365+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:44:18.366+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:44:18.366+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:44:18.366+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:44:18.366+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:44:18.366+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:44:18.366+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:44:18.366+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:44:18.366+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:44:18.366+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:44:18.367+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:44:18.367+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:44:18.367+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2024-06-14T02:44:18.367+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2024-06-14T02:44:18.367+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:44:18.367+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2024-06-14T02:44:18.367+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2024-06-14T02:44:18.367+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2024-06-14T02:44:18.367+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2024-06-14T02:44:18.367+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2024-06-14T02:44:18.368+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2024-06-14T02:44:18.368+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:44:18.368+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:44:18.368+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:44:18.368+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:44:18.368+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2024-06-14T02:44:18.368+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2024-06-14T02:44:18.368+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2024-06-14T02:44:18.368+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2024-06-14T02:44:18.368+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2024-06-14T02:44:18.369+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2024-06-14T02:44:18.369+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:44:18.369+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:44:18.369+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:44:18.369+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:44:18.369+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:44:18.369+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:44:18.369+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:44:18.369+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:44:18.369+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:44:18.370+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:44:18.370+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success(Promise.scala:86)
[2024-06-14T02:44:18.370+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success$(Promise.scala:86)
[2024-06-14T02:44:18.370+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2024-06-14T02:44:18.370+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2024-06-14T02:44:18.370+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2024-06-14T02:44:18.371+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2024-06-14T02:44:18.371+0530] {subprocess.py:93} INFO - 	... 8 more
[2024-06-14T02:44:18.371+0530] {subprocess.py:93} INFO - 24/06/14 02:44:14 WARN Executor: Issue communicating with driver in heartbeater
[2024-06-14T02:44:18.372+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:44:18.372+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:44:18.372+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:44:18.372+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:44:18.372+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2024-06-14T02:44:18.372+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2024-06-14T02:44:18.373+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2024-06-14T02:44:18.373+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2024-06-14T02:44:18.373+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2024-06-14T02:44:18.373+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2024-06-14T02:44:18.373+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:44:18.373+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2024-06-14T02:44:18.373+0530] {subprocess.py:93} INFO - 	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2024-06-14T02:44:18.374+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2024-06-14T02:44:18.374+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2024-06-14T02:44:18.374+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2024-06-14T02:44:18.375+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:44:18.375+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:44:18.375+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:44:18.375+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:44:18.375+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:44:18.375+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:44:18.376+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:44:18.376+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2024-06-14T02:44:18.376+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2024-06-14T02:44:18.376+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2024-06-14T02:44:18.376+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2024-06-14T02:44:18.377+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2024-06-14T02:44:18.377+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2024-06-14T02:44:18.377+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2024-06-14T02:44:18.377+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2024-06-14T02:44:18.377+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:44:18.377+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:44:18.377+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:44:18.377+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:44:18.378+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:44:18.379+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:44:18.379+0530] {subprocess.py:93} INFO - 	... 3 more
[2024-06-14T02:44:18.379+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.56.255:38347
[2024-06-14T02:44:18.379+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2024-06-14T02:44:18.379+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2024-06-14T02:44:18.380+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2024-06-14T02:44:18.380+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2024-06-14T02:44:18.380+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:44:18.380+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:44:18.380+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:44:18.381+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:44:18.381+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:44:18.381+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:44:18.382+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:44:18.382+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:44:18.382+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:44:18.382+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:44:18.382+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:44:18.383+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:44:18.383+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:44:18.383+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:44:18.383+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:44:18.384+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:44:18.384+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:44:18.384+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:44:18.384+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:44:18.385+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:44:18.385+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:44:18.385+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:44:18.385+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:44:18.385+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2024-06-14T02:44:18.386+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2024-06-14T02:44:18.386+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:44:18.386+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2024-06-14T02:44:18.386+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2024-06-14T02:44:18.386+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2024-06-14T02:44:18.387+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2024-06-14T02:44:18.387+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2024-06-14T02:44:18.387+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2024-06-14T02:44:18.387+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:44:18.387+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:44:18.388+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:44:18.388+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:44:18.388+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2024-06-14T02:44:18.388+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2024-06-14T02:44:18.388+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2024-06-14T02:44:18.389+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2024-06-14T02:44:18.389+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2024-06-14T02:44:18.389+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2024-06-14T02:44:18.389+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:44:18.390+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:44:18.390+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:44:18.390+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:44:18.390+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:44:18.390+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:44:18.390+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:44:18.390+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:44:18.391+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:44:18.391+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:44:18.391+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success(Promise.scala:86)
[2024-06-14T02:44:18.392+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success$(Promise.scala:86)
[2024-06-14T02:44:18.393+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2024-06-14T02:44:18.393+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2024-06-14T02:44:18.393+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2024-06-14T02:44:18.394+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2024-06-14T02:44:18.394+0530] {subprocess.py:93} INFO - 	... 8 more
[2024-06-14T02:44:42.194+0530] {subprocess.py:93} INFO - 24/06/14 02:44:37 ERROR Inbox: Ignoring error
[2024-06-14T02:44:42.824+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:44:43.075+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:44:43.206+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:44:43.207+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:44:43.207+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2024-06-14T02:44:43.207+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2024-06-14T02:44:43.208+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2024-06-14T02:44:43.208+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2024-06-14T02:44:43.208+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2024-06-14T02:44:43.208+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2024-06-14T02:44:43.208+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2024-06-14T02:44:43.208+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2024-06-14T02:44:43.208+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:44:43.209+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:44:43.209+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:44:43.209+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:44:43.209+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:44:43.209+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:44:43.209+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:44:43.209+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:44:43.209+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:44:43.210+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.56.255:38347
[2024-06-14T02:44:43.210+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2024-06-14T02:44:43.210+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2024-06-14T02:44:43.210+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2024-06-14T02:44:43.210+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2024-06-14T02:44:43.210+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:44:43.210+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:44:43.210+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:44:43.210+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:44:43.211+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:44:43.211+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:44:43.211+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:44:43.211+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:44:43.211+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:44:43.211+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:44:43.211+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:44:43.212+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:44:43.219+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:44:43.219+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:44:43.219+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:44:43.220+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:44:43.220+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:44:43.220+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:44:43.220+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:44:43.220+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:44:43.221+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:44:43.221+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:44:43.221+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:44:43.221+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2024-06-14T02:44:43.221+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2024-06-14T02:44:43.221+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:44:43.222+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2024-06-14T02:44:43.222+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2024-06-14T02:44:43.222+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2024-06-14T02:44:43.222+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2024-06-14T02:44:43.222+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2024-06-14T02:44:43.222+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2024-06-14T02:44:43.222+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:44:43.223+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:44:43.223+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:44:43.223+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:44:43.223+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2024-06-14T02:44:43.223+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2024-06-14T02:44:43.223+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2024-06-14T02:44:43.223+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2024-06-14T02:44:43.223+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2024-06-14T02:44:43.224+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2024-06-14T02:44:43.224+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:44:43.224+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:44:43.224+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:44:43.224+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:44:43.225+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:44:43.225+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:44:43.225+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:44:43.225+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:44:43.225+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:44:43.225+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:44:43.225+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success(Promise.scala:86)
[2024-06-14T02:44:43.225+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success$(Promise.scala:86)
[2024-06-14T02:44:43.226+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2024-06-14T02:44:43.226+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2024-06-14T02:44:43.226+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2024-06-14T02:44:43.226+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2024-06-14T02:44:43.226+0530] {subprocess.py:93} INFO - 	... 8 more
[2024-06-14T02:44:43.227+0530] {subprocess.py:93} INFO - 24/06/14 02:44:37 WARN Executor: Issue communicating with driver in heartbeater
[2024-06-14T02:44:43.227+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:44:43.227+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:44:43.227+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:44:43.228+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:44:43.228+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2024-06-14T02:44:43.228+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2024-06-14T02:44:43.228+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2024-06-14T02:44:43.229+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2024-06-14T02:44:43.229+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2024-06-14T02:44:43.229+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2024-06-14T02:44:43.229+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:44:43.229+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2024-06-14T02:44:43.230+0530] {subprocess.py:93} INFO - 	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2024-06-14T02:44:43.230+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2024-06-14T02:44:43.230+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2024-06-14T02:44:43.231+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2024-06-14T02:44:43.231+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:44:43.231+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:44:43.231+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:44:43.231+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:44:43.232+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:44:43.232+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:44:43.232+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:44:43.232+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2024-06-14T02:44:43.233+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2024-06-14T02:44:43.233+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2024-06-14T02:44:43.234+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2024-06-14T02:44:43.234+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2024-06-14T02:44:43.234+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2024-06-14T02:44:43.235+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2024-06-14T02:44:43.235+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2024-06-14T02:44:43.235+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:44:43.235+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:44:43.236+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:44:43.236+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:44:43.236+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:44:43.236+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:44:43.237+0530] {subprocess.py:93} INFO - 	... 3 more
[2024-06-14T02:44:43.237+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.56.255:38347
[2024-06-14T02:44:43.237+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2024-06-14T02:44:43.237+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2024-06-14T02:44:43.238+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2024-06-14T02:44:43.238+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2024-06-14T02:44:43.238+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:44:43.239+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:44:43.239+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:44:43.239+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:44:43.239+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:44:43.240+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:44:43.240+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:44:43.240+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:44:43.240+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:44:43.241+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:44:43.241+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:44:43.241+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:44:43.241+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:44:43.241+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:44:43.241+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:44:43.241+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:44:43.242+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:44:43.242+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:44:43.242+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:44:43.242+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:44:43.242+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:44:43.242+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:44:43.242+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:44:43.243+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2024-06-14T02:44:43.243+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2024-06-14T02:44:43.243+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:44:43.243+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2024-06-14T02:44:43.243+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2024-06-14T02:44:43.244+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2024-06-14T02:44:43.244+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2024-06-14T02:44:43.244+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2024-06-14T02:44:43.244+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2024-06-14T02:44:43.244+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:44:43.244+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:44:43.244+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:44:43.245+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:44:43.245+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2024-06-14T02:44:43.245+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2024-06-14T02:44:43.245+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2024-06-14T02:44:43.245+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2024-06-14T02:44:43.245+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2024-06-14T02:44:43.245+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2024-06-14T02:44:43.245+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:44:43.245+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:44:43.246+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:44:43.246+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:44:43.246+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:44:43.246+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:44:43.246+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:44:43.246+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:44:43.247+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:44:43.247+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:44:43.247+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success(Promise.scala:86)
[2024-06-14T02:44:43.247+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success$(Promise.scala:86)
[2024-06-14T02:44:43.247+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2024-06-14T02:44:43.247+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2024-06-14T02:44:43.247+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2024-06-14T02:44:43.247+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2024-06-14T02:44:43.247+0530] {subprocess.py:93} INFO - 	... 8 more
[2024-06-14T02:45:03.766+0530] {subprocess.py:93} INFO - 24/06/14 02:44:58 ERROR Inbox: Ignoring error
[2024-06-14T02:45:04.554+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:45:06.347+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:45:06.564+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:45:06.581+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:45:06.581+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2024-06-14T02:45:06.581+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2024-06-14T02:45:06.581+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2024-06-14T02:45:06.582+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2024-06-14T02:45:06.582+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2024-06-14T02:45:06.582+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2024-06-14T02:45:06.582+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2024-06-14T02:45:06.582+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2024-06-14T02:45:06.582+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:45:06.582+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:45:06.583+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:45:06.583+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:45:06.583+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:45:06.583+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:45:06.583+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:45:06.583+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:45:06.583+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:45:06.584+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.56.255:38347
[2024-06-14T02:45:06.584+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2024-06-14T02:45:06.584+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2024-06-14T02:45:06.584+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2024-06-14T02:45:06.584+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2024-06-14T02:45:06.584+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:45:06.584+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:45:06.584+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:45:06.585+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:45:06.585+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:45:06.585+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:45:06.585+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:45:06.585+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:45:06.585+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:45:06.585+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:45:06.586+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:45:06.586+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:45:06.586+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:45:06.586+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:45:06.586+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:45:06.586+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:45:06.586+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:45:06.586+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:45:06.587+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:45:06.587+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:45:06.587+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:45:06.587+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:45:06.587+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:45:06.587+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2024-06-14T02:45:06.587+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2024-06-14T02:45:06.587+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:45:06.587+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2024-06-14T02:45:06.587+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2024-06-14T02:45:06.587+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2024-06-14T02:45:06.588+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2024-06-14T02:45:06.588+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2024-06-14T02:45:06.588+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2024-06-14T02:45:06.588+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:45:06.588+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:45:06.588+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:45:06.588+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:45:06.588+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2024-06-14T02:45:06.588+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2024-06-14T02:45:06.589+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2024-06-14T02:45:06.589+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2024-06-14T02:45:06.589+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2024-06-14T02:45:06.589+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2024-06-14T02:45:06.589+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:45:06.589+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:45:06.589+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:45:06.589+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:45:06.589+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:45:06.590+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:45:06.590+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:45:06.590+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:45:06.590+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:45:06.590+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:45:06.591+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success(Promise.scala:86)
[2024-06-14T02:45:06.591+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success$(Promise.scala:86)
[2024-06-14T02:45:06.591+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2024-06-14T02:45:06.591+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2024-06-14T02:45:06.591+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2024-06-14T02:45:06.591+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2024-06-14T02:45:06.592+0530] {subprocess.py:93} INFO - 	... 8 more
[2024-06-14T02:45:06.592+0530] {subprocess.py:93} INFO - 24/06/14 02:44:58 WARN Executor: Issue communicating with driver in heartbeater
[2024-06-14T02:45:06.592+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:45:06.592+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:45:06.592+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:45:06.592+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:45:06.592+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2024-06-14T02:45:06.592+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2024-06-14T02:45:06.592+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2024-06-14T02:45:06.592+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2024-06-14T02:45:06.592+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2024-06-14T02:45:06.593+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2024-06-14T02:45:06.593+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:45:06.593+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2024-06-14T02:45:06.593+0530] {subprocess.py:93} INFO - 	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2024-06-14T02:45:06.593+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2024-06-14T02:45:06.593+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2024-06-14T02:45:06.593+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2024-06-14T02:45:06.593+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:45:06.594+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:45:06.594+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:45:06.594+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:45:06.594+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:45:06.594+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:45:06.594+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:45:06.594+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2024-06-14T02:45:06.594+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2024-06-14T02:45:06.594+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2024-06-14T02:45:06.595+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2024-06-14T02:45:06.595+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2024-06-14T02:45:06.595+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2024-06-14T02:45:06.595+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2024-06-14T02:45:06.595+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2024-06-14T02:45:06.595+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:45:06.595+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:45:06.595+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:45:06.596+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:45:06.596+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:45:06.596+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:45:06.596+0530] {subprocess.py:93} INFO - 	... 3 more
[2024-06-14T02:45:06.596+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.56.255:38347
[2024-06-14T02:45:06.597+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2024-06-14T02:45:06.597+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2024-06-14T02:45:06.597+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2024-06-14T02:45:06.597+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2024-06-14T02:45:06.597+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:45:06.598+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:45:06.598+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:45:06.598+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:45:06.598+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:45:06.598+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:45:06.598+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:45:06.599+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:45:06.600+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:45:06.601+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:45:06.601+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:45:06.602+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:45:06.602+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:45:06.602+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:45:06.602+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:45:06.602+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:45:06.602+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:45:06.603+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:45:06.603+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:45:06.603+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:45:06.603+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:45:06.603+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:45:06.603+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:45:06.604+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2024-06-14T02:45:06.604+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2024-06-14T02:45:06.604+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:45:06.604+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2024-06-14T02:45:06.604+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2024-06-14T02:45:06.605+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2024-06-14T02:45:06.605+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2024-06-14T02:45:06.605+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2024-06-14T02:45:06.605+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2024-06-14T02:45:06.605+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:45:06.605+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:45:06.605+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:45:06.605+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:45:06.606+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2024-06-14T02:45:06.606+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2024-06-14T02:45:06.606+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2024-06-14T02:45:06.606+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2024-06-14T02:45:06.606+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2024-06-14T02:45:06.606+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2024-06-14T02:45:06.606+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:45:06.607+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:45:06.607+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:45:06.607+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:45:06.607+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:45:06.607+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:45:06.607+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:45:06.607+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:45:06.607+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:45:06.607+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:45:06.607+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success(Promise.scala:86)
[2024-06-14T02:45:06.607+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success$(Promise.scala:86)
[2024-06-14T02:45:06.608+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2024-06-14T02:45:06.608+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2024-06-14T02:45:06.608+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2024-06-14T02:45:06.608+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2024-06-14T02:45:06.608+0530] {subprocess.py:93} INFO - 	... 8 more
[2024-06-14T02:45:20.667+0530] {subprocess.py:93} INFO - 24/06/14 02:45:20 ERROR Inbox: Ignoring error
[2024-06-14T02:45:20.825+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:45:20.825+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:45:20.825+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:45:20.826+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:45:20.826+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2024-06-14T02:45:20.826+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2024-06-14T02:45:20.826+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2024-06-14T02:45:20.826+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2024-06-14T02:45:20.826+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2024-06-14T02:45:20.826+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2024-06-14T02:45:20.826+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2024-06-14T02:45:20.827+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2024-06-14T02:45:20.827+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:45:20.827+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:45:20.827+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:45:20.827+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:45:20.827+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:45:20.828+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:45:20.828+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:45:20.828+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:45:20.828+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:45:20.828+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.56.255:38347
[2024-06-14T02:45:20.828+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2024-06-14T02:45:20.828+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2024-06-14T02:45:20.828+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2024-06-14T02:45:20.828+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2024-06-14T02:45:20.828+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:45:20.829+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:45:20.829+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:45:20.829+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:45:20.829+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:45:20.829+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:45:20.829+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:45:20.829+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:45:20.830+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:45:20.830+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:45:20.830+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:45:20.830+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:45:20.830+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:45:20.830+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:45:20.831+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:45:20.831+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:45:20.831+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:45:20.831+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:45:20.831+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:45:20.831+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:45:20.832+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:45:20.832+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:45:20.832+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:45:20.832+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2024-06-14T02:45:20.832+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2024-06-14T02:45:20.833+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:45:20.833+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2024-06-14T02:45:20.833+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2024-06-14T02:45:20.833+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2024-06-14T02:45:20.833+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2024-06-14T02:45:20.834+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2024-06-14T02:45:20.834+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2024-06-14T02:45:20.834+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:45:20.834+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:45:20.835+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:45:20.835+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:45:20.835+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2024-06-14T02:45:20.835+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2024-06-14T02:45:20.835+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2024-06-14T02:45:20.835+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2024-06-14T02:45:20.835+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2024-06-14T02:45:20.836+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2024-06-14T02:45:20.836+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:45:20.836+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:45:20.836+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:45:20.836+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:45:20.836+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:45:20.836+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:45:20.836+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:45:20.836+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:45:20.836+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:45:20.836+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:45:20.837+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success(Promise.scala:86)
[2024-06-14T02:45:20.837+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success$(Promise.scala:86)
[2024-06-14T02:45:20.837+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2024-06-14T02:45:20.837+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2024-06-14T02:45:20.837+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2024-06-14T02:45:20.837+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2024-06-14T02:45:20.837+0530] {subprocess.py:93} INFO - 	... 8 more
[2024-06-14T02:45:20.837+0530] {subprocess.py:93} INFO - 24/06/14 02:45:20 WARN Executor: Issue communicating with driver in heartbeater
[2024-06-14T02:45:20.837+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:45:20.837+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:45:20.837+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:45:20.838+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:45:20.838+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2024-06-14T02:45:20.838+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2024-06-14T02:45:20.838+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2024-06-14T02:45:20.838+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2024-06-14T02:45:20.838+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2024-06-14T02:45:20.838+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2024-06-14T02:45:20.839+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:45:20.839+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2024-06-14T02:45:20.839+0530] {subprocess.py:93} INFO - 	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2024-06-14T02:45:20.839+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2024-06-14T02:45:20.839+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2024-06-14T02:45:20.839+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2024-06-14T02:45:20.839+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:45:20.840+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:45:20.840+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:45:20.840+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:45:20.840+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:45:20.840+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:45:20.840+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:45:20.840+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2024-06-14T02:45:20.840+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2024-06-14T02:45:20.841+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2024-06-14T02:45:20.841+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2024-06-14T02:45:20.841+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2024-06-14T02:45:20.841+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2024-06-14T02:45:20.842+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2024-06-14T02:45:20.842+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2024-06-14T02:45:20.842+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:45:20.842+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:45:20.842+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:45:20.842+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:45:20.843+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:45:20.843+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:45:20.843+0530] {subprocess.py:93} INFO - 	... 3 more
[2024-06-14T02:45:20.843+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.56.255:38347
[2024-06-14T02:45:20.843+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2024-06-14T02:45:20.843+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2024-06-14T02:45:20.844+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2024-06-14T02:45:20.844+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2024-06-14T02:45:20.844+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:45:20.844+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:45:20.844+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:45:20.844+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:45:20.844+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:45:20.845+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:45:20.845+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:45:20.845+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:45:20.845+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:45:20.845+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:45:20.846+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:45:20.846+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:45:20.846+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:45:20.846+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:45:20.847+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:45:20.847+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:45:20.847+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:45:20.847+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:45:20.847+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:45:20.847+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:45:20.848+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:45:20.848+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:45:20.848+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:45:20.848+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2024-06-14T02:45:20.848+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2024-06-14T02:45:20.848+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:45:20.848+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2024-06-14T02:45:20.848+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2024-06-14T02:45:20.848+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2024-06-14T02:45:20.848+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2024-06-14T02:45:20.848+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2024-06-14T02:45:20.848+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2024-06-14T02:45:20.849+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:45:20.849+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:45:20.849+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:45:20.849+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:45:20.849+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2024-06-14T02:45:20.849+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2024-06-14T02:45:20.849+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2024-06-14T02:45:20.849+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2024-06-14T02:45:20.849+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2024-06-14T02:45:20.849+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2024-06-14T02:45:20.849+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:45:20.850+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:45:20.850+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:45:20.850+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:45:20.850+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:45:20.850+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:45:20.850+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:45:20.850+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:45:20.850+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:45:20.850+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:45:20.850+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success(Promise.scala:86)
[2024-06-14T02:45:20.850+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success$(Promise.scala:86)
[2024-06-14T02:45:20.851+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2024-06-14T02:45:20.851+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2024-06-14T02:45:20.851+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2024-06-14T02:45:20.851+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2024-06-14T02:45:20.851+0530] {subprocess.py:93} INFO - 	... 8 more
[2024-06-14T02:45:21.915+0530] {subprocess.py:93} INFO - 24/06/14 02:45:21 ERROR Inbox: Ignoring error
[2024-06-14T02:45:22.218+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:45:22.228+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:45:22.228+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:45:22.228+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:45:22.229+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2024-06-14T02:45:22.229+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2024-06-14T02:45:22.229+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2024-06-14T02:45:22.229+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2024-06-14T02:45:22.229+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2024-06-14T02:45:22.229+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2024-06-14T02:45:22.229+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2024-06-14T02:45:22.230+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2024-06-14T02:45:22.230+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:45:22.230+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:45:22.230+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:45:22.230+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:45:22.230+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:45:22.231+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:45:22.231+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:45:22.231+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:45:22.231+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:45:22.231+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.56.255:38347
[2024-06-14T02:45:22.231+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2024-06-14T02:45:22.231+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2024-06-14T02:45:22.232+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2024-06-14T02:45:22.232+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2024-06-14T02:45:22.232+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:45:22.232+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:45:22.232+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:45:22.232+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:45:22.232+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:45:22.232+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:45:22.232+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:45:22.232+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:45:22.233+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:45:22.233+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:45:22.233+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:45:22.233+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:45:22.233+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:45:22.233+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:45:22.233+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:45:22.233+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:45:22.233+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:45:22.233+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:45:22.234+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:45:22.234+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:45:22.234+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:45:22.234+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:45:22.234+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:45:22.234+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2024-06-14T02:45:22.234+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2024-06-14T02:45:22.234+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:45:22.234+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2024-06-14T02:45:22.235+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2024-06-14T02:45:22.235+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2024-06-14T02:45:22.235+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2024-06-14T02:45:22.235+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2024-06-14T02:45:22.235+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2024-06-14T02:45:22.235+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:45:22.235+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:45:22.235+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:45:22.235+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:45:22.235+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2024-06-14T02:45:22.236+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2024-06-14T02:45:22.236+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2024-06-14T02:45:22.237+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2024-06-14T02:45:22.237+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2024-06-14T02:45:22.237+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2024-06-14T02:45:22.237+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:45:22.237+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:45:22.238+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:45:22.238+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:45:22.238+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:45:22.238+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:45:22.238+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:45:22.238+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:45:22.239+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:45:22.239+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:45:22.239+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success(Promise.scala:86)
[2024-06-14T02:45:22.239+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success$(Promise.scala:86)
[2024-06-14T02:45:22.239+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2024-06-14T02:45:22.239+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2024-06-14T02:45:22.240+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2024-06-14T02:45:22.240+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2024-06-14T02:45:22.240+0530] {subprocess.py:93} INFO - 	... 8 more
[2024-06-14T02:45:22.240+0530] {subprocess.py:93} INFO - 24/06/14 02:45:21 WARN Executor: Issue communicating with driver in heartbeater
[2024-06-14T02:45:22.240+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:45:22.240+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:45:22.241+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:45:22.241+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:45:22.241+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2024-06-14T02:45:22.241+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2024-06-14T02:45:22.242+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2024-06-14T02:45:22.242+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2024-06-14T02:45:22.242+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2024-06-14T02:45:22.242+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2024-06-14T02:45:22.242+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:45:22.242+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2024-06-14T02:45:22.243+0530] {subprocess.py:93} INFO - 	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2024-06-14T02:45:22.243+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2024-06-14T02:45:22.243+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2024-06-14T02:45:22.243+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2024-06-14T02:45:22.243+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:45:22.244+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:45:22.244+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:45:22.244+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:45:22.244+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:45:22.244+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:45:22.244+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:45:22.245+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2024-06-14T02:45:22.245+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2024-06-14T02:45:22.245+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2024-06-14T02:45:22.245+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2024-06-14T02:45:22.245+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2024-06-14T02:45:22.245+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2024-06-14T02:45:22.245+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2024-06-14T02:45:22.246+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2024-06-14T02:45:22.246+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:45:22.246+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:45:22.246+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:45:22.246+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:45:22.247+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:45:22.247+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:45:22.247+0530] {subprocess.py:93} INFO - 	... 3 more
[2024-06-14T02:45:22.247+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.56.255:38347
[2024-06-14T02:45:22.247+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2024-06-14T02:45:22.247+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2024-06-14T02:45:22.247+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2024-06-14T02:45:22.247+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2024-06-14T02:45:22.248+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:45:22.248+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:45:22.248+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:45:22.248+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:45:22.248+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:45:22.248+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:45:22.249+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:45:22.249+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:45:22.249+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:45:22.249+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:45:22.250+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:45:22.250+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:45:22.250+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:45:22.250+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:45:22.250+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:45:22.251+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:45:22.251+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:45:22.251+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:45:22.251+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:45:22.252+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:45:22.252+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:45:22.252+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:45:22.253+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:45:22.253+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2024-06-14T02:45:22.253+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2024-06-14T02:45:22.253+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:45:22.253+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2024-06-14T02:45:22.254+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2024-06-14T02:45:22.254+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2024-06-14T02:45:22.254+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2024-06-14T02:45:22.254+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2024-06-14T02:45:22.254+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2024-06-14T02:45:22.254+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:45:22.255+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:45:22.255+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:45:22.255+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:45:22.255+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2024-06-14T02:45:22.256+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2024-06-14T02:45:22.256+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2024-06-14T02:45:22.256+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2024-06-14T02:45:22.256+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2024-06-14T02:45:22.256+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2024-06-14T02:45:22.256+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:45:22.257+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:45:22.257+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:45:22.257+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:45:22.258+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:45:22.258+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:45:22.258+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:45:22.258+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:45:22.259+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:45:22.259+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:45:22.259+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success(Promise.scala:86)
[2024-06-14T02:45:22.259+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success$(Promise.scala:86)
[2024-06-14T02:45:22.259+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2024-06-14T02:45:22.260+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2024-06-14T02:45:22.260+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2024-06-14T02:45:22.260+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2024-06-14T02:45:22.261+0530] {subprocess.py:93} INFO - 	... 8 more
[2024-06-14T02:45:31.899+0530] {subprocess.py:93} INFO - 24/06/14 02:45:30 ERROR Inbox: Ignoring error
[2024-06-14T02:45:32.468+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:45:32.754+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:45:33.008+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:45:33.017+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:45:33.018+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2024-06-14T02:45:33.018+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2024-06-14T02:45:33.018+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2024-06-14T02:45:33.018+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2024-06-14T02:45:33.018+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2024-06-14T02:45:33.019+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2024-06-14T02:45:33.019+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2024-06-14T02:45:33.019+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2024-06-14T02:45:33.019+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:45:33.019+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:45:33.019+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:45:33.019+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:45:33.019+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:45:33.020+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:45:33.020+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:45:33.020+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:45:33.020+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:45:33.020+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.56.255:38347
[2024-06-14T02:45:33.020+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2024-06-14T02:45:33.020+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2024-06-14T02:45:33.021+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2024-06-14T02:45:33.021+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2024-06-14T02:45:33.021+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:45:33.021+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:45:33.101+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:45:33.312+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:45:33.350+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:45:33.350+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:45:33.350+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:45:33.351+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:45:33.351+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:45:33.351+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:45:33.351+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:45:33.351+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:45:33.351+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:45:33.351+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:45:33.351+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:45:33.352+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:45:33.352+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:45:33.352+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:45:33.352+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:45:33.352+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:45:33.363+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:45:33.363+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:45:33.363+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:45:33.364+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2024-06-14T02:45:33.364+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2024-06-14T02:45:33.364+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:45:33.364+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2024-06-14T02:45:33.364+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2024-06-14T02:45:33.364+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2024-06-14T02:45:33.364+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2024-06-14T02:45:33.365+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2024-06-14T02:45:33.365+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2024-06-14T02:45:33.365+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:45:33.365+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:45:33.365+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:45:33.365+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:45:33.366+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2024-06-14T02:45:33.366+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2024-06-14T02:45:33.366+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2024-06-14T02:45:33.366+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2024-06-14T02:45:33.366+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2024-06-14T02:45:33.366+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2024-06-14T02:45:33.367+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:45:33.367+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:45:33.367+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:45:33.367+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:45:33.367+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:45:33.367+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:45:33.368+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:45:33.368+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:45:33.368+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:45:33.368+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:45:33.369+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success(Promise.scala:86)
[2024-06-14T02:45:33.369+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success$(Promise.scala:86)
[2024-06-14T02:45:33.369+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2024-06-14T02:45:33.369+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2024-06-14T02:45:33.369+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2024-06-14T02:45:33.370+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2024-06-14T02:45:33.370+0530] {subprocess.py:93} INFO - 	... 8 more
[2024-06-14T02:45:33.370+0530] {subprocess.py:93} INFO - 24/06/14 02:45:30 WARN Executor: Issue communicating with driver in heartbeater
[2024-06-14T02:45:33.370+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:45:33.370+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:45:33.370+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:45:33.370+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:45:33.371+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2024-06-14T02:45:33.371+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2024-06-14T02:45:33.371+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2024-06-14T02:45:33.371+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2024-06-14T02:45:33.371+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2024-06-14T02:45:33.371+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2024-06-14T02:45:33.372+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:45:33.372+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2024-06-14T02:45:33.372+0530] {subprocess.py:93} INFO - 	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2024-06-14T02:45:33.373+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2024-06-14T02:45:33.373+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2024-06-14T02:45:33.373+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2024-06-14T02:45:33.373+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:45:33.373+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:45:33.374+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:45:33.374+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:45:33.374+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:45:33.374+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:45:33.374+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:45:33.374+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2024-06-14T02:45:33.374+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2024-06-14T02:45:33.374+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2024-06-14T02:45:33.374+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2024-06-14T02:45:33.374+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2024-06-14T02:45:33.374+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2024-06-14T02:45:33.374+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2024-06-14T02:45:33.375+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2024-06-14T02:45:33.375+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:45:33.375+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:45:33.375+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:45:33.376+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:45:33.376+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:45:33.376+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:45:33.376+0530] {subprocess.py:93} INFO - 	... 3 more
[2024-06-14T02:45:33.376+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.56.255:38347
[2024-06-14T02:45:33.376+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2024-06-14T02:45:33.376+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2024-06-14T02:45:33.376+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2024-06-14T02:45:33.376+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2024-06-14T02:45:33.377+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:45:33.377+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:45:33.377+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:45:33.377+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:45:33.377+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:45:33.377+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:45:33.377+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:45:33.377+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:45:33.377+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:45:33.377+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:45:33.377+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:45:33.378+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:45:33.378+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:45:33.378+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:45:33.378+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:45:33.378+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:45:33.378+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:45:33.378+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:45:33.379+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:45:33.379+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:45:33.379+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:45:33.379+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:45:33.379+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:45:33.379+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2024-06-14T02:45:33.379+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2024-06-14T02:45:33.379+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:45:33.380+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2024-06-14T02:45:33.380+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2024-06-14T02:45:33.380+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2024-06-14T02:45:33.380+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2024-06-14T02:45:33.380+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2024-06-14T02:45:33.380+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2024-06-14T02:45:33.380+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:45:33.380+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:45:33.381+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:45:33.381+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:45:33.381+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2024-06-14T02:45:33.381+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2024-06-14T02:45:33.381+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2024-06-14T02:45:33.381+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2024-06-14T02:45:33.381+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2024-06-14T02:45:33.381+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2024-06-14T02:45:33.382+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:45:33.382+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:45:33.382+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:45:33.382+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:45:33.382+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:45:33.382+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:45:33.382+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:45:33.382+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:45:33.383+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:45:33.383+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:45:33.383+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success(Promise.scala:86)
[2024-06-14T02:45:33.383+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success$(Promise.scala:86)
[2024-06-14T02:45:33.383+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2024-06-14T02:45:33.383+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2024-06-14T02:45:33.384+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2024-06-14T02:45:33.384+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2024-06-14T02:45:33.384+0530] {subprocess.py:93} INFO - 	... 8 more
[2024-06-14T02:46:20.151+0530] {subprocess.py:93} INFO - 24/06/14 02:46:04 ERROR Inbox: Ignoring error
[2024-06-14T02:46:27.042+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:46:27.043+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:46:27.043+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:46:27.044+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:46:27.044+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2024-06-14T02:46:27.045+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2024-06-14T02:46:27.045+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2024-06-14T02:46:27.046+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2024-06-14T02:46:27.046+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2024-06-14T02:46:27.046+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2024-06-14T02:46:27.046+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2024-06-14T02:46:27.047+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2024-06-14T02:46:27.047+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:46:27.057+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:46:27.058+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:46:27.058+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:46:27.059+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:46:27.059+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:46:27.060+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:46:27.060+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:46:27.060+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:46:27.061+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.56.255:38347
[2024-06-14T02:46:27.061+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2024-06-14T02:46:27.061+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2024-06-14T02:46:27.062+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2024-06-14T02:46:27.073+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2024-06-14T02:46:27.073+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:46:27.074+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:46:27.074+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:46:27.075+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:46:27.075+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)
[2024-06-14T02:46:27.076+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)
[2024-06-14T02:46:27.076+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.transformWith(Promise.scala:40)
[2024-06-14T02:46:27.077+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)
[2024-06-14T02:46:27.077+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)
[2024-06-14T02:46:27.077+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.flatMap(Future.scala:306)
[2024-06-14T02:46:27.077+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.flatMap$(Future.scala:306)
[2024-06-14T02:46:27.078+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)
[2024-06-14T02:46:27.089+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)
[2024-06-14T02:46:27.090+0530] {subprocess.py:93} INFO - 	... 17 more
[2024-06-14T02:46:27.090+0530] {subprocess.py:93} INFO - 24/06/14 02:46:04 WARN Executor: Issue communicating with driver in heartbeater
[2024-06-14T02:46:27.091+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:46:27.091+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:46:27.092+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:46:27.093+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:46:27.102+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2024-06-14T02:46:27.102+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2024-06-14T02:46:27.103+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2024-06-14T02:46:27.103+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2024-06-14T02:46:27.104+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2024-06-14T02:46:27.105+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2024-06-14T02:46:27.105+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:46:27.105+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2024-06-14T02:46:27.106+0530] {subprocess.py:93} INFO - 	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2024-06-14T02:46:27.106+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2024-06-14T02:46:27.107+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2024-06-14T02:46:27.107+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2024-06-14T02:46:27.108+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:46:27.108+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:46:27.108+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:46:27.121+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:46:27.121+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:46:27.122+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:46:27.122+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:46:27.123+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2024-06-14T02:46:27.124+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2024-06-14T02:46:27.125+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2024-06-14T02:46:27.125+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2024-06-14T02:46:27.126+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2024-06-14T02:46:27.136+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2024-06-14T02:46:27.136+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2024-06-14T02:46:27.137+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2024-06-14T02:46:27.137+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:46:27.138+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:46:27.138+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:46:27.138+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:46:27.139+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:46:27.139+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:46:27.140+0530] {subprocess.py:93} INFO - 	... 3 more
[2024-06-14T02:46:27.140+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.56.255:38347
[2024-06-14T02:46:27.141+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2024-06-14T02:46:27.141+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2024-06-14T02:46:27.152+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2024-06-14T02:46:27.153+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2024-06-14T02:46:27.153+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:46:27.154+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:46:27.154+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:46:27.154+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:46:27.155+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)
[2024-06-14T02:46:27.155+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)
[2024-06-14T02:46:27.155+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.transformWith(Promise.scala:40)
[2024-06-14T02:46:27.155+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)
[2024-06-14T02:46:27.156+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)
[2024-06-14T02:46:27.156+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.flatMap(Future.scala:306)
[2024-06-14T02:46:27.156+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.flatMap$(Future.scala:306)
[2024-06-14T02:46:27.156+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)
[2024-06-14T02:46:27.168+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)
[2024-06-14T02:46:27.169+0530] {subprocess.py:93} INFO - 	... 17 more
[2024-06-14T02:49:00.720+0530] {subprocess.py:93} INFO - 24/06/14 02:48:20 ERROR Inbox: Ignoring error
[2024-06-14T02:49:00.810+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:49:00.811+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:49:00.811+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:49:00.812+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:49:00.812+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2024-06-14T02:49:00.812+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2024-06-14T02:49:00.813+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2024-06-14T02:49:00.813+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2024-06-14T02:49:00.814+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2024-06-14T02:49:00.814+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2024-06-14T02:49:00.815+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2024-06-14T02:49:00.815+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2024-06-14T02:49:00.816+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:49:00.816+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:49:00.816+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:49:00.817+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:49:00.817+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:49:00.817+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:49:00.818+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:49:00.818+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:49:00.818+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:49:00.818+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.56.255:38347
[2024-06-14T02:49:00.819+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2024-06-14T02:49:00.819+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2024-06-14T02:49:00.819+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2024-06-14T02:49:00.819+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2024-06-14T02:49:00.820+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:00.820+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:00.821+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:00.821+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:00.821+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)
[2024-06-14T02:49:00.822+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)
[2024-06-14T02:49:00.822+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.transformWith(Promise.scala:40)
[2024-06-14T02:49:00.822+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)
[2024-06-14T02:49:00.832+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)
[2024-06-14T02:49:00.832+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.flatMap(Future.scala:306)
[2024-06-14T02:49:00.833+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.flatMap$(Future.scala:306)
[2024-06-14T02:49:00.833+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)
[2024-06-14T02:49:00.833+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)
[2024-06-14T02:49:00.834+0530] {subprocess.py:93} INFO - 	... 17 more
[2024-06-14T02:49:00.834+0530] {subprocess.py:93} INFO - 24/06/14 02:48:20 WARN Executor: Issue communicating with driver in heartbeater
[2024-06-14T02:49:00.834+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:49:00.835+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:49:00.835+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:49:00.835+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:49:00.835+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2024-06-14T02:49:00.836+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2024-06-14T02:49:00.836+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2024-06-14T02:49:00.836+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2024-06-14T02:49:00.836+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2024-06-14T02:49:00.837+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2024-06-14T02:49:00.848+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:49:00.848+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2024-06-14T02:49:00.849+0530] {subprocess.py:93} INFO - 	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2024-06-14T02:49:00.849+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2024-06-14T02:49:00.849+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2024-06-14T02:49:00.849+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2024-06-14T02:49:00.850+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:49:00.850+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:49:00.850+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:49:00.850+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:49:00.850+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:49:00.851+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:49:00.851+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:49:00.851+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2024-06-14T02:49:00.851+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2024-06-14T02:49:00.851+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2024-06-14T02:49:00.852+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2024-06-14T02:49:00.852+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2024-06-14T02:49:00.852+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2024-06-14T02:49:00.852+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2024-06-14T02:49:00.852+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2024-06-14T02:49:00.852+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:49:00.853+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:49:00.863+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:49:00.864+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:49:00.864+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:49:00.864+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:49:00.864+0530] {subprocess.py:93} INFO - 	... 3 more
[2024-06-14T02:49:00.865+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.56.255:38347
[2024-06-14T02:49:00.865+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2024-06-14T02:49:00.865+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2024-06-14T02:49:00.865+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2024-06-14T02:49:00.865+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2024-06-14T02:49:00.865+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:00.866+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:00.866+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:00.866+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:00.866+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)
[2024-06-14T02:49:00.866+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)
[2024-06-14T02:49:00.866+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.transformWith(Promise.scala:40)
[2024-06-14T02:49:00.867+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)
[2024-06-14T02:49:00.867+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)
[2024-06-14T02:49:00.867+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.flatMap(Future.scala:306)
[2024-06-14T02:49:00.867+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.flatMap$(Future.scala:306)
[2024-06-14T02:49:00.867+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)
[2024-06-14T02:49:00.868+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)
[2024-06-14T02:49:00.868+0530] {subprocess.py:93} INFO - 	... 17 more
[2024-06-14T02:49:01.084+0530] {subprocess.py:93} INFO - 24/06/14 02:49:00 ERROR Inbox: Ignoring error
[2024-06-14T02:49:01.087+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:49:01.087+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:49:01.088+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:49:01.088+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:49:01.089+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2024-06-14T02:49:01.089+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2024-06-14T02:49:01.089+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2024-06-14T02:49:01.090+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2024-06-14T02:49:01.090+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2024-06-14T02:49:01.090+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2024-06-14T02:49:01.091+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2024-06-14T02:49:01.096+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2024-06-14T02:49:01.097+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:49:01.097+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:49:01.098+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:49:01.098+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:49:01.098+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:49:01.098+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:49:01.099+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:49:01.099+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:49:01.099+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:49:01.099+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.56.255:38347
[2024-06-14T02:49:01.100+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2024-06-14T02:49:01.100+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2024-06-14T02:49:01.100+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2024-06-14T02:49:01.100+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2024-06-14T02:49:01.101+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:01.101+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:01.101+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:01.101+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:01.102+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:01.102+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:01.115+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:01.115+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:01.116+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:01.116+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:01.119+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:49:01.120+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:01.120+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:01.120+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:01.122+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:01.123+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:01.129+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:01.130+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:01.130+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:01.135+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:01.135+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:01.135+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:49:01.136+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:01.136+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2024-06-14T02:49:01.137+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2024-06-14T02:49:01.137+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:49:01.138+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2024-06-14T02:49:01.138+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2024-06-14T02:49:01.139+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2024-06-14T02:49:01.139+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2024-06-14T02:49:01.140+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2024-06-14T02:49:01.140+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2024-06-14T02:49:01.141+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:01.141+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:01.143+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:01.144+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:01.144+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2024-06-14T02:49:01.150+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2024-06-14T02:49:01.151+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2024-06-14T02:49:01.152+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2024-06-14T02:49:01.152+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2024-06-14T02:49:01.153+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2024-06-14T02:49:01.153+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:01.154+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:01.154+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:01.154+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:01.154+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:01.155+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:01.155+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:01.155+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:01.155+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:01.156+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:01.156+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success(Promise.scala:86)
[2024-06-14T02:49:01.157+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success$(Promise.scala:86)
[2024-06-14T02:49:01.157+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2024-06-14T02:49:01.157+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2024-06-14T02:49:01.158+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2024-06-14T02:49:01.158+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2024-06-14T02:49:01.159+0530] {subprocess.py:93} INFO - 	... 8 more
[2024-06-14T02:49:01.160+0530] {subprocess.py:93} INFO - 24/06/14 02:49:00 WARN Executor: Issue communicating with driver in heartbeater
[2024-06-14T02:49:01.161+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:49:01.161+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:49:01.162+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:49:01.162+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:49:01.163+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2024-06-14T02:49:01.163+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2024-06-14T02:49:01.166+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2024-06-14T02:49:01.169+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2024-06-14T02:49:01.170+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2024-06-14T02:49:01.184+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2024-06-14T02:49:01.184+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:49:01.185+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2024-06-14T02:49:01.185+0530] {subprocess.py:93} INFO - 	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2024-06-14T02:49:01.185+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2024-06-14T02:49:01.186+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2024-06-14T02:49:01.186+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2024-06-14T02:49:01.186+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:49:01.189+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:49:01.189+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:49:01.190+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:49:01.197+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:49:01.198+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:49:01.198+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:49:01.199+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2024-06-14T02:49:01.199+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2024-06-14T02:49:01.200+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2024-06-14T02:49:01.201+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2024-06-14T02:49:01.201+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2024-06-14T02:49:01.202+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2024-06-14T02:49:01.202+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2024-06-14T02:49:01.202+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2024-06-14T02:49:01.202+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:49:01.202+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:49:01.202+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:49:01.203+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:49:01.203+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:49:01.203+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:49:01.203+0530] {subprocess.py:93} INFO - 	... 3 more
[2024-06-14T02:49:01.203+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.56.255:38347
[2024-06-14T02:49:01.203+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2024-06-14T02:49:01.203+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2024-06-14T02:49:01.203+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2024-06-14T02:49:01.204+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2024-06-14T02:49:01.204+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:01.204+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:01.204+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:01.204+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:01.204+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:01.204+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:01.204+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:01.206+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:01.208+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:01.209+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:01.209+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:49:01.210+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:01.210+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:01.211+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:01.212+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:01.212+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:01.212+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:01.213+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:01.213+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:01.213+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:01.214+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:01.214+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:49:01.215+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:01.216+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2024-06-14T02:49:01.216+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2024-06-14T02:49:01.217+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:49:01.217+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2024-06-14T02:49:01.218+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2024-06-14T02:49:01.218+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2024-06-14T02:49:01.218+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2024-06-14T02:49:01.218+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2024-06-14T02:49:01.218+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2024-06-14T02:49:01.219+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:01.219+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:01.219+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:01.219+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:01.220+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2024-06-14T02:49:01.220+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2024-06-14T02:49:01.220+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2024-06-14T02:49:01.223+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2024-06-14T02:49:01.227+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2024-06-14T02:49:01.228+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2024-06-14T02:49:01.228+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:01.229+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:01.229+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:01.229+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:01.229+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:01.230+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:01.230+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:01.230+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:01.231+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:01.231+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:01.231+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success(Promise.scala:86)
[2024-06-14T02:49:01.232+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success$(Promise.scala:86)
[2024-06-14T02:49:01.235+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2024-06-14T02:49:01.236+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2024-06-14T02:49:01.236+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2024-06-14T02:49:01.237+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2024-06-14T02:49:01.238+0530] {subprocess.py:93} INFO - 	... 8 more
[2024-06-14T02:49:01.239+0530] {subprocess.py:93} INFO - 24/06/14 02:49:01 ERROR Inbox: Ignoring error
[2024-06-14T02:49:01.240+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:49:01.243+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:49:01.244+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:49:01.244+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:49:01.244+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2024-06-14T02:49:01.245+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2024-06-14T02:49:01.245+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2024-06-14T02:49:01.246+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2024-06-14T02:49:01.246+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2024-06-14T02:49:01.247+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2024-06-14T02:49:01.247+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2024-06-14T02:49:01.247+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2024-06-14T02:49:01.248+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:49:01.248+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:49:01.249+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:49:01.249+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:49:01.249+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:49:01.250+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:49:01.250+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:49:01.251+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:49:01.251+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:49:01.254+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.56.255:38347
[2024-06-14T02:49:01.254+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2024-06-14T02:49:01.255+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2024-06-14T02:49:01.255+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2024-06-14T02:49:01.263+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2024-06-14T02:49:01.263+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:01.264+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:01.264+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:01.264+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:01.265+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:01.265+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:01.265+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:01.266+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:01.266+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:01.267+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:01.267+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:49:01.267+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:01.268+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:01.268+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:01.268+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:01.269+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:01.269+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:01.269+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:01.269+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:01.270+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:01.270+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:01.271+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:49:01.271+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:01.271+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2024-06-14T02:49:01.271+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2024-06-14T02:49:01.272+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:49:01.272+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2024-06-14T02:49:01.272+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2024-06-14T02:49:01.272+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2024-06-14T02:49:01.273+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2024-06-14T02:49:01.273+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2024-06-14T02:49:01.280+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2024-06-14T02:49:01.281+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:01.282+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:01.283+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:01.283+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:01.283+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2024-06-14T02:49:01.284+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2024-06-14T02:49:01.284+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2024-06-14T02:49:01.284+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2024-06-14T02:49:01.284+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2024-06-14T02:49:01.285+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2024-06-14T02:49:01.285+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:01.285+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:01.286+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:01.286+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:01.296+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:01.297+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:01.297+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:01.298+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:01.299+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:01.299+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:01.299+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success(Promise.scala:86)
[2024-06-14T02:49:01.299+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success$(Promise.scala:86)
[2024-06-14T02:49:01.300+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2024-06-14T02:49:01.300+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2024-06-14T02:49:01.300+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2024-06-14T02:49:01.300+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2024-06-14T02:49:01.300+0530] {subprocess.py:93} INFO - 	... 8 more
[2024-06-14T02:49:01.301+0530] {subprocess.py:93} INFO - 24/06/14 02:49:01 WARN Executor: Issue communicating with driver in heartbeater
[2024-06-14T02:49:01.301+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:49:01.301+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:49:01.301+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:49:01.336+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:49:01.337+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2024-06-14T02:49:01.337+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2024-06-14T02:49:01.337+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2024-06-14T02:49:01.338+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2024-06-14T02:49:01.338+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2024-06-14T02:49:01.338+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2024-06-14T02:49:01.339+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:49:01.339+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2024-06-14T02:49:01.339+0530] {subprocess.py:93} INFO - 	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2024-06-14T02:49:01.339+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2024-06-14T02:49:01.340+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2024-06-14T02:49:01.340+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2024-06-14T02:49:01.340+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:49:01.341+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:49:01.341+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:49:01.341+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:49:01.342+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:49:01.358+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:49:01.360+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:49:01.361+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2024-06-14T02:49:01.361+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2024-06-14T02:49:01.361+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2024-06-14T02:49:01.361+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2024-06-14T02:49:01.362+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2024-06-14T02:49:01.362+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2024-06-14T02:49:01.362+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2024-06-14T02:49:01.362+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2024-06-14T02:49:01.362+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:49:01.363+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:49:01.363+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:49:01.363+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:49:01.363+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:49:01.363+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:49:01.364+0530] {subprocess.py:93} INFO - 	... 3 more
[2024-06-14T02:49:01.364+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.56.255:38347
[2024-06-14T02:49:01.364+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2024-06-14T02:49:01.364+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2024-06-14T02:49:01.364+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2024-06-14T02:49:01.365+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2024-06-14T02:49:01.365+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:01.365+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:01.365+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:01.365+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:01.366+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:01.366+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:01.366+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:01.366+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:01.366+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:01.367+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:01.367+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:49:01.367+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:01.367+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:01.368+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:01.368+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:01.368+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:01.368+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:01.370+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:01.372+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:01.373+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:01.380+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:01.380+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:49:01.381+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:01.381+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2024-06-14T02:49:01.381+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2024-06-14T02:49:01.382+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:49:01.382+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2024-06-14T02:49:01.382+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2024-06-14T02:49:01.383+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2024-06-14T02:49:01.383+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2024-06-14T02:49:01.383+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2024-06-14T02:49:01.383+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2024-06-14T02:49:01.384+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:01.384+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:01.384+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:01.385+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:01.385+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2024-06-14T02:49:01.385+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2024-06-14T02:49:01.385+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2024-06-14T02:49:01.386+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2024-06-14T02:49:01.386+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2024-06-14T02:49:01.387+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2024-06-14T02:49:01.387+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:01.387+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:01.388+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:01.388+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:01.401+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:01.401+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:01.402+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:01.403+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:01.403+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:01.404+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:01.404+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success(Promise.scala:86)
[2024-06-14T02:49:01.404+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success$(Promise.scala:86)
[2024-06-14T02:49:01.405+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2024-06-14T02:49:01.405+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2024-06-14T02:49:01.405+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2024-06-14T02:49:01.416+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2024-06-14T02:49:01.417+0530] {subprocess.py:93} INFO - 	... 8 more
[2024-06-14T02:49:01.417+0530] {subprocess.py:93} INFO - 24/06/14 02:49:01 ERROR Inbox: Ignoring error
[2024-06-14T02:49:01.418+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:49:01.418+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:49:01.418+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:49:01.419+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:49:01.419+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2024-06-14T02:49:01.419+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2024-06-14T02:49:01.419+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2024-06-14T02:49:01.420+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2024-06-14T02:49:01.420+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2024-06-14T02:49:01.420+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2024-06-14T02:49:01.420+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2024-06-14T02:49:01.420+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2024-06-14T02:49:01.421+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:49:01.421+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:49:01.421+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:49:01.422+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:49:01.422+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:49:01.422+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:49:01.422+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:49:01.422+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:49:01.446+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:49:01.446+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.56.255:38347
[2024-06-14T02:49:01.450+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2024-06-14T02:49:01.450+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2024-06-14T02:49:01.451+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2024-06-14T02:49:01.462+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2024-06-14T02:49:01.463+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:01.463+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:01.463+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:01.464+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:01.464+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:01.465+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:01.465+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:01.465+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:01.466+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:01.466+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:01.478+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:49:01.478+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:01.479+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:01.479+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:01.479+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:01.480+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:01.480+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:01.481+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:01.481+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:01.482+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:01.494+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:01.494+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:49:01.494+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:01.495+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2024-06-14T02:49:01.495+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2024-06-14T02:49:01.495+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:49:01.495+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2024-06-14T02:49:01.496+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2024-06-14T02:49:01.496+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2024-06-14T02:49:01.496+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2024-06-14T02:49:01.497+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2024-06-14T02:49:01.497+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2024-06-14T02:49:01.498+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:01.498+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:01.511+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:01.511+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:01.511+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2024-06-14T02:49:01.512+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2024-06-14T02:49:01.512+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2024-06-14T02:49:01.512+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2024-06-14T02:49:01.513+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2024-06-14T02:49:01.513+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2024-06-14T02:49:01.514+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:01.514+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:01.541+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:01.541+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:01.544+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:01.544+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:01.544+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:01.545+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:01.545+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:01.545+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:01.546+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success(Promise.scala:86)
[2024-06-14T02:49:01.569+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success$(Promise.scala:86)
[2024-06-14T02:49:01.569+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2024-06-14T02:49:01.570+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2024-06-14T02:49:01.570+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2024-06-14T02:49:01.571+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2024-06-14T02:49:01.571+0530] {subprocess.py:93} INFO - 	... 8 more
[2024-06-14T02:49:01.572+0530] {subprocess.py:93} INFO - 24/06/14 02:49:01 WARN Executor: Issue communicating with driver in heartbeater
[2024-06-14T02:49:01.584+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:49:01.584+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:49:01.585+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:49:01.585+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:49:01.585+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2024-06-14T02:49:01.586+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2024-06-14T02:49:01.586+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2024-06-14T02:49:01.586+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2024-06-14T02:49:01.587+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2024-06-14T02:49:01.587+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2024-06-14T02:49:01.587+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:49:01.588+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2024-06-14T02:49:01.588+0530] {subprocess.py:93} INFO - 	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2024-06-14T02:49:01.589+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2024-06-14T02:49:01.601+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2024-06-14T02:49:01.601+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2024-06-14T02:49:01.601+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:49:01.602+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:49:01.602+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:49:01.603+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:49:01.603+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:49:01.603+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:49:01.604+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:49:01.604+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2024-06-14T02:49:01.605+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2024-06-14T02:49:01.605+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2024-06-14T02:49:01.605+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2024-06-14T02:49:01.605+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2024-06-14T02:49:01.606+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2024-06-14T02:49:01.606+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2024-06-14T02:49:01.606+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2024-06-14T02:49:01.606+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:49:01.606+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:49:01.607+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:49:01.616+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:49:01.617+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:49:01.617+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:49:01.617+0530] {subprocess.py:93} INFO - 	... 3 more
[2024-06-14T02:49:01.620+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.56.255:38347
[2024-06-14T02:49:01.620+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2024-06-14T02:49:01.621+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2024-06-14T02:49:01.632+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2024-06-14T02:49:01.632+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2024-06-14T02:49:01.635+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:01.636+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:01.642+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:01.642+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:01.643+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:01.643+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:01.644+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:01.644+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:01.645+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:01.645+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:01.645+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:49:01.645+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:01.646+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:01.646+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:01.646+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:01.647+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:01.647+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:01.647+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:01.647+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:01.648+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:01.648+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:01.648+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:49:01.648+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:01.649+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2024-06-14T02:49:01.649+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2024-06-14T02:49:01.649+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:49:01.650+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2024-06-14T02:49:01.650+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2024-06-14T02:49:01.650+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2024-06-14T02:49:01.654+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2024-06-14T02:49:01.655+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2024-06-14T02:49:01.656+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2024-06-14T02:49:01.656+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:01.662+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:01.662+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:01.662+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:01.663+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2024-06-14T02:49:01.663+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2024-06-14T02:49:01.664+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2024-06-14T02:49:01.664+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2024-06-14T02:49:01.664+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2024-06-14T02:49:01.665+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2024-06-14T02:49:01.665+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:01.666+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:01.666+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:01.666+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:01.667+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:01.667+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:01.667+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:01.668+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:01.672+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:01.672+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:01.678+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success(Promise.scala:86)
[2024-06-14T02:49:01.679+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success$(Promise.scala:86)
[2024-06-14T02:49:01.679+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2024-06-14T02:49:01.680+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2024-06-14T02:49:01.681+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2024-06-14T02:49:01.681+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2024-06-14T02:49:01.681+0530] {subprocess.py:93} INFO - 	... 8 more
[2024-06-14T02:49:01.682+0530] {subprocess.py:93} INFO - 24/06/14 02:49:01 ERROR Inbox: Ignoring error
[2024-06-14T02:49:01.682+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:49:01.682+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:49:01.683+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:49:01.683+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:49:01.683+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2024-06-14T02:49:01.684+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2024-06-14T02:49:01.684+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2024-06-14T02:49:01.684+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2024-06-14T02:49:01.685+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2024-06-14T02:49:01.685+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2024-06-14T02:49:01.685+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2024-06-14T02:49:01.686+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2024-06-14T02:49:01.686+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:49:01.686+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:49:01.688+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:49:01.689+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:49:01.691+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:49:01.697+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:49:01.698+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:49:01.698+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:49:01.699+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:49:01.699+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.56.255:38347
[2024-06-14T02:49:01.699+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2024-06-14T02:49:01.700+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2024-06-14T02:49:01.700+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2024-06-14T02:49:01.700+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2024-06-14T02:49:01.700+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:01.701+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:01.701+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:01.701+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:01.701+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)
[2024-06-14T02:49:01.702+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)
[2024-06-14T02:49:01.703+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.transformWith(Promise.scala:40)
[2024-06-14T02:49:01.703+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)
[2024-06-14T02:49:01.703+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)
[2024-06-14T02:49:01.703+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.flatMap(Future.scala:306)
[2024-06-14T02:49:01.704+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.flatMap$(Future.scala:306)
[2024-06-14T02:49:01.704+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)
[2024-06-14T02:49:01.704+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)
[2024-06-14T02:49:01.704+0530] {subprocess.py:93} INFO - 	... 17 more
[2024-06-14T02:49:01.704+0530] {subprocess.py:93} INFO - 24/06/14 02:49:01 WARN Executor: Issue communicating with driver in heartbeater
[2024-06-14T02:49:01.716+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:49:01.716+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:49:01.717+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:49:01.717+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:49:01.718+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2024-06-14T02:49:01.718+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2024-06-14T02:49:01.718+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2024-06-14T02:49:01.719+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2024-06-14T02:49:01.719+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2024-06-14T02:49:01.719+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2024-06-14T02:49:01.720+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:49:01.720+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2024-06-14T02:49:01.720+0530] {subprocess.py:93} INFO - 	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2024-06-14T02:49:01.721+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2024-06-14T02:49:01.721+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2024-06-14T02:49:01.721+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2024-06-14T02:49:01.722+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:49:01.722+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:49:01.722+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:49:01.722+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:49:01.723+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:49:01.723+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:49:01.723+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:49:01.724+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2024-06-14T02:49:01.724+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2024-06-14T02:49:01.724+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2024-06-14T02:49:01.724+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2024-06-14T02:49:01.725+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2024-06-14T02:49:01.725+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2024-06-14T02:49:01.736+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2024-06-14T02:49:01.737+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2024-06-14T02:49:01.737+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:49:01.737+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:49:01.738+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:49:01.738+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:49:01.738+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:49:01.739+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:49:01.739+0530] {subprocess.py:93} INFO - 	... 3 more
[2024-06-14T02:49:01.739+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.56.255:38347
[2024-06-14T02:49:01.740+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2024-06-14T02:49:01.740+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2024-06-14T02:49:01.740+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2024-06-14T02:49:01.741+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2024-06-14T02:49:01.741+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:01.743+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:01.744+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:01.744+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:01.744+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)
[2024-06-14T02:49:01.745+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)
[2024-06-14T02:49:01.745+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.transformWith(Promise.scala:40)
[2024-06-14T02:49:01.753+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)
[2024-06-14T02:49:01.753+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)
[2024-06-14T02:49:01.757+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.flatMap(Future.scala:306)
[2024-06-14T02:49:01.757+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.flatMap$(Future.scala:306)
[2024-06-14T02:49:01.758+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)
[2024-06-14T02:49:01.758+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)
[2024-06-14T02:49:01.760+0530] {subprocess.py:93} INFO - 	... 17 more
[2024-06-14T02:49:01.760+0530] {subprocess.py:93} INFO - 24/06/14 02:49:01 ERROR Inbox: Ignoring error
[2024-06-14T02:49:01.761+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:49:01.761+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:49:01.761+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:49:01.762+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:49:01.762+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2024-06-14T02:49:01.762+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2024-06-14T02:49:01.762+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2024-06-14T02:49:01.763+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2024-06-14T02:49:01.763+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2024-06-14T02:49:01.763+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2024-06-14T02:49:01.763+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2024-06-14T02:49:01.764+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2024-06-14T02:49:01.764+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:49:01.770+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:49:01.779+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:49:01.779+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:49:01.780+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:49:01.780+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:49:01.780+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:49:01.781+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:49:01.781+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:49:01.781+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.56.255:38347
[2024-06-14T02:49:01.781+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2024-06-14T02:49:01.782+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2024-06-14T02:49:01.782+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2024-06-14T02:49:01.782+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2024-06-14T02:49:01.782+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:01.782+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:01.782+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:01.783+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:01.783+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)
[2024-06-14T02:49:01.783+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)
[2024-06-14T02:49:01.783+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.transformWith(Promise.scala:40)
[2024-06-14T02:49:01.786+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)
[2024-06-14T02:49:01.787+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)
[2024-06-14T02:49:01.787+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.flatMap(Future.scala:306)
[2024-06-14T02:49:01.787+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.flatMap$(Future.scala:306)
[2024-06-14T02:49:01.788+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)
[2024-06-14T02:49:01.788+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)
[2024-06-14T02:49:01.788+0530] {subprocess.py:93} INFO - 	... 17 more
[2024-06-14T02:49:01.788+0530] {subprocess.py:93} INFO - 24/06/14 02:49:01 WARN Executor: Issue communicating with driver in heartbeater
[2024-06-14T02:49:01.789+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:49:01.789+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:49:01.789+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:49:01.789+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:49:01.790+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2024-06-14T02:49:01.794+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2024-06-14T02:49:01.795+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2024-06-14T02:49:01.796+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2024-06-14T02:49:01.796+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2024-06-14T02:49:01.796+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2024-06-14T02:49:01.797+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:49:01.797+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2024-06-14T02:49:01.797+0530] {subprocess.py:93} INFO - 	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2024-06-14T02:49:01.798+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2024-06-14T02:49:01.798+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2024-06-14T02:49:01.798+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2024-06-14T02:49:01.798+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:49:01.798+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:49:01.799+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:49:01.799+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:49:01.799+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:49:01.799+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:49:01.799+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:49:01.800+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2024-06-14T02:49:01.800+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2024-06-14T02:49:01.800+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2024-06-14T02:49:01.803+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2024-06-14T02:49:01.805+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2024-06-14T02:49:01.806+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2024-06-14T02:49:01.812+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2024-06-14T02:49:01.812+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2024-06-14T02:49:01.812+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:49:01.813+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:49:01.814+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:49:01.814+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:49:01.815+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:49:01.816+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:49:01.816+0530] {subprocess.py:93} INFO - 	... 3 more
[2024-06-14T02:49:01.817+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.56.255:38347
[2024-06-14T02:49:01.817+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2024-06-14T02:49:01.818+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2024-06-14T02:49:01.818+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2024-06-14T02:49:01.819+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2024-06-14T02:49:01.819+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:01.831+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:01.831+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:01.832+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:01.832+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)
[2024-06-14T02:49:01.832+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)
[2024-06-14T02:49:01.832+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.transformWith(Promise.scala:40)
[2024-06-14T02:49:01.833+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)
[2024-06-14T02:49:01.833+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)
[2024-06-14T02:49:01.833+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.flatMap(Future.scala:306)
[2024-06-14T02:49:01.833+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.flatMap$(Future.scala:306)
[2024-06-14T02:49:01.834+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)
[2024-06-14T02:49:01.834+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)
[2024-06-14T02:49:01.834+0530] {subprocess.py:93} INFO - 	... 17 more
[2024-06-14T02:49:01.834+0530] {subprocess.py:93} INFO - 24/06/14 02:49:01 ERROR Inbox: Ignoring error
[2024-06-14T02:49:01.834+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:49:01.834+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:49:01.835+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:49:01.835+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:49:01.835+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2024-06-14T02:49:01.835+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2024-06-14T02:49:01.835+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2024-06-14T02:49:01.835+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2024-06-14T02:49:01.835+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2024-06-14T02:49:01.835+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2024-06-14T02:49:01.836+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2024-06-14T02:49:01.836+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2024-06-14T02:49:01.836+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:49:01.836+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:49:01.836+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:49:01.836+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:49:01.836+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:49:01.836+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:49:01.837+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:49:01.837+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:49:01.837+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:49:01.837+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.56.255:38347
[2024-06-14T02:49:01.837+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2024-06-14T02:49:01.837+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2024-06-14T02:49:01.837+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2024-06-14T02:49:01.838+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2024-06-14T02:49:01.838+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:01.838+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:01.839+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:01.839+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:01.839+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)
[2024-06-14T02:49:01.839+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)
[2024-06-14T02:49:01.839+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.transformWith(Promise.scala:40)
[2024-06-14T02:49:01.847+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)
[2024-06-14T02:49:01.851+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)
[2024-06-14T02:49:01.852+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.flatMap(Future.scala:306)
[2024-06-14T02:49:01.852+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.flatMap$(Future.scala:306)
[2024-06-14T02:49:01.852+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)
[2024-06-14T02:49:01.852+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)
[2024-06-14T02:49:01.853+0530] {subprocess.py:93} INFO - 	... 17 more
[2024-06-14T02:49:01.853+0530] {subprocess.py:93} INFO - 24/06/14 02:49:01 WARN Executor: Issue communicating with driver in heartbeater
[2024-06-14T02:49:01.853+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:49:01.853+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:49:01.853+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:49:01.853+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:49:01.854+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2024-06-14T02:49:01.854+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2024-06-14T02:49:01.854+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2024-06-14T02:49:01.854+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2024-06-14T02:49:01.854+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2024-06-14T02:49:01.855+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2024-06-14T02:49:01.855+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:49:01.855+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2024-06-14T02:49:01.855+0530] {subprocess.py:93} INFO - 	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2024-06-14T02:49:01.855+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2024-06-14T02:49:01.856+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2024-06-14T02:49:01.856+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2024-06-14T02:49:01.856+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:49:01.856+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:49:01.857+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:49:01.857+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:49:01.858+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:49:01.858+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:49:01.860+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:49:01.871+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2024-06-14T02:49:01.872+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2024-06-14T02:49:01.872+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2024-06-14T02:49:01.872+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2024-06-14T02:49:01.872+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2024-06-14T02:49:01.873+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2024-06-14T02:49:01.873+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2024-06-14T02:49:01.873+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2024-06-14T02:49:01.874+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:49:01.874+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:49:01.876+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:49:01.877+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:49:01.878+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:49:01.878+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:49:01.878+0530] {subprocess.py:93} INFO - 	... 3 more
[2024-06-14T02:49:01.879+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.56.255:38347
[2024-06-14T02:49:01.879+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2024-06-14T02:49:01.880+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2024-06-14T02:49:01.880+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2024-06-14T02:49:01.884+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2024-06-14T02:49:01.886+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:01.886+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:01.886+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:01.887+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:01.887+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)
[2024-06-14T02:49:01.887+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)
[2024-06-14T02:49:01.887+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.transformWith(Promise.scala:40)
[2024-06-14T02:49:01.887+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)
[2024-06-14T02:49:01.887+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)
[2024-06-14T02:49:01.887+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.flatMap(Future.scala:306)
[2024-06-14T02:49:01.887+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.flatMap$(Future.scala:306)
[2024-06-14T02:49:01.887+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)
[2024-06-14T02:49:01.887+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)
[2024-06-14T02:49:01.888+0530] {subprocess.py:93} INFO - 	... 17 more
[2024-06-14T02:49:01.888+0530] {subprocess.py:93} INFO - 24/06/14 02:49:01 ERROR Inbox: Ignoring error
[2024-06-14T02:49:01.888+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:49:01.888+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:49:01.888+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:49:01.888+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:49:01.888+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2024-06-14T02:49:01.888+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2024-06-14T02:49:01.888+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2024-06-14T02:49:01.888+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2024-06-14T02:49:01.888+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2024-06-14T02:49:01.889+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2024-06-14T02:49:01.889+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2024-06-14T02:49:01.889+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2024-06-14T02:49:01.889+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:49:01.889+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:49:01.889+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:49:01.889+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:49:01.889+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:49:01.889+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:49:01.889+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:49:01.889+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:49:01.890+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:49:01.890+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.56.255:38347
[2024-06-14T02:49:01.890+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2024-06-14T02:49:01.890+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2024-06-14T02:49:01.890+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2024-06-14T02:49:01.890+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2024-06-14T02:49:01.891+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:01.891+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:01.892+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:01.893+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:01.893+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:01.893+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:01.894+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:01.894+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:01.894+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:01.894+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:01.894+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:49:01.894+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:01.894+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:01.895+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:01.895+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:01.895+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:01.895+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:01.895+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:01.896+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:01.896+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:01.896+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:01.896+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:49:01.896+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:01.896+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2024-06-14T02:49:01.896+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2024-06-14T02:49:01.896+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:49:01.896+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2024-06-14T02:49:01.897+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2024-06-14T02:49:01.897+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2024-06-14T02:49:01.898+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2024-06-14T02:49:01.898+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2024-06-14T02:49:01.898+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2024-06-14T02:49:01.898+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:01.898+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:01.898+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:01.899+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:01.899+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2024-06-14T02:49:01.899+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2024-06-14T02:49:01.899+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2024-06-14T02:49:01.899+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2024-06-14T02:49:01.899+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2024-06-14T02:49:01.899+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2024-06-14T02:49:01.899+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:01.899+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:01.899+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:01.900+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:01.900+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:01.900+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:01.900+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:01.900+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:01.901+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:01.901+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:01.901+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success(Promise.scala:86)
[2024-06-14T02:49:01.901+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success$(Promise.scala:86)
[2024-06-14T02:49:01.901+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2024-06-14T02:49:01.902+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2024-06-14T02:49:01.902+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2024-06-14T02:49:01.902+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2024-06-14T02:49:01.902+0530] {subprocess.py:93} INFO - 	... 8 more
[2024-06-14T02:49:01.902+0530] {subprocess.py:93} INFO - 24/06/14 02:49:01 WARN Executor: Issue communicating with driver in heartbeater
[2024-06-14T02:49:01.902+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:49:01.902+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:49:01.902+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:49:01.902+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:49:01.903+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2024-06-14T02:49:01.903+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2024-06-14T02:49:01.903+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2024-06-14T02:49:01.903+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2024-06-14T02:49:01.903+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2024-06-14T02:49:01.903+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2024-06-14T02:49:01.903+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:49:01.903+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2024-06-14T02:49:01.903+0530] {subprocess.py:93} INFO - 	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2024-06-14T02:49:01.903+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2024-06-14T02:49:01.903+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2024-06-14T02:49:01.903+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2024-06-14T02:49:01.904+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:49:01.904+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:49:01.904+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:49:01.904+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:49:01.904+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:49:01.904+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:49:01.904+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:49:01.904+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2024-06-14T02:49:01.904+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2024-06-14T02:49:01.904+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2024-06-14T02:49:01.905+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2024-06-14T02:49:01.905+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2024-06-14T02:49:01.905+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2024-06-14T02:49:01.905+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2024-06-14T02:49:01.905+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2024-06-14T02:49:01.905+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:49:01.905+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:49:01.906+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:49:01.906+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:49:01.906+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:49:01.906+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:49:01.906+0530] {subprocess.py:93} INFO - 	... 3 more
[2024-06-14T02:49:01.906+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.56.255:38347
[2024-06-14T02:49:01.906+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2024-06-14T02:49:01.906+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2024-06-14T02:49:01.906+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2024-06-14T02:49:01.906+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2024-06-14T02:49:01.906+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:01.907+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:01.908+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:01.908+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:01.909+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:01.910+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:01.910+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:01.910+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:01.910+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:01.910+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:01.911+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:49:01.911+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:01.911+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:01.911+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:01.911+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:01.912+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:01.912+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:01.912+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:01.912+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:01.912+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:01.912+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:01.913+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:49:01.913+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:01.913+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2024-06-14T02:49:01.913+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2024-06-14T02:49:01.914+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:49:01.914+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2024-06-14T02:49:01.915+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2024-06-14T02:49:01.915+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2024-06-14T02:49:01.915+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2024-06-14T02:49:01.915+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2024-06-14T02:49:01.915+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2024-06-14T02:49:01.915+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:01.915+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:01.915+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:01.915+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:01.916+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2024-06-14T02:49:01.916+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2024-06-14T02:49:01.916+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2024-06-14T02:49:01.916+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2024-06-14T02:49:01.916+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2024-06-14T02:49:01.916+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2024-06-14T02:49:01.916+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:01.916+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:01.916+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:01.916+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:01.917+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:01.917+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:01.917+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:01.917+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:01.917+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:01.917+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:01.917+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success(Promise.scala:86)
[2024-06-14T02:49:01.917+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success$(Promise.scala:86)
[2024-06-14T02:49:01.917+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2024-06-14T02:49:01.917+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2024-06-14T02:49:01.917+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2024-06-14T02:49:01.918+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2024-06-14T02:49:01.918+0530] {subprocess.py:93} INFO - 	... 8 more
[2024-06-14T02:49:01.918+0530] {subprocess.py:93} INFO - 24/06/14 02:49:01 ERROR Inbox: Ignoring error
[2024-06-14T02:49:01.918+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:49:01.918+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:49:01.918+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:49:01.918+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:49:01.918+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2024-06-14T02:49:01.918+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2024-06-14T02:49:01.918+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2024-06-14T02:49:01.918+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2024-06-14T02:49:01.919+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2024-06-14T02:49:01.919+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2024-06-14T02:49:01.919+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2024-06-14T02:49:01.919+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2024-06-14T02:49:01.919+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:49:01.919+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:49:01.919+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:49:01.919+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:49:01.919+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:49:01.919+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:49:01.919+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:49:01.920+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:49:01.920+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:49:01.920+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.56.255:38347
[2024-06-14T02:49:01.920+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2024-06-14T02:49:01.920+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2024-06-14T02:49:01.920+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2024-06-14T02:49:01.920+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2024-06-14T02:49:01.920+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:01.920+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:01.920+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:01.920+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:01.920+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:01.921+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:01.921+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:01.921+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:01.921+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:01.921+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:01.921+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:49:01.921+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:01.921+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:01.921+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:01.921+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:01.922+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:01.922+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:01.922+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:01.922+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:01.922+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:01.922+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:01.922+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:49:01.922+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:01.922+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2024-06-14T02:49:01.922+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2024-06-14T02:49:01.922+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:49:01.923+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2024-06-14T02:49:01.923+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2024-06-14T02:49:01.923+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2024-06-14T02:49:01.923+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2024-06-14T02:49:01.923+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2024-06-14T02:49:01.923+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2024-06-14T02:49:01.924+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:01.927+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:01.927+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:01.928+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:01.928+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2024-06-14T02:49:01.928+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2024-06-14T02:49:01.928+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2024-06-14T02:49:01.929+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2024-06-14T02:49:01.929+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2024-06-14T02:49:01.929+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2024-06-14T02:49:01.929+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:01.929+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:01.929+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:01.930+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:01.930+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:01.930+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:01.931+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:01.931+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:01.931+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:01.932+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:01.932+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success(Promise.scala:86)
[2024-06-14T02:49:01.932+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success$(Promise.scala:86)
[2024-06-14T02:49:01.932+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2024-06-14T02:49:01.933+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2024-06-14T02:49:01.933+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2024-06-14T02:49:01.933+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2024-06-14T02:49:01.933+0530] {subprocess.py:93} INFO - 	... 8 more
[2024-06-14T02:49:01.933+0530] {subprocess.py:93} INFO - 24/06/14 02:49:01 WARN Executor: Issue communicating with driver in heartbeater
[2024-06-14T02:49:01.934+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:49:01.934+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:49:01.934+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:49:01.934+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:49:01.934+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2024-06-14T02:49:01.935+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2024-06-14T02:49:01.935+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2024-06-14T02:49:01.935+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2024-06-14T02:49:01.935+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2024-06-14T02:49:01.935+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2024-06-14T02:49:01.935+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:49:01.936+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2024-06-14T02:49:01.936+0530] {subprocess.py:93} INFO - 	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2024-06-14T02:49:01.936+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2024-06-14T02:49:01.936+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2024-06-14T02:49:01.942+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2024-06-14T02:49:01.943+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:49:01.944+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:49:01.944+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:49:01.944+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:49:01.945+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:49:01.945+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:49:01.945+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:49:01.945+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2024-06-14T02:49:01.945+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2024-06-14T02:49:01.946+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2024-06-14T02:49:01.946+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2024-06-14T02:49:01.946+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2024-06-14T02:49:01.947+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2024-06-14T02:49:01.947+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2024-06-14T02:49:01.948+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2024-06-14T02:49:01.948+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:49:01.948+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:49:01.949+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:49:01.949+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:49:01.949+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:49:01.949+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:49:01.950+0530] {subprocess.py:93} INFO - 	... 3 more
[2024-06-14T02:49:01.951+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.56.255:38347
[2024-06-14T02:49:01.952+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2024-06-14T02:49:01.952+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2024-06-14T02:49:01.952+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2024-06-14T02:49:01.952+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2024-06-14T02:49:01.953+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:01.953+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:01.953+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:01.953+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:01.954+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:01.954+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:01.956+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:01.958+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:01.960+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:01.961+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:01.961+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:49:01.961+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:01.962+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:01.962+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:01.962+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:01.963+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:01.963+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:01.965+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:01.965+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:01.967+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:01.968+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:01.968+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:49:01.968+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:01.969+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2024-06-14T02:49:01.969+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2024-06-14T02:49:01.969+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:49:01.969+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2024-06-14T02:49:01.970+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2024-06-14T02:49:01.970+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2024-06-14T02:49:01.970+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2024-06-14T02:49:01.970+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2024-06-14T02:49:01.971+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2024-06-14T02:49:01.971+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:01.971+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:01.971+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:01.971+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:01.972+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2024-06-14T02:49:01.972+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2024-06-14T02:49:01.972+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2024-06-14T02:49:01.972+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2024-06-14T02:49:01.972+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2024-06-14T02:49:01.972+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2024-06-14T02:49:01.972+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:01.972+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:01.972+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:01.972+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:01.973+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:01.973+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:01.973+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:01.973+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:01.973+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:01.973+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:01.973+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success(Promise.scala:86)
[2024-06-14T02:49:01.973+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success$(Promise.scala:86)
[2024-06-14T02:49:01.974+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2024-06-14T02:49:01.974+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2024-06-14T02:49:01.977+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2024-06-14T02:49:01.978+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2024-06-14T02:49:01.978+0530] {subprocess.py:93} INFO - 	... 8 more
[2024-06-14T02:49:02.253+0530] {subprocess.py:93} INFO - 24/06/14 02:49:02 WARN Executor: Issue communicating with driver in heartbeater
[2024-06-14T02:49:02.254+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:49:02.254+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:49:02.255+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:49:02.255+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:49:02.255+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2024-06-14T02:49:02.255+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2024-06-14T02:49:02.256+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2024-06-14T02:49:02.256+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2024-06-14T02:49:02.256+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2024-06-14T02:49:02.256+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2024-06-14T02:49:02.257+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:49:02.257+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2024-06-14T02:49:02.257+0530] {subprocess.py:93} INFO - 	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2024-06-14T02:49:02.257+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2024-06-14T02:49:02.271+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2024-06-14T02:49:02.272+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2024-06-14T02:49:02.272+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:49:02.273+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:49:02.273+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:49:02.274+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:49:02.274+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:49:02.275+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:49:02.277+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:49:02.277+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2024-06-14T02:49:02.277+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2024-06-14T02:49:02.278+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2024-06-14T02:49:02.278+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2024-06-14T02:49:02.278+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2024-06-14T02:49:02.278+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2024-06-14T02:49:02.278+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2024-06-14T02:49:02.287+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2024-06-14T02:49:02.288+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:49:02.288+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:49:02.289+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:49:02.289+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:49:02.289+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:49:02.290+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:49:02.290+0530] {subprocess.py:93} INFO - 	... 3 more
[2024-06-14T02:49:02.291+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.56.255:38347
[2024-06-14T02:49:02.291+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2024-06-14T02:49:02.292+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2024-06-14T02:49:02.293+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2024-06-14T02:49:02.294+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2024-06-14T02:49:02.294+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:02.294+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:02.294+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:02.295+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:02.295+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:02.295+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:02.295+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:02.295+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:02.296+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:02.296+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:02.296+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:49:02.296+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:02.296+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:02.300+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:02.301+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:02.301+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:02.302+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:02.302+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:02.308+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:02.310+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:02.311+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:02.311+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:49:02.311+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:02.312+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2024-06-14T02:49:02.312+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2024-06-14T02:49:02.312+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:49:02.313+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2024-06-14T02:49:02.332+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2024-06-14T02:49:02.332+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2024-06-14T02:49:02.333+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2024-06-14T02:49:02.333+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2024-06-14T02:49:02.333+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2024-06-14T02:49:02.334+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:02.334+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:02.334+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:02.335+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:02.336+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2024-06-14T02:49:02.336+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2024-06-14T02:49:02.337+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2024-06-14T02:49:02.337+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2024-06-14T02:49:02.352+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2024-06-14T02:49:02.352+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2024-06-14T02:49:02.352+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:02.353+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:02.366+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:02.367+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:02.367+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:02.368+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:02.368+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:02.369+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:02.369+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:02.369+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:02.369+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success(Promise.scala:86)
[2024-06-14T02:49:02.370+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success$(Promise.scala:86)
[2024-06-14T02:49:02.370+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2024-06-14T02:49:02.370+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2024-06-14T02:49:02.370+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2024-06-14T02:49:02.371+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2024-06-14T02:49:02.380+0530] {subprocess.py:93} INFO - 	... 8 more
[2024-06-14T02:49:02.381+0530] {subprocess.py:93} INFO - 24/06/14 02:49:02 ERROR Inbox: Ignoring error
[2024-06-14T02:49:02.381+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:49:02.381+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:49:02.381+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:49:02.382+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:49:02.382+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2024-06-14T02:49:02.382+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2024-06-14T02:49:02.382+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2024-06-14T02:49:02.383+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2024-06-14T02:49:02.383+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2024-06-14T02:49:02.383+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2024-06-14T02:49:02.383+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2024-06-14T02:49:02.384+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2024-06-14T02:49:02.384+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:49:02.384+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:49:02.384+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:49:02.397+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:49:02.398+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:49:02.398+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:49:02.398+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:49:02.399+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:49:02.399+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:49:02.399+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.56.255:38347
[2024-06-14T02:49:02.413+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2024-06-14T02:49:02.413+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2024-06-14T02:49:02.414+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2024-06-14T02:49:02.414+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2024-06-14T02:49:02.415+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:02.415+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:02.415+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:02.416+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:02.416+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:02.416+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:02.417+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:02.417+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:02.417+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:02.419+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:02.420+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:49:02.421+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:02.422+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:02.422+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:02.423+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:02.428+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:02.429+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:02.429+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:02.430+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:02.430+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:02.431+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:02.432+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:49:02.432+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:02.433+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2024-06-14T02:49:02.434+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2024-06-14T02:49:02.434+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:49:02.434+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2024-06-14T02:49:02.435+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2024-06-14T02:49:02.435+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2024-06-14T02:49:02.435+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2024-06-14T02:49:02.438+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2024-06-14T02:49:02.439+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2024-06-14T02:49:02.446+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:02.447+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:02.448+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:02.450+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:02.451+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2024-06-14T02:49:02.451+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2024-06-14T02:49:02.451+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2024-06-14T02:49:02.452+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2024-06-14T02:49:02.452+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2024-06-14T02:49:02.452+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2024-06-14T02:49:02.453+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:02.455+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:02.459+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:02.459+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:02.460+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:02.460+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:02.460+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:02.461+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:02.462+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:02.462+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:02.463+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success(Promise.scala:86)
[2024-06-14T02:49:02.463+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success$(Promise.scala:86)
[2024-06-14T02:49:02.464+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2024-06-14T02:49:02.465+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2024-06-14T02:49:02.465+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2024-06-14T02:49:02.465+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2024-06-14T02:49:02.466+0530] {subprocess.py:93} INFO - 	... 8 more
[2024-06-14T02:49:02.466+0530] {subprocess.py:93} INFO - 24/06/14 02:49:02 ERROR Inbox: Ignoring error
[2024-06-14T02:49:02.467+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:49:02.467+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:49:02.467+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:49:02.468+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:49:02.468+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2024-06-14T02:49:02.468+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2024-06-14T02:49:02.469+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2024-06-14T02:49:02.469+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2024-06-14T02:49:02.469+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2024-06-14T02:49:02.470+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2024-06-14T02:49:02.470+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2024-06-14T02:49:02.471+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2024-06-14T02:49:02.471+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:49:02.471+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:49:02.472+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:49:02.472+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:49:02.473+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:49:02.473+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:49:02.474+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:49:02.474+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:49:02.474+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:49:02.474+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.56.255:38347
[2024-06-14T02:49:02.475+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2024-06-14T02:49:02.475+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2024-06-14T02:49:02.475+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2024-06-14T02:49:02.476+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2024-06-14T02:49:02.476+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:02.483+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:02.484+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:02.484+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:02.485+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:02.487+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:02.487+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:02.488+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:02.488+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:02.489+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:02.489+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:49:02.490+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:02.490+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:02.490+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:02.491+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:02.491+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:02.492+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:02.492+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:02.492+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:02.493+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:02.493+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:02.494+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:49:02.508+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:02.508+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2024-06-14T02:49:02.508+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2024-06-14T02:49:02.509+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:49:02.509+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2024-06-14T02:49:02.510+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2024-06-14T02:49:02.510+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2024-06-14T02:49:02.510+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2024-06-14T02:49:02.511+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2024-06-14T02:49:02.511+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2024-06-14T02:49:02.512+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:02.512+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:02.523+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:02.525+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:02.526+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2024-06-14T02:49:02.526+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2024-06-14T02:49:02.527+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2024-06-14T02:49:02.527+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2024-06-14T02:49:02.527+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2024-06-14T02:49:02.528+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2024-06-14T02:49:02.528+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:02.528+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:02.528+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:02.529+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:02.529+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:02.530+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:02.530+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:02.530+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:02.531+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:02.531+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:02.532+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success(Promise.scala:86)
[2024-06-14T02:49:02.532+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success$(Promise.scala:86)
[2024-06-14T02:49:02.533+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2024-06-14T02:49:02.534+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2024-06-14T02:49:02.535+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2024-06-14T02:49:02.535+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2024-06-14T02:49:02.535+0530] {subprocess.py:93} INFO - 	... 8 more
[2024-06-14T02:49:02.536+0530] {subprocess.py:93} INFO - 24/06/14 02:49:02 WARN Executor: Issue communicating with driver in heartbeater
[2024-06-14T02:49:02.537+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:49:02.537+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:49:02.537+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:49:02.537+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:49:02.537+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2024-06-14T02:49:02.537+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2024-06-14T02:49:02.538+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2024-06-14T02:49:02.538+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2024-06-14T02:49:02.538+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2024-06-14T02:49:02.538+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2024-06-14T02:49:02.539+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:49:02.540+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2024-06-14T02:49:02.545+0530] {subprocess.py:93} INFO - 	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2024-06-14T02:49:02.545+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2024-06-14T02:49:02.545+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2024-06-14T02:49:02.545+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2024-06-14T02:49:02.546+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:49:02.546+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:49:02.547+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:49:02.547+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:49:02.547+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:49:02.548+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:49:02.548+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:49:02.549+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2024-06-14T02:49:02.549+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2024-06-14T02:49:02.549+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2024-06-14T02:49:02.549+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2024-06-14T02:49:02.549+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2024-06-14T02:49:02.549+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2024-06-14T02:49:02.549+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2024-06-14T02:49:02.550+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2024-06-14T02:49:02.550+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:49:02.550+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:49:02.550+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:49:02.550+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:49:02.550+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:49:02.550+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:49:02.550+0530] {subprocess.py:93} INFO - 	... 3 more
[2024-06-14T02:49:02.550+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.56.255:38347
[2024-06-14T02:49:02.550+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2024-06-14T02:49:02.551+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2024-06-14T02:49:02.551+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2024-06-14T02:49:02.551+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2024-06-14T02:49:02.551+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:02.552+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:02.553+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:02.554+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:02.554+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:02.555+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:02.560+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:02.563+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:02.564+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:02.565+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:02.565+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:49:02.565+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:02.565+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:02.565+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:02.566+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:02.566+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:02.566+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:02.567+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:02.567+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:02.568+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:02.568+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:02.569+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:49:02.570+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:02.578+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2024-06-14T02:49:02.579+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2024-06-14T02:49:02.579+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:49:02.579+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2024-06-14T02:49:02.579+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2024-06-14T02:49:02.579+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2024-06-14T02:49:02.579+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2024-06-14T02:49:02.579+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2024-06-14T02:49:02.581+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2024-06-14T02:49:02.582+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:02.582+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:02.583+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:02.583+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:02.583+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2024-06-14T02:49:02.584+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2024-06-14T02:49:02.584+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2024-06-14T02:49:02.585+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2024-06-14T02:49:02.586+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2024-06-14T02:49:02.586+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2024-06-14T02:49:02.586+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:02.586+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:02.586+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:02.586+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:02.586+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:02.587+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:02.587+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:02.587+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:02.587+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:02.587+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:02.587+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success(Promise.scala:86)
[2024-06-14T02:49:02.587+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success$(Promise.scala:86)
[2024-06-14T02:49:02.587+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2024-06-14T02:49:02.587+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2024-06-14T02:49:02.587+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2024-06-14T02:49:02.588+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2024-06-14T02:49:02.588+0530] {subprocess.py:93} INFO - 	... 8 more
[2024-06-14T02:49:02.589+0530] {subprocess.py:93} INFO - 24/06/14 02:49:02 ERROR Inbox: Ignoring error
[2024-06-14T02:49:02.589+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:49:02.589+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:49:02.589+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:49:02.589+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:49:02.589+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2024-06-14T02:49:02.590+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2024-06-14T02:49:02.590+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2024-06-14T02:49:02.592+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2024-06-14T02:49:02.593+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2024-06-14T02:49:02.593+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2024-06-14T02:49:02.593+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2024-06-14T02:49:02.593+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2024-06-14T02:49:02.594+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:49:02.594+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:49:02.594+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:49:02.594+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:49:02.595+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:49:02.595+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:49:02.595+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:49:02.595+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:49:02.596+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:49:02.596+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.56.255:38347
[2024-06-14T02:49:02.597+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2024-06-14T02:49:02.598+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2024-06-14T02:49:02.598+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2024-06-14T02:49:02.598+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2024-06-14T02:49:02.600+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:02.600+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:02.600+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:02.600+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:02.600+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:02.600+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:02.600+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:02.601+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:02.601+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:02.601+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:02.601+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:49:02.601+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:02.601+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:02.601+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:02.601+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:02.601+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:02.601+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:02.601+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:02.602+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:02.602+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:02.602+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:02.602+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:49:02.602+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:02.602+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2024-06-14T02:49:02.602+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2024-06-14T02:49:02.602+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:49:02.602+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2024-06-14T02:49:02.602+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2024-06-14T02:49:02.603+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2024-06-14T02:49:02.603+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2024-06-14T02:49:02.603+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2024-06-14T02:49:02.603+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2024-06-14T02:49:02.603+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:02.603+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:02.603+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:02.603+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:02.603+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2024-06-14T02:49:02.603+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2024-06-14T02:49:02.603+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2024-06-14T02:49:02.603+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2024-06-14T02:49:02.604+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2024-06-14T02:49:02.604+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2024-06-14T02:49:02.604+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:02.604+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:02.604+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:02.605+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:02.605+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:02.605+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:02.605+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:02.605+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:02.605+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:02.605+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:02.605+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success(Promise.scala:86)
[2024-06-14T02:49:02.605+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success$(Promise.scala:86)
[2024-06-14T02:49:02.606+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2024-06-14T02:49:02.606+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2024-06-14T02:49:02.606+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2024-06-14T02:49:02.606+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2024-06-14T02:49:02.606+0530] {subprocess.py:93} INFO - 	... 8 more
[2024-06-14T02:49:02.606+0530] {subprocess.py:93} INFO - 24/06/14 02:49:02 WARN Executor: Issue communicating with driver in heartbeater
[2024-06-14T02:49:02.606+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:49:02.606+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:49:02.606+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:49:02.606+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:49:02.607+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2024-06-14T02:49:02.609+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2024-06-14T02:49:02.609+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2024-06-14T02:49:02.609+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2024-06-14T02:49:02.610+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2024-06-14T02:49:02.610+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2024-06-14T02:49:02.610+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:49:02.610+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2024-06-14T02:49:02.610+0530] {subprocess.py:93} INFO - 	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2024-06-14T02:49:02.610+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2024-06-14T02:49:02.610+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2024-06-14T02:49:02.610+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2024-06-14T02:49:02.610+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:49:02.611+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:49:02.611+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:49:02.611+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:49:02.611+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:49:02.611+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:49:02.611+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:49:02.611+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2024-06-14T02:49:02.611+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2024-06-14T02:49:02.612+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2024-06-14T02:49:02.613+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2024-06-14T02:49:02.613+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2024-06-14T02:49:02.613+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2024-06-14T02:49:02.615+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2024-06-14T02:49:02.615+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2024-06-14T02:49:02.615+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:49:02.615+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:49:02.615+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:49:02.616+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:49:02.616+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:49:02.616+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:49:02.616+0530] {subprocess.py:93} INFO - 	... 3 more
[2024-06-14T02:49:02.616+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.56.255:38347
[2024-06-14T02:49:02.616+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2024-06-14T02:49:02.616+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2024-06-14T02:49:02.616+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2024-06-14T02:49:02.616+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2024-06-14T02:49:02.617+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:02.617+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:02.617+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:02.617+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:02.617+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:02.617+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:02.617+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:02.617+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:02.618+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:02.618+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:02.618+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:49:02.618+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:02.618+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:02.619+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:02.619+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:02.619+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:02.619+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:02.619+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:02.619+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:02.620+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:02.620+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:02.620+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:49:02.620+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:02.620+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2024-06-14T02:49:02.620+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2024-06-14T02:49:02.620+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:49:02.620+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2024-06-14T02:49:02.620+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2024-06-14T02:49:02.620+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2024-06-14T02:49:02.620+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2024-06-14T02:49:02.621+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2024-06-14T02:49:02.621+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2024-06-14T02:49:02.621+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:02.621+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:02.621+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:02.621+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:02.621+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2024-06-14T02:49:02.621+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2024-06-14T02:49:02.621+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2024-06-14T02:49:02.621+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2024-06-14T02:49:02.621+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2024-06-14T02:49:02.622+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2024-06-14T02:49:02.622+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:02.622+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:02.622+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:02.622+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:02.622+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:02.622+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:02.622+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:02.622+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:02.622+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:02.623+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:02.623+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success(Promise.scala:86)
[2024-06-14T02:49:02.623+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success$(Promise.scala:86)
[2024-06-14T02:49:02.623+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2024-06-14T02:49:02.623+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2024-06-14T02:49:02.623+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2024-06-14T02:49:02.623+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2024-06-14T02:49:02.623+0530] {subprocess.py:93} INFO - 	... 8 more
[2024-06-14T02:49:02.624+0530] {subprocess.py:93} INFO - 24/06/14 02:49:02 ERROR Inbox: Ignoring error
[2024-06-14T02:49:02.625+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:49:02.626+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:49:02.626+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:49:02.626+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:49:02.626+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2024-06-14T02:49:02.626+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2024-06-14T02:49:02.626+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2024-06-14T02:49:02.626+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2024-06-14T02:49:02.627+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2024-06-14T02:49:02.627+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2024-06-14T02:49:02.627+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2024-06-14T02:49:02.627+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2024-06-14T02:49:02.627+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:49:02.627+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:49:02.627+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:49:02.627+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:49:02.627+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:49:02.627+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:49:02.628+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:49:02.628+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:49:02.628+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:49:02.628+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.56.255:38347
[2024-06-14T02:49:02.628+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2024-06-14T02:49:02.629+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2024-06-14T02:49:02.629+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2024-06-14T02:49:02.630+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2024-06-14T02:49:02.631+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:02.631+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:02.631+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:02.632+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:02.632+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:02.632+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:02.632+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:02.632+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:02.633+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:02.633+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:02.633+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:49:02.633+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:02.633+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:02.634+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:02.634+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:02.634+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:02.634+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:02.635+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:02.635+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:02.635+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:02.636+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:02.636+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:49:02.636+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:02.637+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2024-06-14T02:49:02.637+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2024-06-14T02:49:02.637+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:49:02.637+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2024-06-14T02:49:02.637+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2024-06-14T02:49:02.637+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2024-06-14T02:49:02.638+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2024-06-14T02:49:02.638+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2024-06-14T02:49:02.638+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2024-06-14T02:49:02.638+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:02.638+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:02.638+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:02.638+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:02.639+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2024-06-14T02:49:02.639+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2024-06-14T02:49:02.639+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2024-06-14T02:49:02.639+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2024-06-14T02:49:02.639+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2024-06-14T02:49:02.639+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2024-06-14T02:49:02.639+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:02.640+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:02.640+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:02.640+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:02.641+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:02.642+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:02.647+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:02.648+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:02.648+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:02.650+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:02.651+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success(Promise.scala:86)
[2024-06-14T02:49:02.652+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success$(Promise.scala:86)
[2024-06-14T02:49:02.652+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2024-06-14T02:49:02.653+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2024-06-14T02:49:02.653+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2024-06-14T02:49:02.654+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2024-06-14T02:49:02.657+0530] {subprocess.py:93} INFO - 	... 8 more
[2024-06-14T02:49:02.664+0530] {subprocess.py:93} INFO - 24/06/14 02:49:02 WARN Executor: Issue communicating with driver in heartbeater
[2024-06-14T02:49:02.671+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:49:02.672+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:49:02.672+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:49:02.672+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:49:02.673+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2024-06-14T02:49:02.673+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2024-06-14T02:49:02.673+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2024-06-14T02:49:02.673+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2024-06-14T02:49:02.677+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2024-06-14T02:49:02.678+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2024-06-14T02:49:02.679+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:49:02.681+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2024-06-14T02:49:02.681+0530] {subprocess.py:93} INFO - 	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2024-06-14T02:49:02.682+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2024-06-14T02:49:02.682+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2024-06-14T02:49:02.682+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2024-06-14T02:49:02.683+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:49:02.683+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:49:02.684+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:49:02.684+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:49:02.685+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:49:02.685+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:49:02.685+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:49:02.687+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2024-06-14T02:49:02.687+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2024-06-14T02:49:02.687+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2024-06-14T02:49:02.688+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2024-06-14T02:49:02.688+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2024-06-14T02:49:02.699+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2024-06-14T02:49:02.700+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2024-06-14T02:49:02.700+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2024-06-14T02:49:02.700+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:49:02.701+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:49:02.701+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:49:02.702+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:49:02.702+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:49:02.702+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:49:02.704+0530] {subprocess.py:93} INFO - 	... 3 more
[2024-06-14T02:49:02.704+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.56.255:38347
[2024-06-14T02:49:02.704+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2024-06-14T02:49:02.705+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2024-06-14T02:49:02.705+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2024-06-14T02:49:02.705+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2024-06-14T02:49:02.705+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:02.706+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:02.706+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:02.706+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:02.707+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:02.707+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:02.708+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:02.716+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:02.717+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:02.717+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:02.718+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:49:02.719+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:02.720+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:02.720+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:02.720+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:02.720+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:02.720+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:02.721+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:02.721+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:02.721+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:02.722+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:02.722+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:49:02.723+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:02.723+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2024-06-14T02:49:02.723+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2024-06-14T02:49:02.724+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:49:02.724+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2024-06-14T02:49:02.726+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2024-06-14T02:49:02.726+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2024-06-14T02:49:02.734+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2024-06-14T02:49:02.735+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2024-06-14T02:49:02.736+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2024-06-14T02:49:02.736+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:02.736+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:02.736+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:02.736+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:02.736+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2024-06-14T02:49:02.737+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2024-06-14T02:49:02.737+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2024-06-14T02:49:02.737+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2024-06-14T02:49:02.737+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2024-06-14T02:49:02.737+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2024-06-14T02:49:02.737+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:02.737+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:02.738+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:02.738+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:02.738+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:02.738+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:02.738+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:02.738+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:02.739+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:02.739+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:02.739+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success(Promise.scala:86)
[2024-06-14T02:49:02.739+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success$(Promise.scala:86)
[2024-06-14T02:49:02.739+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2024-06-14T02:49:02.739+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2024-06-14T02:49:02.739+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2024-06-14T02:49:02.740+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2024-06-14T02:49:02.740+0530] {subprocess.py:93} INFO - 	... 8 more
[2024-06-14T02:49:02.740+0530] {subprocess.py:93} INFO - 24/06/14 02:49:02 WARN Executor: Issue communicating with driver in heartbeater
[2024-06-14T02:49:02.741+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:49:02.741+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:49:02.742+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:49:02.743+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:49:02.743+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2024-06-14T02:49:02.744+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2024-06-14T02:49:02.751+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2024-06-14T02:49:02.752+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2024-06-14T02:49:02.752+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2024-06-14T02:49:02.752+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2024-06-14T02:49:02.753+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:49:02.753+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2024-06-14T02:49:02.754+0530] {subprocess.py:93} INFO - 	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2024-06-14T02:49:02.754+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2024-06-14T02:49:02.755+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2024-06-14T02:49:02.755+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2024-06-14T02:49:02.755+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:49:02.756+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:49:02.756+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:49:02.756+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:49:02.756+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:49:02.756+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:49:02.756+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:49:02.757+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2024-06-14T02:49:02.757+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2024-06-14T02:49:02.757+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2024-06-14T02:49:02.758+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2024-06-14T02:49:02.759+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2024-06-14T02:49:02.759+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2024-06-14T02:49:02.760+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2024-06-14T02:49:02.760+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2024-06-14T02:49:02.761+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:49:02.765+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:49:02.766+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:49:02.766+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:49:02.767+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:49:02.767+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:49:02.768+0530] {subprocess.py:93} INFO - 	... 3 more
[2024-06-14T02:49:02.768+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.56.255:38347
[2024-06-14T02:49:02.768+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2024-06-14T02:49:02.768+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2024-06-14T02:49:02.769+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2024-06-14T02:49:02.769+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2024-06-14T02:49:02.770+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:02.772+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:02.772+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:02.773+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:02.773+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:02.774+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:02.775+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:02.776+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:02.777+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:02.778+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:02.779+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:49:02.779+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:02.779+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:02.779+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:02.780+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:02.780+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:02.780+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:02.781+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:02.781+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:02.782+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:02.782+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:02.782+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:49:02.783+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:02.783+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2024-06-14T02:49:02.786+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2024-06-14T02:49:02.786+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:49:02.787+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2024-06-14T02:49:02.787+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2024-06-14T02:49:02.788+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2024-06-14T02:49:02.788+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2024-06-14T02:49:02.789+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2024-06-14T02:49:02.790+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2024-06-14T02:49:02.792+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:02.794+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:02.794+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:02.795+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:02.795+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2024-06-14T02:49:02.795+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2024-06-14T02:49:02.796+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2024-06-14T02:49:02.796+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2024-06-14T02:49:02.796+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2024-06-14T02:49:02.797+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2024-06-14T02:49:02.797+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:02.797+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:02.798+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:02.798+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:02.798+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:02.801+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:02.802+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:02.804+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:02.805+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:02.806+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:02.806+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success(Promise.scala:86)
[2024-06-14T02:49:02.807+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success$(Promise.scala:86)
[2024-06-14T02:49:02.808+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2024-06-14T02:49:02.809+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2024-06-14T02:49:02.810+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2024-06-14T02:49:02.811+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2024-06-14T02:49:02.811+0530] {subprocess.py:93} INFO - 	... 8 more
[2024-06-14T02:49:02.811+0530] {subprocess.py:93} INFO - 24/06/14 02:49:02 ERROR Inbox: Ignoring error
[2024-06-14T02:49:02.811+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:49:02.811+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:49:02.812+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:49:02.812+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:49:02.812+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2024-06-14T02:49:02.812+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2024-06-14T02:49:02.812+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2024-06-14T02:49:02.813+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2024-06-14T02:49:02.813+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2024-06-14T02:49:02.813+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2024-06-14T02:49:02.813+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2024-06-14T02:49:02.814+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2024-06-14T02:49:02.814+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:49:02.814+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:49:02.815+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:49:02.815+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:49:02.815+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:49:02.815+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:49:02.815+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:49:02.816+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:49:02.816+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:49:02.816+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.56.255:38347
[2024-06-14T02:49:02.817+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2024-06-14T02:49:02.817+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2024-06-14T02:49:02.817+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2024-06-14T02:49:02.818+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2024-06-14T02:49:02.818+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:02.818+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:02.819+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:02.820+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:02.820+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:02.821+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:02.828+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:02.829+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:02.831+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:02.832+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:02.832+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:49:02.832+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:02.833+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:02.833+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:02.834+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:02.834+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:02.837+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:02.837+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:02.838+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:02.838+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:02.838+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:02.838+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:49:02.839+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:02.839+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2024-06-14T02:49:02.839+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2024-06-14T02:49:02.839+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:49:02.840+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2024-06-14T02:49:02.840+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2024-06-14T02:49:02.840+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2024-06-14T02:49:02.845+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2024-06-14T02:49:02.846+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2024-06-14T02:49:02.846+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2024-06-14T02:49:02.846+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:02.847+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:02.847+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:02.848+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:02.850+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2024-06-14T02:49:02.850+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2024-06-14T02:49:02.851+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2024-06-14T02:49:02.851+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2024-06-14T02:49:02.851+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2024-06-14T02:49:02.852+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2024-06-14T02:49:02.852+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:02.852+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:02.853+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:02.853+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:02.853+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:02.854+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:02.854+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:02.854+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:02.854+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:02.855+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:02.855+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success(Promise.scala:86)
[2024-06-14T02:49:02.855+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success$(Promise.scala:86)
[2024-06-14T02:49:02.855+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2024-06-14T02:49:02.856+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2024-06-14T02:49:02.856+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2024-06-14T02:49:02.856+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2024-06-14T02:49:02.861+0530] {subprocess.py:93} INFO - 	... 8 more
[2024-06-14T02:49:02.862+0530] {subprocess.py:93} INFO - 24/06/14 02:49:02 ERROR Inbox: Ignoring error
[2024-06-14T02:49:02.862+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:49:02.862+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:49:02.863+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:49:02.867+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:49:02.868+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2024-06-14T02:49:02.868+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2024-06-14T02:49:02.868+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2024-06-14T02:49:02.869+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2024-06-14T02:49:02.870+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2024-06-14T02:49:02.871+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2024-06-14T02:49:02.872+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2024-06-14T02:49:02.873+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2024-06-14T02:49:02.873+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:49:02.873+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:49:02.874+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:49:02.874+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:49:02.874+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:49:02.875+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:49:02.877+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:49:02.878+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:49:02.878+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:49:02.878+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.56.255:38347
[2024-06-14T02:49:02.879+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2024-06-14T02:49:02.880+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2024-06-14T02:49:02.880+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2024-06-14T02:49:02.880+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2024-06-14T02:49:02.881+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:02.882+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:02.882+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:02.883+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:02.883+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)
[2024-06-14T02:49:02.884+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)
[2024-06-14T02:49:02.884+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.transformWith(Promise.scala:40)
[2024-06-14T02:49:02.885+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)
[2024-06-14T02:49:02.886+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)
[2024-06-14T02:49:02.886+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.flatMap(Future.scala:306)
[2024-06-14T02:49:02.886+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.flatMap$(Future.scala:306)
[2024-06-14T02:49:02.886+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)
[2024-06-14T02:49:02.887+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)
[2024-06-14T02:49:02.887+0530] {subprocess.py:93} INFO - 	... 17 more
[2024-06-14T02:49:02.887+0530] {subprocess.py:93} INFO - 24/06/14 02:49:02 WARN Executor: Issue communicating with driver in heartbeater
[2024-06-14T02:49:02.887+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:49:02.888+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:49:02.888+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:49:02.888+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:49:02.888+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2024-06-14T02:49:02.888+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2024-06-14T02:49:02.889+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2024-06-14T02:49:02.889+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2024-06-14T02:49:02.889+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2024-06-14T02:49:02.889+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2024-06-14T02:49:02.889+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:49:02.890+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2024-06-14T02:49:02.890+0530] {subprocess.py:93} INFO - 	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2024-06-14T02:49:02.890+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2024-06-14T02:49:02.891+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2024-06-14T02:49:02.893+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2024-06-14T02:49:02.894+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:49:02.894+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:49:02.895+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:49:02.896+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:49:02.896+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:49:02.897+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:49:02.900+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:49:02.901+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2024-06-14T02:49:02.902+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2024-06-14T02:49:02.902+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2024-06-14T02:49:02.902+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2024-06-14T02:49:02.903+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2024-06-14T02:49:02.903+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2024-06-14T02:49:02.903+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2024-06-14T02:49:02.904+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2024-06-14T02:49:02.904+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:49:02.904+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:49:02.904+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:49:02.904+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:49:02.904+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:49:02.905+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:49:02.905+0530] {subprocess.py:93} INFO - 	... 3 more
[2024-06-14T02:49:02.905+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.56.255:38347
[2024-06-14T02:49:02.905+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2024-06-14T02:49:02.905+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2024-06-14T02:49:02.906+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2024-06-14T02:49:02.906+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2024-06-14T02:49:02.906+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:02.906+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:02.906+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:02.907+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:02.907+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)
[2024-06-14T02:49:02.907+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)
[2024-06-14T02:49:02.908+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.transformWith(Promise.scala:40)
[2024-06-14T02:49:02.908+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)
[2024-06-14T02:49:02.908+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)
[2024-06-14T02:49:02.908+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.flatMap(Future.scala:306)
[2024-06-14T02:49:02.909+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.flatMap$(Future.scala:306)
[2024-06-14T02:49:02.909+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)
[2024-06-14T02:49:02.909+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)
[2024-06-14T02:49:02.909+0530] {subprocess.py:93} INFO - 	... 17 more
[2024-06-14T02:49:02.910+0530] {subprocess.py:93} INFO - 24/06/14 02:49:02 ERROR Inbox: Ignoring error
[2024-06-14T02:49:02.912+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:49:02.912+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:49:02.912+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:49:02.912+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:49:02.912+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2024-06-14T02:49:02.913+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2024-06-14T02:49:02.913+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2024-06-14T02:49:02.913+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2024-06-14T02:49:02.914+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2024-06-14T02:49:02.914+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2024-06-14T02:49:02.914+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2024-06-14T02:49:02.915+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2024-06-14T02:49:02.915+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:49:02.916+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:49:02.916+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:49:02.917+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:49:02.918+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:49:02.919+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:49:02.919+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:49:02.919+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:49:02.920+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:49:02.920+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.56.255:38347
[2024-06-14T02:49:02.920+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2024-06-14T02:49:02.921+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2024-06-14T02:49:02.921+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2024-06-14T02:49:02.922+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2024-06-14T02:49:02.922+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:02.922+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:02.923+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:02.923+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:02.923+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)
[2024-06-14T02:49:02.924+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)
[2024-06-14T02:49:02.924+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.transformWith(Promise.scala:40)
[2024-06-14T02:49:02.925+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)
[2024-06-14T02:49:02.925+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)
[2024-06-14T02:49:02.925+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.flatMap(Future.scala:306)
[2024-06-14T02:49:02.925+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.flatMap$(Future.scala:306)
[2024-06-14T02:49:02.926+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)
[2024-06-14T02:49:02.926+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)
[2024-06-14T02:49:02.926+0530] {subprocess.py:93} INFO - 	... 17 more
[2024-06-14T02:49:02.927+0530] {subprocess.py:93} INFO - 24/06/14 02:49:02 WARN Executor: Issue communicating with driver in heartbeater
[2024-06-14T02:49:02.927+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:49:02.927+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:49:02.927+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:49:02.929+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:49:02.930+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2024-06-14T02:49:02.931+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2024-06-14T02:49:02.936+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2024-06-14T02:49:02.936+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2024-06-14T02:49:02.937+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2024-06-14T02:49:02.937+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2024-06-14T02:49:02.937+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:49:02.938+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2024-06-14T02:49:02.938+0530] {subprocess.py:93} INFO - 	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2024-06-14T02:49:02.939+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2024-06-14T02:49:02.939+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2024-06-14T02:49:02.942+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2024-06-14T02:49:02.945+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:49:02.945+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:49:02.946+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:49:02.946+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:49:02.946+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:49:02.946+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:49:02.947+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:49:02.947+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2024-06-14T02:49:02.947+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2024-06-14T02:49:02.948+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2024-06-14T02:49:02.948+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2024-06-14T02:49:02.950+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2024-06-14T02:49:02.950+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2024-06-14T02:49:02.951+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2024-06-14T02:49:02.952+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2024-06-14T02:49:02.952+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:49:02.952+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:49:02.959+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:49:02.960+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:49:02.961+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:49:02.961+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:49:02.961+0530] {subprocess.py:93} INFO - 	... 3 more
[2024-06-14T02:49:02.962+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.56.255:38347
[2024-06-14T02:49:02.962+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2024-06-14T02:49:02.962+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2024-06-14T02:49:02.962+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2024-06-14T02:49:02.963+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2024-06-14T02:49:02.963+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:02.963+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:02.963+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:02.964+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:02.964+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)
[2024-06-14T02:49:02.964+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)
[2024-06-14T02:49:02.964+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.transformWith(Promise.scala:40)
[2024-06-14T02:49:02.964+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)
[2024-06-14T02:49:02.965+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)
[2024-06-14T02:49:02.965+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.flatMap(Future.scala:306)
[2024-06-14T02:49:02.965+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.flatMap$(Future.scala:306)
[2024-06-14T02:49:02.965+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)
[2024-06-14T02:49:02.966+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)
[2024-06-14T02:49:02.968+0530] {subprocess.py:93} INFO - 	... 17 more
[2024-06-14T02:49:02.968+0530] {subprocess.py:93} INFO - 24/06/14 02:49:02 WARN Executor: Issue communicating with driver in heartbeater
[2024-06-14T02:49:02.969+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:49:02.969+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:49:02.970+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:49:02.970+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:49:02.970+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2024-06-14T02:49:02.971+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2024-06-14T02:49:02.972+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2024-06-14T02:49:02.972+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2024-06-14T02:49:02.973+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2024-06-14T02:49:02.973+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2024-06-14T02:49:02.977+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:49:02.977+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2024-06-14T02:49:02.977+0530] {subprocess.py:93} INFO - 	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2024-06-14T02:49:02.978+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2024-06-14T02:49:02.978+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2024-06-14T02:49:02.978+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2024-06-14T02:49:02.979+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:49:02.979+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:49:02.979+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:49:02.980+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:49:02.980+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:49:02.980+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:49:02.981+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:49:02.981+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2024-06-14T02:49:02.981+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2024-06-14T02:49:02.981+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2024-06-14T02:49:02.982+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2024-06-14T02:49:02.982+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2024-06-14T02:49:02.982+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2024-06-14T02:49:02.983+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2024-06-14T02:49:02.983+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2024-06-14T02:49:02.983+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:49:02.983+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:49:02.983+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:49:02.984+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:49:02.984+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:49:02.984+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:49:02.984+0530] {subprocess.py:93} INFO - 	... 3 more
[2024-06-14T02:49:02.985+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.56.255:38347
[2024-06-14T02:49:02.985+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2024-06-14T02:49:02.985+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2024-06-14T02:49:02.986+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2024-06-14T02:49:02.986+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2024-06-14T02:49:02.987+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:02.987+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:02.988+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:02.988+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:02.989+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)
[2024-06-14T02:49:02.991+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)
[2024-06-14T02:49:02.992+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.transformWith(Promise.scala:40)
[2024-06-14T02:49:02.993+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)
[2024-06-14T02:49:02.993+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)
[2024-06-14T02:49:02.994+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.flatMap(Future.scala:306)
[2024-06-14T02:49:02.994+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.flatMap$(Future.scala:306)
[2024-06-14T02:49:02.994+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)
[2024-06-14T02:49:02.995+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)
[2024-06-14T02:49:02.997+0530] {subprocess.py:93} INFO - 	... 17 more
[2024-06-14T02:49:02.997+0530] {subprocess.py:93} INFO - 24/06/14 02:49:02 ERROR Inbox: Ignoring error
[2024-06-14T02:49:02.998+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:49:02.998+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:49:02.998+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:49:02.998+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:49:02.998+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2024-06-14T02:49:02.999+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2024-06-14T02:49:02.999+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2024-06-14T02:49:02.999+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2024-06-14T02:49:02.999+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2024-06-14T02:49:02.999+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2024-06-14T02:49:02.999+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2024-06-14T02:49:03.000+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2024-06-14T02:49:03.000+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:49:03.000+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:49:03.000+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:49:03.000+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:49:03.001+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:49:03.001+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:49:03.001+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:49:03.001+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:49:03.001+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:49:03.002+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.56.255:38347
[2024-06-14T02:49:03.002+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2024-06-14T02:49:03.002+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2024-06-14T02:49:03.002+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2024-06-14T02:49:03.002+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2024-06-14T02:49:03.003+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:03.003+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:03.003+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:03.003+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:03.004+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)
[2024-06-14T02:49:03.008+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)
[2024-06-14T02:49:03.008+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.transformWith(Promise.scala:40)
[2024-06-14T02:49:03.009+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)
[2024-06-14T02:49:03.009+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)
[2024-06-14T02:49:03.009+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.flatMap(Future.scala:306)
[2024-06-14T02:49:03.009+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.flatMap$(Future.scala:306)
[2024-06-14T02:49:03.010+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)
[2024-06-14T02:49:03.010+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)
[2024-06-14T02:49:03.010+0530] {subprocess.py:93} INFO - 	... 17 more
[2024-06-14T02:49:03.012+0530] {subprocess.py:93} INFO - 24/06/14 02:49:02 ERROR Inbox: Ignoring error
[2024-06-14T02:49:03.012+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:49:03.013+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:49:03.013+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:49:03.013+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:49:03.014+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2024-06-14T02:49:03.014+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2024-06-14T02:49:03.014+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2024-06-14T02:49:03.015+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2024-06-14T02:49:03.015+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2024-06-14T02:49:03.016+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2024-06-14T02:49:03.016+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2024-06-14T02:49:03.016+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2024-06-14T02:49:03.016+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:49:03.017+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:49:03.017+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:49:03.017+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:49:03.017+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:49:03.018+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:49:03.018+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:49:03.018+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:49:03.018+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:49:03.018+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.56.255:38347
[2024-06-14T02:49:03.019+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2024-06-14T02:49:03.019+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2024-06-14T02:49:03.020+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2024-06-14T02:49:03.020+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2024-06-14T02:49:03.020+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:03.020+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:03.021+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:03.021+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:03.021+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:03.021+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:03.022+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:03.022+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:03.022+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:03.022+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:03.022+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:49:03.023+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:03.023+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:03.023+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:03.027+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:03.027+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:03.031+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:03.032+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:03.033+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:03.033+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:03.034+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:03.036+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:49:03.036+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:03.037+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2024-06-14T02:49:03.037+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2024-06-14T02:49:03.037+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:49:03.038+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2024-06-14T02:49:03.038+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2024-06-14T02:49:03.038+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2024-06-14T02:49:03.039+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2024-06-14T02:49:03.039+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2024-06-14T02:49:03.039+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2024-06-14T02:49:03.039+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:03.040+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:03.040+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:03.040+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:03.040+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2024-06-14T02:49:03.040+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2024-06-14T02:49:03.041+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2024-06-14T02:49:03.041+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2024-06-14T02:49:03.041+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2024-06-14T02:49:03.042+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2024-06-14T02:49:03.042+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:03.042+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:03.043+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:03.044+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:03.046+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:03.047+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:03.048+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:03.049+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:03.049+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:03.049+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:03.050+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success(Promise.scala:86)
[2024-06-14T02:49:03.050+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success$(Promise.scala:86)
[2024-06-14T02:49:03.050+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2024-06-14T02:49:03.051+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2024-06-14T02:49:03.052+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2024-06-14T02:49:03.052+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2024-06-14T02:49:03.053+0530] {subprocess.py:93} INFO - 	... 8 more
[2024-06-14T02:49:03.053+0530] {subprocess.py:93} INFO - 24/06/14 02:49:02 WARN Executor: Issue communicating with driver in heartbeater
[2024-06-14T02:49:03.054+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:49:03.054+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:49:03.054+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:49:03.054+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:49:03.055+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2024-06-14T02:49:03.055+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2024-06-14T02:49:03.055+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2024-06-14T02:49:03.056+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2024-06-14T02:49:03.056+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2024-06-14T02:49:03.056+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2024-06-14T02:49:03.057+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:49:03.057+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2024-06-14T02:49:03.057+0530] {subprocess.py:93} INFO - 	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2024-06-14T02:49:03.058+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2024-06-14T02:49:03.058+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2024-06-14T02:49:03.059+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2024-06-14T02:49:03.059+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:49:03.059+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:49:03.060+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:49:03.060+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:49:03.060+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:49:03.061+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:49:03.063+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:49:03.066+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2024-06-14T02:49:03.066+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2024-06-14T02:49:03.067+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2024-06-14T02:49:03.072+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2024-06-14T02:49:03.072+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2024-06-14T02:49:03.073+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2024-06-14T02:49:03.074+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2024-06-14T02:49:03.075+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2024-06-14T02:49:03.075+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:49:03.076+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:49:03.080+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:49:03.081+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:49:03.082+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:49:03.083+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:49:03.083+0530] {subprocess.py:93} INFO - 	... 3 more
[2024-06-14T02:49:03.084+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.56.255:38347
[2024-06-14T02:49:03.084+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2024-06-14T02:49:03.085+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2024-06-14T02:49:03.085+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2024-06-14T02:49:03.085+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2024-06-14T02:49:03.088+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:03.088+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:03.088+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:03.089+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:03.089+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:03.089+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:03.089+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:03.089+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:03.090+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:03.090+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:03.090+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:49:03.090+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:03.091+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:03.091+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:03.092+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:03.092+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:03.092+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:03.093+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:03.097+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:03.100+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:03.100+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:03.101+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:49:03.102+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:03.103+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2024-06-14T02:49:03.103+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2024-06-14T02:49:03.104+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:49:03.104+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2024-06-14T02:49:03.105+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2024-06-14T02:49:03.106+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2024-06-14T02:49:03.106+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2024-06-14T02:49:03.108+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2024-06-14T02:49:03.109+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2024-06-14T02:49:03.109+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:03.110+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:03.111+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:03.111+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:03.111+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2024-06-14T02:49:03.112+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2024-06-14T02:49:03.112+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2024-06-14T02:49:03.112+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2024-06-14T02:49:03.112+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2024-06-14T02:49:03.113+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2024-06-14T02:49:03.113+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:03.113+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:03.114+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:03.114+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:03.115+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:03.115+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:03.115+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:03.122+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:03.122+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:03.122+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:03.123+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success(Promise.scala:86)
[2024-06-14T02:49:03.123+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success$(Promise.scala:86)
[2024-06-14T02:49:03.124+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2024-06-14T02:49:03.124+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2024-06-14T02:49:03.124+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2024-06-14T02:49:03.125+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2024-06-14T02:49:03.125+0530] {subprocess.py:93} INFO - 	... 8 more
[2024-06-14T02:49:03.125+0530] {subprocess.py:93} INFO - 24/06/14 02:49:02 WARN Executor: Issue communicating with driver in heartbeater
[2024-06-14T02:49:03.126+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:49:03.126+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:49:03.127+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:49:03.127+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:49:03.127+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2024-06-14T02:49:03.128+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2024-06-14T02:49:03.128+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2024-06-14T02:49:03.129+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2024-06-14T02:49:03.129+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2024-06-14T02:49:03.129+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2024-06-14T02:49:03.129+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:49:03.130+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2024-06-14T02:49:03.130+0530] {subprocess.py:93} INFO - 	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2024-06-14T02:49:03.130+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2024-06-14T02:49:03.130+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2024-06-14T02:49:03.131+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2024-06-14T02:49:03.131+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:49:03.134+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:49:03.135+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:49:03.136+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:49:03.137+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:49:03.137+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:49:03.138+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:49:03.138+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2024-06-14T02:49:03.138+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2024-06-14T02:49:03.138+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2024-06-14T02:49:03.139+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2024-06-14T02:49:03.140+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2024-06-14T02:49:03.143+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2024-06-14T02:49:03.143+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2024-06-14T02:49:03.143+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2024-06-14T02:49:03.144+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:49:03.144+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:49:03.145+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:49:03.145+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:49:03.145+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:49:03.145+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:49:03.145+0530] {subprocess.py:93} INFO - 	... 3 more
[2024-06-14T02:49:03.146+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.56.255:38347
[2024-06-14T02:49:03.146+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2024-06-14T02:49:03.146+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2024-06-14T02:49:03.146+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2024-06-14T02:49:03.147+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2024-06-14T02:49:03.147+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:03.147+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:03.147+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:03.147+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:03.148+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:03.148+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:03.148+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:03.150+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:03.151+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:03.152+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:03.152+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:49:03.152+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:03.153+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:03.156+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:03.156+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:03.160+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:03.160+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:03.160+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:03.161+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:03.161+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:03.161+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:03.161+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:49:03.162+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:03.162+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2024-06-14T02:49:03.162+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2024-06-14T02:49:03.163+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:49:03.163+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2024-06-14T02:49:03.163+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2024-06-14T02:49:03.163+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2024-06-14T02:49:03.164+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2024-06-14T02:49:03.164+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2024-06-14T02:49:03.164+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2024-06-14T02:49:03.164+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:03.165+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:03.165+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:03.165+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:03.165+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2024-06-14T02:49:03.166+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2024-06-14T02:49:03.166+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2024-06-14T02:49:03.167+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2024-06-14T02:49:03.167+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2024-06-14T02:49:03.167+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2024-06-14T02:49:03.167+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:03.167+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:03.168+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:03.168+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:03.168+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:03.168+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:03.168+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:03.169+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:03.170+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:03.171+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:03.171+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success(Promise.scala:86)
[2024-06-14T02:49:03.171+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success$(Promise.scala:86)
[2024-06-14T02:49:03.172+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2024-06-14T02:49:03.172+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2024-06-14T02:49:03.172+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2024-06-14T02:49:03.172+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2024-06-14T02:49:03.172+0530] {subprocess.py:93} INFO - 	... 8 more
[2024-06-14T02:49:03.172+0530] {subprocess.py:93} INFO - 24/06/14 02:49:02 ERROR Inbox: Ignoring error
[2024-06-14T02:49:03.173+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:49:03.173+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:49:03.173+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:49:03.174+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:49:03.174+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2024-06-14T02:49:03.174+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2024-06-14T02:49:03.175+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2024-06-14T02:49:03.175+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2024-06-14T02:49:03.176+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2024-06-14T02:49:03.176+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2024-06-14T02:49:03.177+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2024-06-14T02:49:03.177+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2024-06-14T02:49:03.177+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:49:03.181+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:49:03.181+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:49:03.181+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:49:03.182+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:49:03.182+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:49:03.182+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:49:03.182+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:49:03.182+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:49:03.182+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.56.255:38347
[2024-06-14T02:49:03.182+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2024-06-14T02:49:03.182+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2024-06-14T02:49:03.182+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2024-06-14T02:49:03.183+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2024-06-14T02:49:03.183+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:03.183+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:03.183+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:03.183+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:03.183+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:03.183+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:03.183+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:03.183+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:03.183+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:03.183+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:03.184+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:49:03.184+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:03.184+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:03.184+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:03.184+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:03.185+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:03.185+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:03.185+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:03.185+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:03.185+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:03.185+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:03.185+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:49:03.185+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:03.185+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2024-06-14T02:49:03.186+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2024-06-14T02:49:03.186+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:49:03.186+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2024-06-14T02:49:03.186+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2024-06-14T02:49:03.186+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2024-06-14T02:49:03.186+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2024-06-14T02:49:03.186+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2024-06-14T02:49:03.186+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2024-06-14T02:49:03.186+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:03.186+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:03.186+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:03.187+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:03.187+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2024-06-14T02:49:03.187+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2024-06-14T02:49:03.187+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2024-06-14T02:49:03.187+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2024-06-14T02:49:03.187+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2024-06-14T02:49:03.187+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2024-06-14T02:49:03.187+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:03.187+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:03.188+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:03.188+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:03.188+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:03.188+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:03.188+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:03.188+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:03.188+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:03.188+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:03.188+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success(Promise.scala:86)
[2024-06-14T02:49:03.189+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success$(Promise.scala:86)
[2024-06-14T02:49:03.189+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2024-06-14T02:49:03.189+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2024-06-14T02:49:03.189+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2024-06-14T02:49:03.189+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2024-06-14T02:49:03.189+0530] {subprocess.py:93} INFO - 	... 8 more
[2024-06-14T02:49:03.189+0530] {subprocess.py:93} INFO - 24/06/14 02:49:02 ERROR Inbox: Ignoring error
[2024-06-14T02:49:03.189+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:49:03.189+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:49:03.189+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:49:03.190+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:49:03.190+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2024-06-14T02:49:03.190+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2024-06-14T02:49:03.192+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2024-06-14T02:49:03.192+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2024-06-14T02:49:03.193+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2024-06-14T02:49:03.194+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2024-06-14T02:49:03.194+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2024-06-14T02:49:03.194+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2024-06-14T02:49:03.194+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:49:03.194+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:49:03.195+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:49:03.195+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:49:03.195+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:49:03.195+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:49:03.195+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:49:03.195+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:49:03.195+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:49:03.196+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.56.255:38347
[2024-06-14T02:49:03.196+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2024-06-14T02:49:03.196+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2024-06-14T02:49:03.196+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2024-06-14T02:49:03.196+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2024-06-14T02:49:03.196+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:03.196+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:03.196+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:03.196+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:03.196+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:03.197+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:03.197+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:03.197+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:03.197+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:03.197+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:03.197+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:49:03.197+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:03.197+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:03.197+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:03.197+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:03.197+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:03.198+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:03.198+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:03.198+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:03.198+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:03.198+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:03.198+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:49:03.198+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:03.198+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2024-06-14T02:49:03.198+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2024-06-14T02:49:03.198+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:49:03.198+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2024-06-14T02:49:03.199+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2024-06-14T02:49:03.199+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2024-06-14T02:49:03.199+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2024-06-14T02:49:03.199+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2024-06-14T02:49:03.199+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2024-06-14T02:49:03.199+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:03.199+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:03.199+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:03.199+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:03.199+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2024-06-14T02:49:03.199+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2024-06-14T02:49:03.200+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2024-06-14T02:49:03.200+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2024-06-14T02:49:03.200+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2024-06-14T02:49:03.200+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2024-06-14T02:49:03.200+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:03.200+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:03.200+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:03.200+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:03.200+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:03.200+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:03.201+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:03.201+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:03.201+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:03.201+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:03.201+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success(Promise.scala:86)
[2024-06-14T02:49:03.201+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success$(Promise.scala:86)
[2024-06-14T02:49:03.201+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2024-06-14T02:49:03.201+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2024-06-14T02:49:03.201+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2024-06-14T02:49:03.202+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2024-06-14T02:49:03.202+0530] {subprocess.py:93} INFO - 	... 8 more
[2024-06-14T02:49:03.202+0530] {subprocess.py:93} INFO - 24/06/14 02:49:02 WARN Executor: Issue communicating with driver in heartbeater
[2024-06-14T02:49:03.202+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:49:03.202+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:49:03.202+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:49:03.202+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:49:03.202+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2024-06-14T02:49:03.202+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2024-06-14T02:49:03.202+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2024-06-14T02:49:03.202+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2024-06-14T02:49:03.203+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2024-06-14T02:49:03.203+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2024-06-14T02:49:03.203+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:49:03.203+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2024-06-14T02:49:03.203+0530] {subprocess.py:93} INFO - 	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2024-06-14T02:49:03.203+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2024-06-14T02:49:03.203+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2024-06-14T02:49:03.203+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2024-06-14T02:49:03.203+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:49:03.203+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:49:03.203+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:49:03.203+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:49:03.204+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:49:03.204+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:49:03.204+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:49:03.204+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2024-06-14T02:49:03.204+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2024-06-14T02:49:03.204+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2024-06-14T02:49:03.205+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2024-06-14T02:49:03.205+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2024-06-14T02:49:03.205+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2024-06-14T02:49:03.205+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2024-06-14T02:49:03.205+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2024-06-14T02:49:03.205+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:49:03.205+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:49:03.205+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:49:03.205+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:49:03.206+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:49:03.206+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:49:03.206+0530] {subprocess.py:93} INFO - 	... 3 more
[2024-06-14T02:49:03.206+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.56.255:38347
[2024-06-14T02:49:03.206+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2024-06-14T02:49:03.206+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2024-06-14T02:49:03.206+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2024-06-14T02:49:03.206+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2024-06-14T02:49:03.207+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:03.209+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:03.209+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:03.210+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:03.210+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:03.210+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:03.210+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:03.211+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:03.211+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:03.211+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:03.211+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:49:03.212+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:03.212+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:03.212+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:03.212+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:03.212+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:03.212+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:03.212+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:03.212+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:03.212+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:03.213+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:03.213+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:49:03.213+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:03.213+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2024-06-14T02:49:03.213+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2024-06-14T02:49:03.213+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:49:03.213+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2024-06-14T02:49:03.213+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2024-06-14T02:49:03.213+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2024-06-14T02:49:03.213+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2024-06-14T02:49:03.213+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2024-06-14T02:49:03.214+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2024-06-14T02:49:03.214+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:03.214+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:03.214+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:03.214+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:03.214+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2024-06-14T02:49:03.214+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2024-06-14T02:49:03.214+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2024-06-14T02:49:03.214+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2024-06-14T02:49:03.214+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2024-06-14T02:49:03.214+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2024-06-14T02:49:03.215+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:03.215+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:03.215+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:03.215+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:03.215+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:03.215+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:03.215+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:03.215+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:03.215+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:03.216+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:03.216+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success(Promise.scala:86)
[2024-06-14T02:49:03.216+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success$(Promise.scala:86)
[2024-06-14T02:49:03.216+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2024-06-14T02:49:03.216+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2024-06-14T02:49:03.216+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2024-06-14T02:49:03.216+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2024-06-14T02:49:03.216+0530] {subprocess.py:93} INFO - 	... 8 more
[2024-06-14T02:49:03.217+0530] {subprocess.py:93} INFO - 24/06/14 02:49:02 WARN Executor: Issue communicating with driver in heartbeater
[2024-06-14T02:49:03.217+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:49:03.217+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:49:03.217+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:49:03.217+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:49:03.217+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2024-06-14T02:49:03.217+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2024-06-14T02:49:03.217+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2024-06-14T02:49:03.217+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2024-06-14T02:49:03.217+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2024-06-14T02:49:03.217+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2024-06-14T02:49:03.218+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:49:03.218+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2024-06-14T02:49:03.218+0530] {subprocess.py:93} INFO - 	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2024-06-14T02:49:03.218+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2024-06-14T02:49:03.218+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2024-06-14T02:49:03.218+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2024-06-14T02:49:03.218+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:49:03.218+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:49:03.218+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:49:03.218+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:49:03.218+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:49:03.219+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:49:03.219+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:49:03.219+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2024-06-14T02:49:03.219+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2024-06-14T02:49:03.219+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2024-06-14T02:49:03.219+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2024-06-14T02:49:03.219+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2024-06-14T02:49:03.219+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2024-06-14T02:49:03.219+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2024-06-14T02:49:03.219+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2024-06-14T02:49:03.219+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:49:03.219+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:49:03.220+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:49:03.220+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:49:03.220+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:49:03.220+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:49:03.220+0530] {subprocess.py:93} INFO - 	... 3 more
[2024-06-14T02:49:03.220+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.56.255:38347
[2024-06-14T02:49:03.220+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2024-06-14T02:49:03.220+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2024-06-14T02:49:03.220+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2024-06-14T02:49:03.221+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2024-06-14T02:49:03.221+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:03.221+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:03.221+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:03.221+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:03.221+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:03.221+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:03.221+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:03.222+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:03.222+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:03.222+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:03.222+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:49:03.222+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:03.222+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:03.222+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:03.222+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:03.223+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:03.223+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:03.223+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:03.223+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:03.223+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:03.223+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:03.223+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:49:03.223+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:03.223+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2024-06-14T02:49:03.224+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2024-06-14T02:49:03.224+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:49:03.225+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2024-06-14T02:49:03.225+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2024-06-14T02:49:03.225+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2024-06-14T02:49:03.225+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2024-06-14T02:49:03.225+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2024-06-14T02:49:03.225+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2024-06-14T02:49:03.225+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:03.225+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:03.226+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:03.226+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:03.226+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2024-06-14T02:49:03.226+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2024-06-14T02:49:03.226+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2024-06-14T02:49:03.226+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2024-06-14T02:49:03.226+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2024-06-14T02:49:03.226+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2024-06-14T02:49:03.226+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:03.226+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:03.227+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:03.227+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:03.227+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:03.227+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:03.227+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:03.227+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:03.227+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:03.227+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:03.227+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success(Promise.scala:86)
[2024-06-14T02:49:03.227+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success$(Promise.scala:86)
[2024-06-14T02:49:03.228+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2024-06-14T02:49:03.228+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2024-06-14T02:49:03.228+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2024-06-14T02:49:03.228+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2024-06-14T02:49:03.229+0530] {subprocess.py:93} INFO - 	... 8 more
[2024-06-14T02:49:03.229+0530] {subprocess.py:93} INFO - 24/06/14 02:49:02 ERROR Inbox: Ignoring error
[2024-06-14T02:49:03.229+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:49:03.229+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:49:03.229+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:49:03.229+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:49:03.229+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2024-06-14T02:49:03.229+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2024-06-14T02:49:03.229+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2024-06-14T02:49:03.230+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2024-06-14T02:49:03.230+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2024-06-14T02:49:03.230+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2024-06-14T02:49:03.230+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2024-06-14T02:49:03.230+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2024-06-14T02:49:03.230+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:49:03.230+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:49:03.230+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:49:03.230+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:49:03.230+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:49:03.230+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:49:03.231+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:49:03.231+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:49:03.231+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:49:03.231+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.56.255:38347
[2024-06-14T02:49:03.231+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2024-06-14T02:49:03.231+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2024-06-14T02:49:03.232+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2024-06-14T02:49:03.237+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2024-06-14T02:49:03.237+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:03.238+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:03.238+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:03.239+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:03.239+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:03.240+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:03.241+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:03.241+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:03.244+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:03.245+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:03.245+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:49:03.245+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:03.246+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:03.246+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:03.246+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:03.247+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:03.247+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:03.248+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:03.248+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:03.248+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:03.249+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:03.249+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:49:03.252+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:03.252+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2024-06-14T02:49:03.256+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2024-06-14T02:49:03.258+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:49:03.260+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2024-06-14T02:49:03.261+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2024-06-14T02:49:03.262+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2024-06-14T02:49:03.262+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2024-06-14T02:49:03.262+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2024-06-14T02:49:03.263+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2024-06-14T02:49:03.263+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:03.264+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:03.265+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:03.266+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:03.266+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2024-06-14T02:49:03.266+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2024-06-14T02:49:03.267+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2024-06-14T02:49:03.267+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2024-06-14T02:49:03.268+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2024-06-14T02:49:03.269+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2024-06-14T02:49:03.270+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:03.270+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:03.270+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:03.277+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:03.277+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:03.278+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:03.278+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:03.278+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:03.279+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:03.279+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:03.280+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success(Promise.scala:86)
[2024-06-14T02:49:03.280+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success$(Promise.scala:86)
[2024-06-14T02:49:03.280+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2024-06-14T02:49:03.281+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2024-06-14T02:49:03.281+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2024-06-14T02:49:03.282+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2024-06-14T02:49:03.283+0530] {subprocess.py:93} INFO - 	... 8 more
[2024-06-14T02:49:03.283+0530] {subprocess.py:93} INFO - 24/06/14 02:49:03 ERROR Inbox: Ignoring error
[2024-06-14T02:49:03.283+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:49:03.284+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:49:03.284+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:49:03.286+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:49:03.287+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2024-06-14T02:49:03.296+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2024-06-14T02:49:03.296+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2024-06-14T02:49:03.296+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2024-06-14T02:49:03.297+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2024-06-14T02:49:03.297+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2024-06-14T02:49:03.297+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2024-06-14T02:49:03.298+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2024-06-14T02:49:03.298+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:49:03.299+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:49:03.300+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:49:03.300+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:49:03.300+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:49:03.301+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:49:03.301+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:49:03.301+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:49:03.302+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:49:03.302+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.56.255:38347
[2024-06-14T02:49:03.302+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2024-06-14T02:49:03.302+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2024-06-14T02:49:03.303+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2024-06-14T02:49:03.303+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2024-06-14T02:49:03.303+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:03.305+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:03.312+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:03.313+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:03.313+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)
[2024-06-14T02:49:03.313+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)
[2024-06-14T02:49:03.314+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.transformWith(Promise.scala:40)
[2024-06-14T02:49:03.315+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)
[2024-06-14T02:49:03.315+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)
[2024-06-14T02:49:03.315+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.flatMap(Future.scala:306)
[2024-06-14T02:49:03.315+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.flatMap$(Future.scala:306)
[2024-06-14T02:49:03.315+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)
[2024-06-14T02:49:03.316+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)
[2024-06-14T02:49:03.316+0530] {subprocess.py:93} INFO - 	... 17 more
[2024-06-14T02:49:03.316+0530] {subprocess.py:93} INFO - 24/06/14 02:49:03 WARN Executor: Issue communicating with driver in heartbeater
[2024-06-14T02:49:03.316+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:49:03.317+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:49:03.318+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:49:03.318+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:49:03.318+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2024-06-14T02:49:03.319+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2024-06-14T02:49:03.319+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2024-06-14T02:49:03.319+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2024-06-14T02:49:03.320+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2024-06-14T02:49:03.320+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2024-06-14T02:49:03.333+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:49:03.334+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2024-06-14T02:49:03.335+0530] {subprocess.py:93} INFO - 	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2024-06-14T02:49:03.336+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2024-06-14T02:49:03.336+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2024-06-14T02:49:03.337+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2024-06-14T02:49:03.337+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:49:03.337+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:49:03.338+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:49:03.338+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:49:03.338+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:49:03.339+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:49:03.339+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:49:03.339+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2024-06-14T02:49:03.339+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2024-06-14T02:49:03.340+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2024-06-14T02:49:03.340+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2024-06-14T02:49:03.340+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2024-06-14T02:49:03.341+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2024-06-14T02:49:03.342+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2024-06-14T02:49:03.342+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2024-06-14T02:49:03.352+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:49:03.352+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:49:03.353+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:49:03.353+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:49:03.354+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:49:03.355+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:49:03.355+0530] {subprocess.py:93} INFO - 	... 3 more
[2024-06-14T02:49:03.355+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.56.255:38347
[2024-06-14T02:49:03.355+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2024-06-14T02:49:03.356+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2024-06-14T02:49:03.356+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2024-06-14T02:49:03.356+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2024-06-14T02:49:03.357+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:03.357+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:03.359+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:03.359+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:03.360+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)
[2024-06-14T02:49:03.360+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)
[2024-06-14T02:49:03.360+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.transformWith(Promise.scala:40)
[2024-06-14T02:49:03.361+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)
[2024-06-14T02:49:03.361+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)
[2024-06-14T02:49:03.361+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.flatMap(Future.scala:306)
[2024-06-14T02:49:03.362+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.flatMap$(Future.scala:306)
[2024-06-14T02:49:03.362+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)
[2024-06-14T02:49:03.362+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)
[2024-06-14T02:49:03.363+0530] {subprocess.py:93} INFO - 	... 17 more
[2024-06-14T02:49:03.363+0530] {subprocess.py:93} INFO - 24/06/14 02:49:03 ERROR Inbox: Ignoring error
[2024-06-14T02:49:03.372+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:49:03.372+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:49:03.372+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:49:03.379+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:49:03.380+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2024-06-14T02:49:03.380+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2024-06-14T02:49:03.381+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2024-06-14T02:49:03.381+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2024-06-14T02:49:03.382+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2024-06-14T02:49:03.393+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2024-06-14T02:49:03.393+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2024-06-14T02:49:03.394+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2024-06-14T02:49:03.399+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:49:03.400+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:49:03.401+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:49:03.401+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:49:03.401+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:49:03.402+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:49:03.402+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:49:03.403+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:49:03.403+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:49:03.404+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.56.255:38347
[2024-06-14T02:49:03.404+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2024-06-14T02:49:03.404+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2024-06-14T02:49:03.405+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2024-06-14T02:49:03.405+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2024-06-14T02:49:03.405+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:03.405+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:03.406+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:03.406+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:03.406+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)
[2024-06-14T02:49:03.406+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)
[2024-06-14T02:49:03.407+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.transformWith(Promise.scala:40)
[2024-06-14T02:49:03.407+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)
[2024-06-14T02:49:03.407+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)
[2024-06-14T02:49:03.407+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.flatMap(Future.scala:306)
[2024-06-14T02:49:03.409+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.flatMap$(Future.scala:306)
[2024-06-14T02:49:03.409+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)
[2024-06-14T02:49:03.409+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)
[2024-06-14T02:49:03.410+0530] {subprocess.py:93} INFO - 	... 17 more
[2024-06-14T02:49:03.410+0530] {subprocess.py:93} INFO - 24/06/14 02:49:03 WARN Executor: Issue communicating with driver in heartbeater
[2024-06-14T02:49:03.410+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:49:03.411+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:49:03.411+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:49:03.411+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:49:03.412+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2024-06-14T02:49:03.412+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2024-06-14T02:49:03.417+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2024-06-14T02:49:03.417+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2024-06-14T02:49:03.418+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2024-06-14T02:49:03.419+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2024-06-14T02:49:03.419+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:49:03.419+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2024-06-14T02:49:03.420+0530] {subprocess.py:93} INFO - 	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2024-06-14T02:49:03.420+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2024-06-14T02:49:03.420+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2024-06-14T02:49:03.420+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2024-06-14T02:49:03.420+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:49:03.421+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:49:03.421+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:49:03.421+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:49:03.421+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:49:03.421+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:49:03.422+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:49:03.422+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2024-06-14T02:49:03.422+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2024-06-14T02:49:03.422+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2024-06-14T02:49:03.422+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2024-06-14T02:49:03.422+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2024-06-14T02:49:03.423+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2024-06-14T02:49:03.423+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2024-06-14T02:49:03.423+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2024-06-14T02:49:03.423+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:49:03.423+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:49:03.428+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:49:03.429+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:49:03.432+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:49:03.433+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:49:03.434+0530] {subprocess.py:93} INFO - 	... 3 more
[2024-06-14T02:49:03.434+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.56.255:38347
[2024-06-14T02:49:03.435+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2024-06-14T02:49:03.436+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2024-06-14T02:49:03.436+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2024-06-14T02:49:03.437+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2024-06-14T02:49:03.437+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:03.437+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:03.438+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:03.438+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:03.438+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)
[2024-06-14T02:49:03.439+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)
[2024-06-14T02:49:03.439+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.transformWith(Promise.scala:40)
[2024-06-14T02:49:03.439+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)
[2024-06-14T02:49:03.439+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)
[2024-06-14T02:49:03.440+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.flatMap(Future.scala:306)
[2024-06-14T02:49:03.440+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.flatMap$(Future.scala:306)
[2024-06-14T02:49:03.440+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)
[2024-06-14T02:49:03.441+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)
[2024-06-14T02:49:03.447+0530] {subprocess.py:93} INFO - 	... 17 more
[2024-06-14T02:49:03.450+0530] {subprocess.py:93} INFO - 24/06/14 02:49:03 ERROR Inbox: Ignoring error
[2024-06-14T02:49:03.451+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:49:03.451+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:49:03.452+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:49:03.452+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:49:03.453+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2024-06-14T02:49:03.453+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2024-06-14T02:49:03.454+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2024-06-14T02:49:03.454+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2024-06-14T02:49:03.454+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2024-06-14T02:49:03.454+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2024-06-14T02:49:03.454+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2024-06-14T02:49:03.455+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2024-06-14T02:49:03.455+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:49:03.455+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:49:03.455+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:49:03.456+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:49:03.456+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:49:03.456+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:49:03.457+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:49:03.457+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:49:03.457+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:49:03.458+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.56.255:38347
[2024-06-14T02:49:03.459+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2024-06-14T02:49:03.459+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2024-06-14T02:49:03.460+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2024-06-14T02:49:03.460+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2024-06-14T02:49:03.460+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:03.461+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:03.462+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:03.463+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:03.463+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:03.463+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:03.464+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:03.465+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:03.466+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:03.466+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:03.466+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:49:03.466+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:03.466+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:03.467+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:03.467+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:03.467+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:03.467+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:03.467+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:03.468+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:03.468+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:03.468+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:03.469+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:49:03.469+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:03.470+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2024-06-14T02:49:03.470+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2024-06-14T02:49:03.471+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:49:03.471+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2024-06-14T02:49:03.472+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2024-06-14T02:49:03.472+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2024-06-14T02:49:03.472+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2024-06-14T02:49:03.473+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2024-06-14T02:49:03.473+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2024-06-14T02:49:03.473+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:03.473+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:03.474+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:03.474+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:03.474+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2024-06-14T02:49:03.475+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2024-06-14T02:49:03.475+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2024-06-14T02:49:03.475+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2024-06-14T02:49:03.476+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2024-06-14T02:49:03.476+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2024-06-14T02:49:03.476+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:03.477+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:03.477+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:03.480+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:03.481+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:03.491+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:03.492+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:03.492+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:03.494+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:03.494+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:03.495+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success(Promise.scala:86)
[2024-06-14T02:49:03.495+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success$(Promise.scala:86)
[2024-06-14T02:49:03.495+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2024-06-14T02:49:03.498+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2024-06-14T02:49:03.499+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2024-06-14T02:49:03.499+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2024-06-14T02:49:03.500+0530] {subprocess.py:93} INFO - 	... 8 more
[2024-06-14T02:49:03.500+0530] {subprocess.py:93} INFO - 24/06/14 02:49:03 WARN Executor: Issue communicating with driver in heartbeater
[2024-06-14T02:49:03.500+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:49:03.501+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:49:03.501+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:49:03.501+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:49:03.501+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2024-06-14T02:49:03.502+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2024-06-14T02:49:03.502+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2024-06-14T02:49:03.502+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2024-06-14T02:49:03.502+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2024-06-14T02:49:03.502+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2024-06-14T02:49:03.502+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:49:03.502+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2024-06-14T02:49:03.502+0530] {subprocess.py:93} INFO - 	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2024-06-14T02:49:03.503+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2024-06-14T02:49:03.503+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2024-06-14T02:49:03.503+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2024-06-14T02:49:03.503+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:49:03.503+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:49:03.503+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:49:03.504+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:49:03.504+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:49:03.504+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:49:03.505+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:49:03.505+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2024-06-14T02:49:03.506+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2024-06-14T02:49:03.506+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2024-06-14T02:49:03.506+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2024-06-14T02:49:03.507+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2024-06-14T02:49:03.507+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2024-06-14T02:49:03.509+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2024-06-14T02:49:03.509+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2024-06-14T02:49:03.509+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:49:03.510+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:49:03.510+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:49:03.511+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:49:03.511+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:49:03.511+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:49:03.512+0530] {subprocess.py:93} INFO - 	... 3 more
[2024-06-14T02:49:03.512+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.56.255:38347
[2024-06-14T02:49:03.513+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2024-06-14T02:49:03.513+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2024-06-14T02:49:03.514+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2024-06-14T02:49:03.516+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2024-06-14T02:49:03.516+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:03.517+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:03.518+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:03.518+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:03.519+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:03.519+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:03.519+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:03.519+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:03.520+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:03.520+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:03.521+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:49:03.526+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:03.526+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:03.527+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:03.527+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:03.528+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:03.528+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:03.529+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:03.529+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:03.530+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:03.530+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:03.531+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:49:03.531+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:03.532+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2024-06-14T02:49:03.532+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2024-06-14T02:49:03.533+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:49:03.533+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2024-06-14T02:49:03.533+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2024-06-14T02:49:03.535+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2024-06-14T02:49:03.535+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2024-06-14T02:49:03.536+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2024-06-14T02:49:03.536+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2024-06-14T02:49:03.537+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:03.537+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:03.538+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:03.539+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:03.539+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2024-06-14T02:49:03.540+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2024-06-14T02:49:03.540+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2024-06-14T02:49:03.540+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2024-06-14T02:49:03.541+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2024-06-14T02:49:03.541+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2024-06-14T02:49:03.541+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:03.542+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:03.542+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:03.542+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:03.543+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:03.543+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:03.543+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:03.543+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:03.544+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:03.544+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:03.544+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success(Promise.scala:86)
[2024-06-14T02:49:03.544+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success$(Promise.scala:86)
[2024-06-14T02:49:03.545+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2024-06-14T02:49:03.545+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2024-06-14T02:49:03.545+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2024-06-14T02:49:03.545+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2024-06-14T02:49:03.546+0530] {subprocess.py:93} INFO - 	... 8 more
[2024-06-14T02:49:03.546+0530] {subprocess.py:93} INFO - 24/06/14 02:49:03 WARN Executor: Issue communicating with driver in heartbeater
[2024-06-14T02:49:03.546+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:49:03.547+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:49:03.547+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:49:03.548+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:49:03.549+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2024-06-14T02:49:03.549+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2024-06-14T02:49:03.550+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2024-06-14T02:49:03.551+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2024-06-14T02:49:03.559+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2024-06-14T02:49:03.559+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2024-06-14T02:49:03.559+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:49:03.560+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2024-06-14T02:49:03.560+0530] {subprocess.py:93} INFO - 	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2024-06-14T02:49:03.561+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2024-06-14T02:49:03.562+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2024-06-14T02:49:03.562+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2024-06-14T02:49:03.563+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:49:03.563+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:49:03.563+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:49:03.563+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:49:03.563+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:49:03.575+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:49:03.576+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:49:03.576+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2024-06-14T02:49:03.577+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2024-06-14T02:49:03.578+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2024-06-14T02:49:03.578+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2024-06-14T02:49:03.579+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2024-06-14T02:49:03.579+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2024-06-14T02:49:03.580+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2024-06-14T02:49:03.580+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2024-06-14T02:49:03.580+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:49:03.591+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:49:03.592+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:49:03.592+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:49:03.593+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:49:03.593+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:49:03.593+0530] {subprocess.py:93} INFO - 	... 3 more
[2024-06-14T02:49:03.593+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.56.255:38347
[2024-06-14T02:49:03.594+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2024-06-14T02:49:03.594+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2024-06-14T02:49:03.607+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2024-06-14T02:49:03.608+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2024-06-14T02:49:03.609+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:03.609+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:03.609+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:03.610+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:03.610+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:03.610+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:03.611+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:03.611+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:03.611+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:03.612+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:03.622+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:49:03.623+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:03.624+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:03.624+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:03.625+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:03.625+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:03.626+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:03.626+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:03.626+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:03.627+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:03.627+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:03.628+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:49:03.637+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:03.639+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2024-06-14T02:49:03.639+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2024-06-14T02:49:03.639+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:49:03.640+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2024-06-14T02:49:03.640+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2024-06-14T02:49:03.640+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2024-06-14T02:49:03.640+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2024-06-14T02:49:03.641+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2024-06-14T02:49:03.641+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2024-06-14T02:49:03.642+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:03.642+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:03.642+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:03.643+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:03.643+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2024-06-14T02:49:03.644+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2024-06-14T02:49:03.644+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2024-06-14T02:49:03.644+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2024-06-14T02:49:03.644+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2024-06-14T02:49:03.645+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2024-06-14T02:49:03.645+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:03.645+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:03.646+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:03.646+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:03.646+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:03.646+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:03.648+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:03.660+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:03.661+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:03.661+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:03.662+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success(Promise.scala:86)
[2024-06-14T02:49:03.662+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success$(Promise.scala:86)
[2024-06-14T02:49:03.663+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2024-06-14T02:49:03.664+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2024-06-14T02:49:03.664+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2024-06-14T02:49:03.664+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2024-06-14T02:49:03.665+0530] {subprocess.py:93} INFO - 	... 8 more
[2024-06-14T02:49:03.665+0530] {subprocess.py:93} INFO - 24/06/14 02:49:03 ERROR Inbox: Ignoring error
[2024-06-14T02:49:03.665+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:49:03.666+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:49:03.666+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:49:03.666+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:49:03.667+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2024-06-14T02:49:03.667+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2024-06-14T02:49:03.667+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2024-06-14T02:49:03.668+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2024-06-14T02:49:03.668+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2024-06-14T02:49:03.668+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2024-06-14T02:49:03.669+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2024-06-14T02:49:03.669+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2024-06-14T02:49:03.680+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:49:03.681+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:49:03.681+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:49:03.681+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:49:03.682+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:49:03.682+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:49:03.682+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:49:03.683+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:49:03.683+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:49:03.683+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.56.255:38347
[2024-06-14T02:49:03.683+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2024-06-14T02:49:03.683+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2024-06-14T02:49:03.684+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2024-06-14T02:49:03.684+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2024-06-14T02:49:03.684+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:03.684+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:03.685+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:03.685+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:03.685+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:03.685+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:03.685+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:03.686+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:03.686+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:03.686+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:03.686+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:49:03.687+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:03.687+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:03.687+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:03.688+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:03.688+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:03.688+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:03.689+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:03.689+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:03.689+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:03.690+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:03.699+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:49:03.699+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:03.699+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2024-06-14T02:49:03.700+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2024-06-14T02:49:03.700+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:49:03.701+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2024-06-14T02:49:03.701+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2024-06-14T02:49:03.702+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2024-06-14T02:49:03.702+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2024-06-14T02:49:03.702+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2024-06-14T02:49:03.702+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2024-06-14T02:49:03.702+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:03.703+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:03.703+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:03.703+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:03.704+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2024-06-14T02:49:03.704+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2024-06-14T02:49:03.704+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2024-06-14T02:49:03.705+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2024-06-14T02:49:03.705+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2024-06-14T02:49:03.706+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2024-06-14T02:49:03.706+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:03.706+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:03.707+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:03.709+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:03.710+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:03.710+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:03.717+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:03.718+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:03.718+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:03.718+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:03.719+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success(Promise.scala:86)
[2024-06-14T02:49:03.719+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success$(Promise.scala:86)
[2024-06-14T02:49:03.720+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2024-06-14T02:49:03.720+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2024-06-14T02:49:03.720+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2024-06-14T02:49:03.721+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2024-06-14T02:49:03.722+0530] {subprocess.py:93} INFO - 	... 8 more
[2024-06-14T02:49:03.722+0530] {subprocess.py:93} INFO - 24/06/14 02:49:03 ERROR Inbox: Ignoring error
[2024-06-14T02:49:03.722+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:49:03.722+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:49:03.723+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:49:03.723+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:49:03.723+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2024-06-14T02:49:03.724+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2024-06-14T02:49:03.724+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2024-06-14T02:49:03.725+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2024-06-14T02:49:03.726+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2024-06-14T02:49:03.726+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2024-06-14T02:49:03.730+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2024-06-14T02:49:03.731+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2024-06-14T02:49:03.731+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:49:03.732+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:49:03.732+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:49:03.732+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:49:03.732+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:49:03.733+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:49:03.733+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:49:03.733+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:49:03.733+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:49:03.733+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.56.255:38347
[2024-06-14T02:49:03.733+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2024-06-14T02:49:03.734+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2024-06-14T02:49:03.736+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2024-06-14T02:49:03.736+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2024-06-14T02:49:03.737+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:03.737+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:03.737+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:03.737+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:03.738+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:03.738+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:03.738+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:03.738+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:03.738+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:03.739+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:03.739+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:49:03.739+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:03.739+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:03.739+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:03.740+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:03.740+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:03.740+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:03.740+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:03.741+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:03.742+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:03.742+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:03.742+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:49:03.742+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:03.742+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2024-06-14T02:49:03.742+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2024-06-14T02:49:03.742+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:49:03.742+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2024-06-14T02:49:03.743+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2024-06-14T02:49:03.743+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2024-06-14T02:49:03.743+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2024-06-14T02:49:03.743+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2024-06-14T02:49:03.743+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2024-06-14T02:49:03.743+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:03.743+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:03.743+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:03.744+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:03.744+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2024-06-14T02:49:03.744+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2024-06-14T02:49:03.744+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2024-06-14T02:49:03.744+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2024-06-14T02:49:03.745+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2024-06-14T02:49:03.745+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2024-06-14T02:49:03.745+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:03.745+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:03.745+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:03.745+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:03.745+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:03.745+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:03.745+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:03.745+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:03.746+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:03.746+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:03.746+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success(Promise.scala:86)
[2024-06-14T02:49:03.746+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success$(Promise.scala:86)
[2024-06-14T02:49:03.746+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2024-06-14T02:49:03.746+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2024-06-14T02:49:03.746+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2024-06-14T02:49:03.746+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2024-06-14T02:49:03.746+0530] {subprocess.py:93} INFO - 	... 8 more
[2024-06-14T02:49:03.746+0530] {subprocess.py:93} INFO - 24/06/14 02:49:03 WARN Executor: Issue communicating with driver in heartbeater
[2024-06-14T02:49:03.746+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:49:03.747+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:49:03.747+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:49:03.747+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:49:03.747+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2024-06-14T02:49:03.747+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2024-06-14T02:49:03.747+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2024-06-14T02:49:03.747+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2024-06-14T02:49:03.747+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2024-06-14T02:49:03.747+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2024-06-14T02:49:03.747+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:49:03.748+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2024-06-14T02:49:03.748+0530] {subprocess.py:93} INFO - 	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2024-06-14T02:49:03.748+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2024-06-14T02:49:03.748+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2024-06-14T02:49:03.748+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2024-06-14T02:49:03.748+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:49:03.748+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:49:03.748+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:49:03.748+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:49:03.748+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:49:03.748+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:49:03.749+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:49:03.749+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2024-06-14T02:49:03.749+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2024-06-14T02:49:03.749+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2024-06-14T02:49:03.749+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2024-06-14T02:49:03.749+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2024-06-14T02:49:03.749+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2024-06-14T02:49:03.749+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2024-06-14T02:49:03.749+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2024-06-14T02:49:03.749+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:49:03.750+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:49:03.750+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:49:03.750+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:49:03.750+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:49:03.751+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:49:03.751+0530] {subprocess.py:93} INFO - 	... 3 more
[2024-06-14T02:49:03.751+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.56.255:38347
[2024-06-14T02:49:03.751+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2024-06-14T02:49:03.751+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2024-06-14T02:49:03.751+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2024-06-14T02:49:03.752+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2024-06-14T02:49:03.752+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:03.752+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:03.752+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:03.752+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:03.752+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:03.752+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:03.752+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:03.752+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:03.752+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:03.753+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:03.753+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:49:03.753+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:03.753+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:03.753+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:03.753+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:03.753+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:03.753+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:03.753+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:03.753+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:03.754+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:03.754+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:03.754+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:49:03.754+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:03.754+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2024-06-14T02:49:03.754+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2024-06-14T02:49:03.754+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:49:03.754+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2024-06-14T02:49:03.754+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2024-06-14T02:49:03.754+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2024-06-14T02:49:03.755+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2024-06-14T02:49:03.755+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2024-06-14T02:49:03.755+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2024-06-14T02:49:03.755+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:03.755+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:03.755+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:03.755+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:03.755+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2024-06-14T02:49:03.755+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2024-06-14T02:49:03.755+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2024-06-14T02:49:03.756+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2024-06-14T02:49:03.756+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2024-06-14T02:49:03.756+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2024-06-14T02:49:03.756+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:03.756+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:03.756+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:03.756+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:03.756+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:03.756+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:03.757+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:03.757+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:03.757+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:03.757+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:03.758+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success(Promise.scala:86)
[2024-06-14T02:49:03.758+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success$(Promise.scala:86)
[2024-06-14T02:49:03.758+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2024-06-14T02:49:03.758+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2024-06-14T02:49:03.759+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2024-06-14T02:49:03.759+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2024-06-14T02:49:03.759+0530] {subprocess.py:93} INFO - 	... 8 more
[2024-06-14T02:49:03.759+0530] {subprocess.py:93} INFO - 24/06/14 02:49:03 ERROR Inbox: Ignoring error
[2024-06-14T02:49:03.759+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:49:03.759+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:49:03.759+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:49:03.759+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:49:03.759+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2024-06-14T02:49:03.760+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2024-06-14T02:49:03.760+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2024-06-14T02:49:03.760+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2024-06-14T02:49:03.760+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2024-06-14T02:49:03.760+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2024-06-14T02:49:03.760+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2024-06-14T02:49:03.760+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2024-06-14T02:49:03.760+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:49:03.760+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:49:03.760+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:49:03.760+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:49:03.761+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:49:03.761+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:49:03.761+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:49:03.761+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:49:03.761+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:49:03.761+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.56.255:38347
[2024-06-14T02:49:03.761+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2024-06-14T02:49:03.761+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2024-06-14T02:49:03.761+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2024-06-14T02:49:03.761+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2024-06-14T02:49:03.762+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:03.762+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:03.762+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:03.762+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:03.762+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:03.762+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:03.762+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:03.762+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:03.762+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:03.762+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:03.763+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:49:03.763+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:03.763+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:03.763+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:03.763+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:03.763+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:03.763+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:03.763+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:03.763+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:03.763+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:03.763+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:03.763+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:49:03.764+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:03.764+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2024-06-14T02:49:03.764+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2024-06-14T02:49:03.764+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:49:03.764+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2024-06-14T02:49:03.764+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2024-06-14T02:49:03.764+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2024-06-14T02:49:03.764+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2024-06-14T02:49:03.764+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2024-06-14T02:49:03.765+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2024-06-14T02:49:03.765+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:03.765+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:03.766+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:03.766+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:03.766+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2024-06-14T02:49:03.766+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2024-06-14T02:49:03.766+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2024-06-14T02:49:03.766+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2024-06-14T02:49:03.766+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2024-06-14T02:49:03.766+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2024-06-14T02:49:03.767+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:03.767+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:03.767+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:03.767+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:03.767+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:03.767+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:03.767+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:03.767+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:03.767+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:03.767+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:03.768+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success(Promise.scala:86)
[2024-06-14T02:49:03.768+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success$(Promise.scala:86)
[2024-06-14T02:49:03.768+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2024-06-14T02:49:03.768+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2024-06-14T02:49:03.768+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2024-06-14T02:49:03.768+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2024-06-14T02:49:03.768+0530] {subprocess.py:93} INFO - 	... 8 more
[2024-06-14T02:49:03.768+0530] {subprocess.py:93} INFO - 24/06/14 02:49:03 WARN Executor: Issue communicating with driver in heartbeater
[2024-06-14T02:49:03.768+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:49:03.768+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:49:03.769+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:49:03.769+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:49:03.769+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2024-06-14T02:49:03.769+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2024-06-14T02:49:03.769+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2024-06-14T02:49:03.769+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2024-06-14T02:49:03.769+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2024-06-14T02:49:03.769+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2024-06-14T02:49:03.769+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:49:03.769+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2024-06-14T02:49:03.769+0530] {subprocess.py:93} INFO - 	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2024-06-14T02:49:03.770+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2024-06-14T02:49:03.770+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2024-06-14T02:49:03.770+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2024-06-14T02:49:03.770+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:49:03.770+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:49:03.770+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:49:03.770+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:49:03.770+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:49:03.770+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:49:03.770+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:49:03.770+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2024-06-14T02:49:03.770+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2024-06-14T02:49:03.771+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2024-06-14T02:49:03.771+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2024-06-14T02:49:03.771+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2024-06-14T02:49:03.771+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2024-06-14T02:49:03.771+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2024-06-14T02:49:03.771+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2024-06-14T02:49:03.771+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:49:03.771+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:49:03.771+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:49:03.772+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:49:03.772+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:49:03.772+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:49:03.772+0530] {subprocess.py:93} INFO - 	... 3 more
[2024-06-14T02:49:03.772+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.56.255:38347
[2024-06-14T02:49:03.772+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2024-06-14T02:49:03.772+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2024-06-14T02:49:03.772+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2024-06-14T02:49:03.772+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2024-06-14T02:49:03.772+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:03.772+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:03.772+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:03.773+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:03.773+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:03.773+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:03.773+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:03.773+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:03.773+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:03.774+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:03.775+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:49:03.775+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:03.775+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:03.775+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:03.776+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:03.776+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:03.776+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:03.776+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:03.776+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:03.776+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:03.776+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:03.777+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:49:03.777+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:03.777+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2024-06-14T02:49:03.777+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2024-06-14T02:49:03.777+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:49:03.777+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2024-06-14T02:49:03.777+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2024-06-14T02:49:03.777+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2024-06-14T02:49:03.778+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2024-06-14T02:49:03.778+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2024-06-14T02:49:03.778+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2024-06-14T02:49:03.778+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:03.779+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:03.779+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:03.779+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:03.780+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2024-06-14T02:49:03.780+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2024-06-14T02:49:03.781+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2024-06-14T02:49:03.783+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2024-06-14T02:49:03.783+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2024-06-14T02:49:03.783+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2024-06-14T02:49:03.784+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:03.784+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:03.784+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:03.784+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:03.784+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:03.784+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:03.784+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:03.784+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:03.785+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:03.785+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:03.785+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success(Promise.scala:86)
[2024-06-14T02:49:03.785+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success$(Promise.scala:86)
[2024-06-14T02:49:03.785+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2024-06-14T02:49:03.785+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2024-06-14T02:49:03.785+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2024-06-14T02:49:03.785+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2024-06-14T02:49:03.785+0530] {subprocess.py:93} INFO - 	... 8 more
[2024-06-14T02:49:03.785+0530] {subprocess.py:93} INFO - 24/06/14 02:49:03 WARN Executor: Issue communicating with driver in heartbeater
[2024-06-14T02:49:03.786+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:49:03.786+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:49:03.786+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:49:03.786+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:49:03.786+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2024-06-14T02:49:03.786+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2024-06-14T02:49:03.786+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2024-06-14T02:49:03.786+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2024-06-14T02:49:03.787+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2024-06-14T02:49:03.787+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2024-06-14T02:49:03.787+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:49:03.787+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2024-06-14T02:49:03.787+0530] {subprocess.py:93} INFO - 	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2024-06-14T02:49:03.788+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2024-06-14T02:49:03.788+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2024-06-14T02:49:03.788+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2024-06-14T02:49:03.788+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:49:03.789+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:49:03.789+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:49:03.789+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:49:03.793+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:49:03.793+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:49:03.794+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:49:03.794+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2024-06-14T02:49:03.794+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2024-06-14T02:49:03.795+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2024-06-14T02:49:03.795+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2024-06-14T02:49:03.795+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2024-06-14T02:49:03.795+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2024-06-14T02:49:03.797+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2024-06-14T02:49:03.798+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2024-06-14T02:49:03.799+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:49:03.799+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:49:03.799+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:49:03.800+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:49:03.800+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:49:03.800+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:49:03.800+0530] {subprocess.py:93} INFO - 	... 3 more
[2024-06-14T02:49:03.801+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.56.255:38347
[2024-06-14T02:49:03.801+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2024-06-14T02:49:03.802+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2024-06-14T02:49:03.803+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2024-06-14T02:49:03.803+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2024-06-14T02:49:03.804+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:03.804+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:03.804+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:03.804+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:03.805+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:03.805+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:03.805+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:03.806+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:03.806+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:03.806+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:03.806+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:49:03.806+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:03.806+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:03.806+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:03.809+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:03.809+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:03.810+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:03.810+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:03.811+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:03.811+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:03.812+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:03.812+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:49:03.812+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:03.813+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2024-06-14T02:49:03.813+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2024-06-14T02:49:03.813+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:49:03.813+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2024-06-14T02:49:03.814+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2024-06-14T02:49:03.814+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2024-06-14T02:49:03.814+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2024-06-14T02:49:03.814+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2024-06-14T02:49:03.814+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2024-06-14T02:49:03.815+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:03.815+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:03.815+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:03.815+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:03.815+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2024-06-14T02:49:03.816+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2024-06-14T02:49:03.816+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2024-06-14T02:49:03.816+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2024-06-14T02:49:03.816+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2024-06-14T02:49:03.817+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2024-06-14T02:49:03.817+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:03.817+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:03.817+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:03.817+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:03.818+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:03.818+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:03.818+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:03.818+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:03.818+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:03.819+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:03.819+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success(Promise.scala:86)
[2024-06-14T02:49:03.819+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success$(Promise.scala:86)
[2024-06-14T02:49:03.820+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2024-06-14T02:49:03.827+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2024-06-14T02:49:03.831+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2024-06-14T02:49:03.832+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2024-06-14T02:49:03.832+0530] {subprocess.py:93} INFO - 	... 8 more
[2024-06-14T02:49:03.832+0530] {subprocess.py:93} INFO - 24/06/14 02:49:03 ERROR Inbox: Ignoring error
[2024-06-14T02:49:03.832+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:49:03.832+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:49:03.833+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:49:03.833+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:49:03.833+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2024-06-14T02:49:03.833+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2024-06-14T02:49:03.833+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2024-06-14T02:49:03.834+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2024-06-14T02:49:03.834+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2024-06-14T02:49:03.834+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2024-06-14T02:49:03.834+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2024-06-14T02:49:03.834+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2024-06-14T02:49:03.835+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:49:03.835+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:49:03.835+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:49:03.835+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:49:03.835+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:49:03.836+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:49:03.836+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:49:03.836+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:49:03.836+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:49:03.836+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.56.255:38347
[2024-06-14T02:49:03.836+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2024-06-14T02:49:03.836+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2024-06-14T02:49:03.836+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2024-06-14T02:49:03.837+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2024-06-14T02:49:03.837+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:03.837+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:03.837+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:03.837+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:03.837+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:03.838+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:03.838+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:03.838+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:03.838+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:03.838+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:03.839+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:49:03.839+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:03.839+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:03.839+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:03.839+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:03.839+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:03.840+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:03.840+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:03.840+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:03.840+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:03.840+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:03.841+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:49:03.843+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:03.845+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2024-06-14T02:49:03.846+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2024-06-14T02:49:03.846+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:49:03.846+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2024-06-14T02:49:03.847+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2024-06-14T02:49:03.847+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2024-06-14T02:49:03.847+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2024-06-14T02:49:03.847+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2024-06-14T02:49:03.847+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2024-06-14T02:49:03.847+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:03.847+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:03.847+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:03.847+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:03.848+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2024-06-14T02:49:03.848+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2024-06-14T02:49:03.848+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2024-06-14T02:49:03.848+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2024-06-14T02:49:03.848+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2024-06-14T02:49:03.848+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2024-06-14T02:49:03.848+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:03.849+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:03.849+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:03.849+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:03.849+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:03.849+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:03.849+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:03.849+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:03.850+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:03.850+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:03.850+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success(Promise.scala:86)
[2024-06-14T02:49:03.850+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success$(Promise.scala:86)
[2024-06-14T02:49:03.850+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2024-06-14T02:49:03.850+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2024-06-14T02:49:03.851+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2024-06-14T02:49:03.851+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2024-06-14T02:49:03.851+0530] {subprocess.py:93} INFO - 	... 8 more
[2024-06-14T02:49:03.851+0530] {subprocess.py:93} INFO - 24/06/14 02:49:03 WARN Executor: Issue communicating with driver in heartbeater
[2024-06-14T02:49:03.852+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:49:03.852+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:49:03.852+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:49:03.853+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:49:03.853+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2024-06-14T02:49:03.853+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2024-06-14T02:49:03.854+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2024-06-14T02:49:03.854+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2024-06-14T02:49:03.854+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2024-06-14T02:49:03.855+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2024-06-14T02:49:03.855+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:49:03.855+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2024-06-14T02:49:03.856+0530] {subprocess.py:93} INFO - 	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2024-06-14T02:49:03.856+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2024-06-14T02:49:03.856+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2024-06-14T02:49:03.856+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2024-06-14T02:49:03.857+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:49:03.857+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:49:03.857+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:49:03.857+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:49:03.858+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:49:03.858+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:49:03.859+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:49:03.860+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2024-06-14T02:49:03.860+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2024-06-14T02:49:03.861+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2024-06-14T02:49:03.867+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2024-06-14T02:49:03.868+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2024-06-14T02:49:03.868+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2024-06-14T02:49:03.869+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2024-06-14T02:49:03.869+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2024-06-14T02:49:03.869+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:49:03.870+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:49:03.871+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:49:03.871+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:49:03.872+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:49:03.872+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:49:03.872+0530] {subprocess.py:93} INFO - 	... 3 more
[2024-06-14T02:49:03.873+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.56.255:38347
[2024-06-14T02:49:03.873+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2024-06-14T02:49:03.873+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2024-06-14T02:49:03.874+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2024-06-14T02:49:03.874+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2024-06-14T02:49:03.874+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:03.876+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:03.876+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:03.876+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:03.877+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:03.877+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:03.877+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:03.877+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:03.878+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:03.878+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:03.878+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:49:03.879+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:03.880+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:03.880+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:03.881+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:03.881+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:03.881+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:03.882+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:03.882+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:03.882+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:03.882+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:03.883+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:49:03.883+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:03.883+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2024-06-14T02:49:03.884+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2024-06-14T02:49:03.885+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:49:03.886+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2024-06-14T02:49:03.886+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2024-06-14T02:49:03.887+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2024-06-14T02:49:03.887+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2024-06-14T02:49:03.887+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2024-06-14T02:49:03.888+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2024-06-14T02:49:03.888+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:03.889+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:03.889+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:03.889+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:03.889+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2024-06-14T02:49:03.890+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2024-06-14T02:49:03.890+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2024-06-14T02:49:03.890+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2024-06-14T02:49:03.890+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2024-06-14T02:49:03.891+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2024-06-14T02:49:03.891+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:03.891+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:03.891+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:03.891+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:03.892+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:03.892+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:03.892+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:03.892+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:03.892+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:03.892+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:03.893+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success(Promise.scala:86)
[2024-06-14T02:49:03.893+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success$(Promise.scala:86)
[2024-06-14T02:49:03.893+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2024-06-14T02:49:03.893+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2024-06-14T02:49:03.893+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2024-06-14T02:49:03.894+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2024-06-14T02:49:03.894+0530] {subprocess.py:93} INFO - 	... 8 more
[2024-06-14T02:49:03.894+0530] {subprocess.py:93} INFO - 24/06/14 02:49:03 ERROR Inbox: Ignoring error
[2024-06-14T02:49:03.894+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:49:03.895+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:49:03.895+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:49:03.895+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:49:03.896+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2024-06-14T02:49:03.896+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2024-06-14T02:49:03.897+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2024-06-14T02:49:03.897+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2024-06-14T02:49:03.897+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2024-06-14T02:49:03.897+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2024-06-14T02:49:03.897+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2024-06-14T02:49:03.898+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2024-06-14T02:49:03.898+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:49:03.898+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:49:03.899+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:49:03.899+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:49:03.899+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:49:03.900+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:49:03.900+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:49:03.901+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:49:03.901+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:49:03.902+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.56.255:38347
[2024-06-14T02:49:03.902+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2024-06-14T02:49:03.902+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2024-06-14T02:49:03.903+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2024-06-14T02:49:03.903+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2024-06-14T02:49:03.904+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:03.905+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:03.906+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:03.906+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:03.907+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:03.908+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:03.908+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:03.908+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:03.909+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:03.909+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:03.910+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:49:03.910+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:03.911+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:03.912+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:03.912+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:03.912+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:03.913+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:03.913+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:03.914+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:03.914+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:03.914+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:03.915+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2024-06-14T02:49:03.917+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:03.917+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2024-06-14T02:49:03.918+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2024-06-14T02:49:03.919+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:49:03.919+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2024-06-14T02:49:03.920+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2024-06-14T02:49:03.923+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2024-06-14T02:49:03.925+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2024-06-14T02:49:03.926+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2024-06-14T02:49:03.926+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2024-06-14T02:49:03.927+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:03.927+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:03.927+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:03.928+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:03.928+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2024-06-14T02:49:03.929+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2024-06-14T02:49:03.929+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2024-06-14T02:49:03.929+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2024-06-14T02:49:03.929+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2024-06-14T02:49:03.930+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2024-06-14T02:49:03.935+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:03.935+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:03.936+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:03.936+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:03.936+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2024-06-14T02:49:03.937+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2024-06-14T02:49:03.939+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2024-06-14T02:49:03.941+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2024-06-14T02:49:03.941+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2024-06-14T02:49:03.942+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2024-06-14T02:49:03.942+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success(Promise.scala:86)
[2024-06-14T02:49:03.943+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success$(Promise.scala:86)
[2024-06-14T02:49:03.943+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2024-06-14T02:49:03.944+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2024-06-14T02:49:03.944+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2024-06-14T02:49:03.944+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2024-06-14T02:49:03.945+0530] {subprocess.py:93} INFO - 	... 8 more
[2024-06-14T02:49:03.945+0530] {subprocess.py:93} INFO - 24/06/14 02:49:03 ERROR Inbox: Ignoring error
[2024-06-14T02:49:03.945+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:49:03.946+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:49:03.946+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:49:03.946+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:49:03.947+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2024-06-14T02:49:03.947+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2024-06-14T02:49:03.947+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2024-06-14T02:49:03.948+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2024-06-14T02:49:03.948+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2024-06-14T02:49:03.950+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2024-06-14T02:49:03.950+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2024-06-14T02:49:03.951+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2024-06-14T02:49:03.951+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:49:03.952+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:49:03.952+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:49:03.952+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:49:03.953+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:49:03.953+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:49:03.953+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:49:03.954+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:49:03.954+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:49:03.954+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.56.255:38347
[2024-06-14T02:49:03.954+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2024-06-14T02:49:03.954+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2024-06-14T02:49:03.955+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2024-06-14T02:49:03.956+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2024-06-14T02:49:03.956+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:03.956+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:03.956+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:03.956+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:03.956+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)
[2024-06-14T02:49:03.959+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)
[2024-06-14T02:49:03.959+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.transformWith(Promise.scala:40)
[2024-06-14T02:49:03.960+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)
[2024-06-14T02:49:03.960+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)
[2024-06-14T02:49:03.962+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.flatMap(Future.scala:306)
[2024-06-14T02:49:03.962+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.flatMap$(Future.scala:306)
[2024-06-14T02:49:03.962+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)
[2024-06-14T02:49:03.962+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)
[2024-06-14T02:49:03.963+0530] {subprocess.py:93} INFO - 	... 17 more
[2024-06-14T02:49:03.963+0530] {subprocess.py:93} INFO - 24/06/14 02:49:03 WARN Executor: Issue communicating with driver in heartbeater
[2024-06-14T02:49:03.964+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:49:03.964+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:49:03.964+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:49:03.965+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:49:03.965+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2024-06-14T02:49:03.965+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2024-06-14T02:49:03.965+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2024-06-14T02:49:03.966+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)
[2024-06-14T02:49:03.966+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)
[2024-06-14T02:49:03.966+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
[2024-06-14T02:49:03.967+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:49:03.967+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2024-06-14T02:49:03.967+0530] {subprocess.py:93} INFO - 	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2024-06-14T02:49:03.967+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2024-06-14T02:49:03.967+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2024-06-14T02:49:03.968+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2024-06-14T02:49:03.969+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:49:03.970+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:49:03.970+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:49:03.970+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2024-06-14T02:49:03.971+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
[2024-06-14T02:49:03.971+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
[2024-06-14T02:49:03.971+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2024-06-14T02:49:03.971+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2024-06-14T02:49:03.972+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2024-06-14T02:49:03.972+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2024-06-14T02:49:03.972+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)
[2024-06-14T02:49:03.972+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)
[2024-06-14T02:49:03.972+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)
[2024-06-14T02:49:03.972+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)
[2024-06-14T02:49:03.972+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)
[2024-06-14T02:49:03.972+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)
[2024-06-14T02:49:03.972+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2024-06-14T02:49:03.972+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2024-06-14T02:49:03.972+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2024-06-14T02:49:03.973+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2024-06-14T02:49:03.973+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2024-06-14T02:49:03.977+0530] {subprocess.py:93} INFO - 	... 3 more
[2024-06-14T02:49:03.979+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.56.255:38347
[2024-06-14T02:49:03.980+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2024-06-14T02:49:03.980+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2024-06-14T02:49:03.980+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2024-06-14T02:49:03.981+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2024-06-14T02:49:03.981+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2024-06-14T02:49:03.981+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2024-06-14T02:49:03.982+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2024-06-14T02:49:03.982+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2024-06-14T02:49:03.982+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)
[2024-06-14T02:49:03.982+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)
[2024-06-14T02:49:03.983+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.transformWith(Promise.scala:40)
[2024-06-14T02:49:03.983+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)
[2024-06-14T02:49:03.983+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)
[2024-06-14T02:49:03.984+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.flatMap(Future.scala:306)
[2024-06-14T02:49:03.984+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.flatMap$(Future.scala:306)
[2024-06-14T02:49:03.984+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)
[2024-06-14T02:49:03.985+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)
[2024-06-14T02:49:03.985+0530] {subprocess.py:93} INFO - 	... 17 more
[2024-06-14T02:49:03.986+0530] {subprocess.py:93} INFO - 24/06/14 02:49:03 ERROR Executor: Exit as unable to send heartbeats to driver more than 60 times
[2024-06-14T02:51:24.563+0530] {subprocess.py:93} INFO - 24/06/14 02:51:24 ERROR SparkContext: Error initializing SparkContext.
[2024-06-14T02:51:24.805+0530] {subprocess.py:93} INFO - java.lang.IllegalStateException: Shutdown hooks cannot be modified during shutdown.
[2024-06-14T02:51:24.805+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkShutdownHookManager.add(ShutdownHookManager.scala:195)
[2024-06-14T02:51:24.806+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:153)
[2024-06-14T02:51:24.806+0530] {subprocess.py:93} INFO - 	at org.apache.spark.SparkContext.<init>(SparkContext.scala:683)
[2024-06-14T02:51:24.807+0530] {subprocess.py:93} INFO - 	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)
[2024-06-14T02:51:24.807+0530] {subprocess.py:93} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2024-06-14T02:51:24.807+0530] {subprocess.py:93} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
[2024-06-14T02:51:24.808+0530] {subprocess.py:93} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
[2024-06-14T02:51:24.808+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
[2024-06-14T02:51:24.809+0530] {subprocess.py:93} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)
[2024-06-14T02:51:24.809+0530] {subprocess.py:93} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2024-06-14T02:51:24.809+0530] {subprocess.py:93} INFO - 	at py4j.Gateway.invoke(Gateway.java:238)
[2024-06-14T02:51:24.809+0530] {subprocess.py:93} INFO - 	at py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)
[2024-06-14T02:51:24.810+0530] {subprocess.py:93} INFO - 	at py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)
[2024-06-14T02:51:24.810+0530] {subprocess.py:93} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2024-06-14T02:51:24.810+0530] {subprocess.py:93} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2024-06-14T02:51:24.811+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:53:48.990+0530] {subprocess.py:93} INFO - 24/06/14 02:53:48 WARN HeartbeatReceiver: Removing executor driver with no recent heartbeats: 145246 ms exceeds timeout 120000 ms
[2024-06-14T02:53:49.006+0530] {subprocess.py:93} INFO - 24/06/14 02:53:48 WARN ShutdownHookManager: ShutdownHook '' timeout, java.util.concurrent.TimeoutException
[2024-06-14T02:53:49.006+0530] {subprocess.py:93} INFO - java.util.concurrent.TimeoutException
[2024-06-14T02:53:49.006+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:204)
[2024-06-14T02:53:49.007+0530] {subprocess.py:93} INFO - 	at org.apache.hadoop.util.ShutdownHookManager.executeShutdown(ShutdownHookManager.java:124)
[2024-06-14T02:53:49.007+0530] {subprocess.py:93} INFO - 	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:95)
[2024-06-14T02:53:49.365+0530] {subprocess.py:93} INFO - 24/06/14 02:53:49 WARN SparkContext: Killing executors is not supported by current scheduler.
[2024-06-14T02:53:49.434+0530] {subprocess.py:93} INFO - 24/06/14 02:53:49 WARN JavaUtils: Attempt to delete using native Unix OS command failed for path = /tmp/blockmgr-d86b6b61-bdd1-4a1d-8bba-47bf940c8b2d. Falling back to Java IO way
[2024-06-14T02:53:49.434+0530] {subprocess.py:93} INFO - java.io.IOException: Failed to delete: /tmp/blockmgr-d86b6b61-bdd1-4a1d-8bba-47bf940c8b2d
[2024-06-14T02:53:49.435+0530] {subprocess.py:93} INFO - 	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:165)
[2024-06-14T02:53:49.435+0530] {subprocess.py:93} INFO - 	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:109)
[2024-06-14T02:53:49.435+0530] {subprocess.py:93} INFO - 	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:90)
[2024-06-14T02:53:49.436+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkFileUtils.deleteRecursively(SparkFileUtils.scala:121)
[2024-06-14T02:53:49.436+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkFileUtils.deleteRecursively$(SparkFileUtils.scala:120)
[2024-06-14T02:53:49.436+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1126)
[2024-06-14T02:53:49.437+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1(DiskBlockManager.scala:368)
[2024-06-14T02:53:49.437+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1$adapted(DiskBlockManager.scala:364)
[2024-06-14T02:53:49.437+0530] {subprocess.py:93} INFO - 	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)
[2024-06-14T02:53:49.437+0530] {subprocess.py:93} INFO - 	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)
[2024-06-14T02:53:49.437+0530] {subprocess.py:93} INFO - 	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)
[2024-06-14T02:53:49.437+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.DiskBlockManager.doStop(DiskBlockManager.scala:364)
[2024-06-14T02:53:49.437+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.DiskBlockManager.$anonfun$addShutdownHook$2(DiskBlockManager.scala:346)
[2024-06-14T02:53:49.437+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
[2024-06-14T02:53:49.438+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
[2024-06-14T02:53:49.438+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:53:49.438+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
[2024-06-14T02:53:49.438+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
[2024-06-14T02:53:49.438+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2024-06-14T02:53:49.438+0530] {subprocess.py:93} INFO - 	at scala.util.Try$.apply(Try.scala:213)
[2024-06-14T02:53:49.438+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
[2024-06-14T02:53:49.438+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
[2024-06-14T02:53:49.438+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2024-06-14T02:53:49.439+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2024-06-14T02:53:49.439+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2024-06-14T02:53:49.439+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2024-06-14T02:53:49.439+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-06-14T02:53:49.439+0530] {subprocess.py:93} INFO - Caused by: java.lang.InterruptedException
[2024-06-14T02:53:49.439+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Object.wait(Native Method)
[2024-06-14T02:53:49.439+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Object.wait(Object.java:328)
[2024-06-14T02:53:49.439+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.ProcessImpl.waitFor(ProcessImpl.java:495)
[2024-06-14T02:53:49.439+0530] {subprocess.py:93} INFO - 	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:163)
[2024-06-14T02:53:49.439+0530] {subprocess.py:93} INFO - 	... 26 more
[2024-06-14T02:55:25.673+0530] {subprocess.py:93} INFO - 24/06/14 02:54:30 WARN ShutdownHookManager: ShutdownHook 'ClientFinalizer' timeout, java.util.concurrent.TimeoutException
[2024-06-14T02:55:31.889+0530] {subprocess.py:93} INFO - java.util.concurrent.TimeoutException
[2024-06-14T02:55:39.469+0530] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:204)
[2024-06-14T02:55:39.472+0530] {subprocess.py:93} INFO - 	at org.apache.hadoop.util.ShutdownHookManager.executeShutdown(ShutdownHookManager.java:124)
[2024-06-14T02:55:39.472+0530] {subprocess.py:93} INFO - 	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:95)
[2024-06-14T03:00:46.487+0530] {subprocess.py:93} INFO - ERROR:root:Exception while sending command.
[2024-06-14T03:00:46.516+0530] {subprocess.py:93} INFO - Traceback (most recent call last):
[2024-06-14T03:00:46.517+0530] {subprocess.py:93} INFO -   File "/home/wsl/airflow_venv/lib/python3.10/site-packages/py4j/clientserver.py", line 516, in send_command
[2024-06-14T03:00:46.517+0530] {subprocess.py:93} INFO -     raise Py4JNetworkError("Answer from Java side is empty")
[2024-06-14T03:00:46.517+0530] {subprocess.py:93} INFO - py4j.protocol.Py4JNetworkError: Answer from Java side is empty
[2024-06-14T03:00:46.518+0530] {subprocess.py:93} INFO - 
[2024-06-14T03:00:46.519+0530] {subprocess.py:93} INFO - During handling of the above exception, another exception occurred:
[2024-06-14T03:00:46.519+0530] {subprocess.py:93} INFO - 
[2024-06-14T03:00:46.520+0530] {subprocess.py:93} INFO - Traceback (most recent call last):
[2024-06-14T03:00:46.520+0530] {subprocess.py:93} INFO -   File "/home/wsl/airflow_venv/lib/python3.10/site-packages/py4j/java_gateway.py", line 1038, in send_command
[2024-06-14T03:00:46.520+0530] {subprocess.py:93} INFO -     response = connection.send_command(command)
[2024-06-14T03:00:46.520+0530] {subprocess.py:93} INFO -   File "/home/wsl/airflow_venv/lib/python3.10/site-packages/py4j/clientserver.py", line 539, in send_command
[2024-06-14T03:00:46.529+0530] {subprocess.py:93} INFO -     raise Py4JNetworkError(
[2024-06-14T03:00:46.531+0530] {subprocess.py:93} INFO - py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2024-06-14T03:00:46.532+0530] {subprocess.py:93} INFO - Traceback (most recent call last):
[2024-06-14T03:00:46.532+0530] {subprocess.py:93} INFO -   File "/home/wsl/airflow/dags/Collect Data/test.py", line 16, in <module>
[2024-06-14T03:00:46.555+0530] {subprocess.py:93} INFO -     .getOrCreate()
[2024-06-14T03:00:46.567+0530] {subprocess.py:93} INFO -   File "/home/wsl/airflow_venv/lib/python3.10/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
[2024-06-14T03:00:46.583+0530] {subprocess.py:93} INFO -     sc = SparkContext.getOrCreate(sparkConf)
[2024-06-14T03:00:46.584+0530] {subprocess.py:93} INFO -   File "/home/wsl/airflow_venv/lib/python3.10/site-packages/pyspark/context.py", line 515, in getOrCreate
[2024-06-14T03:00:46.601+0530] {subprocess.py:93} INFO -     SparkContext(conf=conf or SparkConf())
[2024-06-14T03:00:46.602+0530] {subprocess.py:93} INFO -   File "/home/wsl/airflow_venv/lib/python3.10/site-packages/pyspark/context.py", line 203, in __init__
[2024-06-14T03:00:46.602+0530] {subprocess.py:93} INFO -     self._do_init(
[2024-06-14T03:00:46.603+0530] {subprocess.py:93} INFO -   File "/home/wsl/airflow_venv/lib/python3.10/site-packages/pyspark/context.py", line 296, in _do_init
[2024-06-14T03:00:46.603+0530] {subprocess.py:93} INFO -     self._jsc = jsc or self._initialize_context(self._conf._jconf)
[2024-06-14T03:00:46.603+0530] {subprocess.py:93} INFO -   File "/home/wsl/airflow_venv/lib/python3.10/site-packages/pyspark/context.py", line 421, in _initialize_context
[2024-06-14T03:00:46.604+0530] {subprocess.py:93} INFO -     return self._jvm.JavaSparkContext(jconf)
[2024-06-14T03:00:46.604+0530] {subprocess.py:93} INFO -   File "/home/wsl/airflow_venv/lib/python3.10/site-packages/py4j/java_gateway.py", line 1587, in __call__
[2024-06-14T03:00:46.605+0530] {subprocess.py:93} INFO -     return_value = get_return_value(
[2024-06-14T03:00:46.605+0530] {subprocess.py:93} INFO -   File "/home/wsl/airflow_venv/lib/python3.10/site-packages/py4j/protocol.py", line 334, in get_return_value
[2024-06-14T03:00:46.609+0530] {subprocess.py:93} INFO -     raise Py4JError(
[2024-06-14T03:00:46.609+0530] {subprocess.py:93} INFO - py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2024-06-14T03:00:48.524+0530] {subprocess.py:97} INFO - Command exited with return code 1
[2024-06-14T03:00:48.546+0530] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-14T03:00:48.966+0530] {taskinstance.py:2890} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 465, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 432, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 400, in wrapper
    return func(self, *args, **kwargs)
  File "/home/wsl/airflow_venv/lib/python3.10/site-packages/airflow/operators/bash.py", line 243, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 1.
[2024-06-14T03:00:49.273+0530] {taskinstance.py:1205} INFO - Marking task as UP_FOR_RETRY. dag_id=my_data_pipeline_dag, task_id=collect_data_3, execution_date=20240613T204431, start_date=20240613T205417, end_date=20240613T213049
[2024-06-14T03:00:49.590+0530] {standard_task_runner.py:110} ERROR - Failed to execute job 93 for task collect_data_3 (Bash command failed. The command returned a non-zero exit code 1.; 29320)
[2024-06-14T03:00:49.654+0530] {local_task_job_runner.py:240} INFO - Task exited with return code 1
[2024-06-14T03:00:49.961+0530] {taskinstance.py:3482} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-14T03:00:49.963+0530] {local_task_job_runner.py:222} INFO - ::endgroup::
